/*
THIS IS A GENERATED/BUNDLED FILE BY ROLLUP
if you want to view the source visit the plugins github repository
*/

'use strict';

var obsidian = require('obsidian');
var path$1 = require('path');

function _interopNamespace(e) {
    if (e && e.__esModule) return e;
    var n = Object.create(null);
    if (e) {
        Object.keys(e).forEach(function (k) {
            if (k !== 'default') {
                var d = Object.getOwnPropertyDescriptor(e, k);
                Object.defineProperty(n, k, d.get ? d : {
                    enumerable: true,
                    get: function () { return e[k]; }
                });
            }
        });
    }
    n["default"] = e;
    return Object.freeze(n);
}

var path__namespace = /*#__PURE__*/_interopNamespace(path$1);

/*! *****************************************************************************
Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
***************************************************************************** */

function __awaiter(thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}

/**
 * @typedef Options
 * @property {boolean} [includeImageAlt=true]
 */

/**
 * Get the text content of a node.
 * Prefer the node‚Äôs plain-text fields, otherwise serialize its children,
 * and if the given value is an array, serialize the nodes in it.
 *
 * @param {unknown} node
 * @param {Options} [options]
 * @returns {string}
 */
function toString(node, options) {
  var {includeImageAlt = true} = options || {};
  return one(node, includeImageAlt)
}

/**
 * @param {unknown} node
 * @param {boolean} includeImageAlt
 * @returns {string}
 */
function one(node, includeImageAlt) {
  return (
    (node &&
      typeof node === 'object' &&
      // @ts-ignore looks like a literal.
      (node.value ||
        // @ts-ignore looks like an image.
        (includeImageAlt ? node.alt : '') ||
        // @ts-ignore looks like a parent.
        ('children' in node && all(node.children, includeImageAlt)) ||
        (Array.isArray(node) && all(node, includeImageAlt)))) ||
    ''
  )
}

/**
 * @param {Array.<unknown>} values
 * @param {boolean} includeImageAlt
 * @returns {string}
 */
function all(values, includeImageAlt) {
  /** @type {Array.<string>} */
  var result = [];
  var index = -1;

  while (++index < values.length) {
    result[index] = one(values[index], includeImageAlt);
  }

  return result.join('')
}

/**
 * Like `Array#splice`, but smarter for giant arrays.
 *
 * `Array#splice` takes all items to be inserted as individual argument which
 * causes a stack overflow in V8 when trying to insert 100k items for instance.
 *
 * Otherwise, this does not return the removed items, and takes `items` as an
 * array instead of rest parameters.
 *
 * @template {unknown} T
 * @param {T[]} list
 * @param {number} start
 * @param {number} remove
 * @param {T[]} items
 * @returns {void}
 */
function splice(list, start, remove, items) {
  const end = list.length;
  let chunkStart = 0;
  /** @type {unknown[]} */

  let parameters; // Make start between zero and `end` (included).

  if (start < 0) {
    start = -start > end ? 0 : end + start;
  } else {
    start = start > end ? end : start;
  }

  remove = remove > 0 ? remove : 0; // No need to chunk the items if there‚Äôs only a couple (10k) items.

  if (items.length < 10000) {
    parameters = Array.from(items);
    parameters.unshift(start, remove) // @ts-expect-error Hush, it‚Äôs fine.
    ;[].splice.apply(list, parameters);
  } else {
    // Delete `remove` items starting from `start`
    if (remove) [].splice.apply(list, [start, remove]); // Insert the items in chunks to not cause stack overflows.

    while (chunkStart < items.length) {
      parameters = items.slice(chunkStart, chunkStart + 10000);
      parameters.unshift(start, 0) // @ts-expect-error Hush, it‚Äôs fine.
      ;[].splice.apply(list, parameters);
      chunkStart += 10000;
      start += 10000;
    }
  }
}
/**
 * Append `items` (an array) at the end of `list` (another array).
 * When `list` was empty, returns `items` instead.
 *
 * This prevents a potentially expensive operation when `list` is empty,
 * and adds items in batches to prevent V8 from hanging.
 *
 * @template {unknown} T
 * @param {T[]} list
 * @param {T[]} items
 * @returns {T[]}
 */

function push(list, items) {
  if (list.length > 0) {
    splice(list, list.length, 0, items);
    return list
  }

  return items
}

/**
 * @typedef {import('micromark-util-types').NormalizedExtension} NormalizedExtension
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').HtmlExtension} HtmlExtension
 */

const hasOwnProperty = {}.hasOwnProperty;

/**
 * Combine several syntax extensions into one.
 *
 * @param {Extension[]} extensions List of syntax extensions.
 * @returns {NormalizedExtension} A single combined extension.
 */
function combineExtensions(extensions) {
  /** @type {NormalizedExtension} */
  const all = {};
  let index = -1;

  while (++index < extensions.length) {
    syntaxExtension(all, extensions[index]);
  }

  return all
}

/**
 * Merge `extension` into `all`.
 *
 * @param {NormalizedExtension} all Extension to merge into.
 * @param {Extension} extension Extension to merge.
 * @returns {void}
 */
function syntaxExtension(all, extension) {
  /** @type {string} */
  let hook;

  for (hook in extension) {
    const maybe = hasOwnProperty.call(all, hook) ? all[hook] : undefined;
    const left = maybe || (all[hook] = {});
    const right = extension[hook];
    /** @type {string} */
    let code;

    for (code in right) {
      if (!hasOwnProperty.call(left, code)) left[code] = [];
      const value = right[code];
      constructs(
        // @ts-expect-error Looks like a list.
        left[code],
        Array.isArray(value) ? value : value ? [value] : []
      );
    }
  }
}

/**
 * Merge `list` into `existing` (both lists of constructs).
 * Mutates `existing`.
 *
 * @param {unknown[]} existing
 * @param {unknown[]} list
 * @returns {void}
 */
function constructs(existing, list) {
  let index = -1;
  /** @type {unknown[]} */
  const before = [];

  while (++index < list.length) {
(list[index].add === 'after' ? existing : before).push(list[index]);
  }

  splice(existing, 0, 0, before);
}

// This module is generated by `script/`.
//
// CommonMark handles attention (emphasis, strong) markers based on what comes
// before or after them.
// One such difference is if those characters are Unicode punctuation.
// This script is generated from the Unicode data.
const unicodePunctuationRegex =
  /[!-/:-@[-`{-~\u00A1\u00A7\u00AB\u00B6\u00B7\u00BB\u00BF\u037E\u0387\u055A-\u055F\u0589\u058A\u05BE\u05C0\u05C3\u05C6\u05F3\u05F4\u0609\u060A\u060C\u060D\u061B\u061E\u061F\u066A-\u066D\u06D4\u0700-\u070D\u07F7-\u07F9\u0830-\u083E\u085E\u0964\u0965\u0970\u09FD\u0A76\u0AF0\u0C77\u0C84\u0DF4\u0E4F\u0E5A\u0E5B\u0F04-\u0F12\u0F14\u0F3A-\u0F3D\u0F85\u0FD0-\u0FD4\u0FD9\u0FDA\u104A-\u104F\u10FB\u1360-\u1368\u1400\u166E\u169B\u169C\u16EB-\u16ED\u1735\u1736\u17D4-\u17D6\u17D8-\u17DA\u1800-\u180A\u1944\u1945\u1A1E\u1A1F\u1AA0-\u1AA6\u1AA8-\u1AAD\u1B5A-\u1B60\u1BFC-\u1BFF\u1C3B-\u1C3F\u1C7E\u1C7F\u1CC0-\u1CC7\u1CD3\u2010-\u2027\u2030-\u2043\u2045-\u2051\u2053-\u205E\u207D\u207E\u208D\u208E\u2308-\u230B\u2329\u232A\u2768-\u2775\u27C5\u27C6\u27E6-\u27EF\u2983-\u2998\u29D8-\u29DB\u29FC\u29FD\u2CF9-\u2CFC\u2CFE\u2CFF\u2D70\u2E00-\u2E2E\u2E30-\u2E4F\u2E52\u3001-\u3003\u3008-\u3011\u3014-\u301F\u3030\u303D\u30A0\u30FB\uA4FE\uA4FF\uA60D-\uA60F\uA673\uA67E\uA6F2-\uA6F7\uA874-\uA877\uA8CE\uA8CF\uA8F8-\uA8FA\uA8FC\uA92E\uA92F\uA95F\uA9C1-\uA9CD\uA9DE\uA9DF\uAA5C-\uAA5F\uAADE\uAADF\uAAF0\uAAF1\uABEB\uFD3E\uFD3F\uFE10-\uFE19\uFE30-\uFE52\uFE54-\uFE61\uFE63\uFE68\uFE6A\uFE6B\uFF01-\uFF03\uFF05-\uFF0A\uFF0C-\uFF0F\uFF1A\uFF1B\uFF1F\uFF20\uFF3B-\uFF3D\uFF3F\uFF5B\uFF5D\uFF5F-\uFF65]/;

/**
 * @typedef {import('micromark-util-types').Code} Code
 */
/**
 * Check whether the character code represents an ASCII alpha (`a` through `z`,
 * case insensitive).
 *
 * An **ASCII alpha** is an ASCII upper alpha or ASCII lower alpha.
 *
 * An **ASCII upper alpha** is a character in the inclusive range U+0041 (`A`)
 * to U+005A (`Z`).
 *
 * An **ASCII lower alpha** is a character in the inclusive range U+0061 (`a`)
 * to U+007A (`z`).
 */

const asciiAlpha = regexCheck(/[A-Za-z]/);
/**
 * Check whether the character code represents an ASCII digit (`0` through `9`).
 *
 * An **ASCII digit** is a character in the inclusive range U+0030 (`0`) to
 * U+0039 (`9`).
 */

const asciiDigit = regexCheck(/\d/);
/**
 * Check whether the character code represents an ASCII hex digit (`a` through
 * `f`, case insensitive, or `0` through `9`).
 *
 * An **ASCII hex digit** is an ASCII digit (see `asciiDigit`), ASCII upper hex
 * digit, or an ASCII lower hex digit.
 *
 * An **ASCII upper hex digit** is a character in the inclusive range U+0041
 * (`A`) to U+0046 (`F`).
 *
 * An **ASCII lower hex digit** is a character in the inclusive range U+0061
 * (`a`) to U+0066 (`f`).
 */

const asciiHexDigit = regexCheck(/[\dA-Fa-f]/);
/**
 * Check whether the character code represents an ASCII alphanumeric (`a`
 * through `z`, case insensitive, or `0` through `9`).
 *
 * An **ASCII alphanumeric** is an ASCII digit (see `asciiDigit`) or ASCII alpha
 * (see `asciiAlpha`).
 */

const asciiAlphanumeric = regexCheck(/[\dA-Za-z]/);
/**
 * Check whether the character code represents ASCII punctuation.
 *
 * An **ASCII punctuation** is a character in the inclusive ranges U+0021
 * EXCLAMATION MARK (`!`) to U+002F SLASH (`/`), U+003A COLON (`:`) to U+0040 AT
 * SIGN (`@`), U+005B LEFT SQUARE BRACKET (`[`) to U+0060 GRAVE ACCENT
 * (`` ` ``), or U+007B LEFT CURLY BRACE (`{`) to U+007E TILDE (`~`).
 */

const asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/);
/**
 * Check whether the character code represents an ASCII atext.
 *
 * atext is an ASCII alphanumeric (see `asciiAlphanumeric`), or a character in
 * the inclusive ranges U+0023 NUMBER SIGN (`#`) to U+0027 APOSTROPHE (`'`),
 * U+002A ASTERISK (`*`), U+002B PLUS SIGN (`+`), U+002D DASH (`-`), U+002F
 * SLASH (`/`), U+003D EQUALS TO (`=`), U+003F QUESTION MARK (`?`), U+005E
 * CARET (`^`) to U+0060 GRAVE ACCENT (`` ` ``), or U+007B LEFT CURLY BRACE
 * (`{`) to U+007E TILDE (`~`).
 *
 * See:
 * **\[RFC5322]**:
 * [Internet Message Format](https://tools.ietf.org/html/rfc5322).
 * P. Resnick.
 * IETF.
 */

const asciiAtext = regexCheck(/[#-'*+\--9=?A-Z^-~]/);
/**
 * Check whether a character code is an ASCII control character.
 *
 * An **ASCII control** is a character in the inclusive range U+0000 NULL (NUL)
 * to U+001F (US), or U+007F (DEL).
 *
 * @param {Code} code
 * @returns {code is number}
 */

function asciiControl(code) {
  return (
    // Special whitespace codes (which have negative values), C0 and Control
    // character DEL
    code !== null && (code < 32 || code === 127)
  )
}
/**
 * Check whether a character code is a markdown line ending (see
 * `markdownLineEnding`) or markdown space (see `markdownSpace`).
 *
 * @param {Code} code
 * @returns {code is number}
 */

function markdownLineEndingOrSpace$1(code) {
  return code !== null && (code < 0 || code === 32)
}
/**
 * Check whether a character code is a markdown line ending.
 *
 * A **markdown line ending** is the virtual characters M-0003 CARRIAGE RETURN
 * LINE FEED (CRLF), M-0004 LINE FEED (LF) and M-0005 CARRIAGE RETURN (CR).
 *
 * In micromark, the actual character U+000A LINE FEED (LF) and U+000D CARRIAGE
 * RETURN (CR) are replaced by these virtual characters depending on whether
 * they occurred together.
 *
 * @param {Code} code
 * @returns {code is number}
 */

function markdownLineEnding$1(code) {
  return code !== null && code < -2
}
/**
 * Check whether a character code is a markdown space.
 *
 * A **markdown space** is the concrete character U+0020 SPACE (SP) and the
 * virtual characters M-0001 VIRTUAL SPACE (VS) and M-0002 HORIZONTAL TAB (HT).
 *
 * In micromark, the actual character U+0009 CHARACTER TABULATION (HT) is
 * replaced by one M-0002 HORIZONTAL TAB (HT) and between 0 and 3 M-0001 VIRTUAL
 * SPACE (VS) characters, depending on the column at which the tab occurred.
 *
 * @param {Code} code
 * @returns {code is number}
 */

function markdownSpace(code) {
  return code === -2 || code === -1 || code === 32
}
/**
 * Check whether the character code represents Unicode whitespace.
 *
 * Note that this does handle micromark specific markdown whitespace characters.
 * See `markdownLineEndingOrSpace` to check that.
 *
 * A **Unicode whitespace** is a character in the Unicode `Zs` (Separator,
 * Space) category, or U+0009 CHARACTER TABULATION (HT), U+000A LINE FEED (LF),
 * U+000C (FF), or U+000D CARRIAGE RETURN (CR) (**\[UNICODE]**).
 *
 * See:
 * **\[UNICODE]**:
 * [The Unicode Standard](https://www.unicode.org/versions/).
 * Unicode Consortium.
 */

const unicodeWhitespace = regexCheck(/\s/);
/**
 * Check whether the character code represents Unicode punctuation.
 *
 * A **Unicode punctuation** is a character in the Unicode `Pc` (Punctuation,
 * Connector), `Pd` (Punctuation, Dash), `Pe` (Punctuation, Close), `Pf`
 * (Punctuation, Final quote), `Pi` (Punctuation, Initial quote), `Po`
 * (Punctuation, Other), or `Ps` (Punctuation, Open) categories, or an ASCII
 * punctuation (see `asciiPunctuation`).
 *
 * See:
 * **\[UNICODE]**:
 * [The Unicode Standard](https://www.unicode.org/versions/).
 * Unicode Consortium.
 */
// Size note: removing ASCII from the regex and using `asciiPunctuation` here
// In fact adds to the bundle size.

const unicodePunctuation = regexCheck(unicodePunctuationRegex);
/**
 * Create a code check from a regex.
 *
 * @param {RegExp} regex
 * @returns {(code: Code) => code is number}
 */

function regexCheck(regex) {
  return check
  /**
   * Check whether a code matches the bound regex.
   *
   * @param {Code} code Character code
   * @returns {code is number} Whether the character code matches the bound regex
   */

  function check(code) {
    return code !== null && regex.test(String.fromCharCode(code))
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 */
/**
 * @param {Effects} effects
 * @param {State} ok
 * @param {string} type
 * @param {number} [max=Infinity]
 * @returns {State}
 */

function factorySpace(effects, ok, type, max) {
  const limit = max ? max - 1 : Number.POSITIVE_INFINITY;
  let size = 0;
  return start
  /** @type {State} */

  function start(code) {
    if (markdownSpace(code)) {
      effects.enter(type);
      return prefix(code)
    }

    return ok(code)
  }
  /** @type {State} */

  function prefix(code) {
    if (markdownSpace(code) && size++ < limit) {
      effects.consume(code);
      return prefix
    }

    effects.exit(type);
    return ok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').Initializer} Initializer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {InitialConstruct} */
const content$1 = {
  tokenize: initializeContent
};
/** @type {Initializer} */

function initializeContent(effects) {
  const contentStart = effects.attempt(
    this.parser.constructs.contentInitial,
    afterContentStartConstruct,
    paragraphInitial
  );
  /** @type {Token} */

  let previous;
  return contentStart
  /** @type {State} */

  function afterContentStartConstruct(code) {
    if (code === null) {
      effects.consume(code);
      return
    }

    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return factorySpace(effects, contentStart, 'linePrefix')
  }
  /** @type {State} */

  function paragraphInitial(code) {
    effects.enter('paragraph');
    return lineStart(code)
  }
  /** @type {State} */

  function lineStart(code) {
    const token = effects.enter('chunkText', {
      contentType: 'text',
      previous
    });

    if (previous) {
      previous.next = token;
    }

    previous = token;
    return data(code)
  }
  /** @type {State} */

  function data(code) {
    if (code === null) {
      effects.exit('chunkText');
      effects.exit('paragraph');
      effects.consume(code);
      return
    }

    if (markdownLineEnding$1(code)) {
      effects.consume(code);
      effects.exit('chunkText');
      return lineStart
    } // Data.

    effects.consume(code);
    return data
  }
}

/**
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').Initializer} Initializer
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Point} Point
 */
/** @type {InitialConstruct} */

const document$1 = {
  tokenize: initializeDocument
};
/** @type {Construct} */

const containerConstruct = {
  tokenize: tokenizeContainer
};
/** @type {Initializer} */

function initializeDocument(effects) {
  const self = this;
  /** @type {StackItem[]} */

  const stack = [];
  let continued = 0;
  /** @type {TokenizeContext|undefined} */

  let childFlow;
  /** @type {Token|undefined} */

  let childToken;
  /** @type {number} */

  let lineStartOffset;
  return start
  /** @type {State} */

  function start(code) {
    // First we iterate through the open blocks, starting with the root
    // document, and descending through last children down to the last open
    // block.
    // Each block imposes a condition that the line must satisfy if the block is
    // to remain open.
    // For example, a block quote requires a `>` character.
    // A paragraph requires a non-blank line.
    // In this phase we may match all or just some of the open blocks.
    // But we cannot close unmatched blocks yet, because we may have a lazy
    // continuation line.
    if (continued < stack.length) {
      const item = stack[continued];
      self.containerState = item[1];
      return effects.attempt(
        item[0].continuation,
        documentContinue,
        checkNewContainers
      )(code)
    } // Done.

    return checkNewContainers(code)
  }
  /** @type {State} */

  function documentContinue(code) {
    continued++; // Note: this field is called `_closeFlow` but it also closes containers.
    // Perhaps a good idea to rename it but it‚Äôs already used in the wild by
    // extensions.

    if (self.containerState._closeFlow) {
      self.containerState._closeFlow = undefined;

      if (childFlow) {
        closeFlow();
      } // Note: this algorithm for moving events around is similar to the
      // algorithm when dealing with lazy lines in `writeToChild`.

      const indexBeforeExits = self.events.length;
      let indexBeforeFlow = indexBeforeExits;
      /** @type {Point|undefined} */

      let point; // Find the flow chunk.

      while (indexBeforeFlow--) {
        if (
          self.events[indexBeforeFlow][0] === 'exit' &&
          self.events[indexBeforeFlow][1].type === 'chunkFlow'
        ) {
          point = self.events[indexBeforeFlow][1].end;
          break
        }
      }

      exitContainers(continued); // Fix positions.

      let index = indexBeforeExits;

      while (index < self.events.length) {
        self.events[index][1].end = Object.assign({}, point);
        index++;
      } // Inject the exits earlier (they‚Äôre still also at the end).

      splice(
        self.events,
        indexBeforeFlow + 1,
        0,
        self.events.slice(indexBeforeExits)
      ); // Discard the duplicate exits.

      self.events.length = index;
      return checkNewContainers(code)
    }

    return start(code)
  }
  /** @type {State} */

  function checkNewContainers(code) {
    // Next, after consuming the continuation markers for existing blocks, we
    // look for new block starts (e.g. `>` for a block quote).
    // If we encounter a new block start, we close any blocks unmatched in
    // step 1 before creating the new block as a child of the last matched
    // block.
    if (continued === stack.length) {
      // No need to `check` whether there‚Äôs a container, of `exitContainers`
      // would be moot.
      // We can instead immediately `attempt` to parse one.
      if (!childFlow) {
        return documentContinued(code)
      } // If we have concrete content, such as block HTML or fenced code,
      // we can‚Äôt have containers ‚Äúpierce‚Äù into them, so we can immediately
      // start.

      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {
        return flowStart(code)
      } // If we do have flow, it could still be a blank line,
      // but we‚Äôd be interrupting it w/ a new container if there‚Äôs a current
      // construct.

      self.interrupt = Boolean(
        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack
      );
    } // Check if there is a new container.

    self.containerState = {};
    return effects.check(
      containerConstruct,
      thereIsANewContainer,
      thereIsNoNewContainer
    )(code)
  }
  /** @type {State} */

  function thereIsANewContainer(code) {
    if (childFlow) closeFlow();
    exitContainers(continued);
    return documentContinued(code)
  }
  /** @type {State} */

  function thereIsNoNewContainer(code) {
    self.parser.lazy[self.now().line] = continued !== stack.length;
    lineStartOffset = self.now().offset;
    return flowStart(code)
  }
  /** @type {State} */

  function documentContinued(code) {
    // Try new containers.
    self.containerState = {};
    return effects.attempt(
      containerConstruct,
      containerContinue,
      flowStart
    )(code)
  }
  /** @type {State} */

  function containerContinue(code) {
    continued++;
    stack.push([self.currentConstruct, self.containerState]); // Try another.

    return documentContinued(code)
  }
  /** @type {State} */

  function flowStart(code) {
    if (code === null) {
      if (childFlow) closeFlow();
      exitContainers(0);
      effects.consume(code);
      return
    }

    childFlow = childFlow || self.parser.flow(self.now());
    effects.enter('chunkFlow', {
      contentType: 'flow',
      previous: childToken,
      _tokenizer: childFlow
    });
    return flowContinue(code)
  }
  /** @type {State} */

  function flowContinue(code) {
    if (code === null) {
      writeToChild(effects.exit('chunkFlow'), true);
      exitContainers(0);
      effects.consume(code);
      return
    }

    if (markdownLineEnding$1(code)) {
      effects.consume(code);
      writeToChild(effects.exit('chunkFlow')); // Get ready for the next line.

      continued = 0;
      self.interrupt = undefined;
      return start
    }

    effects.consume(code);
    return flowContinue
  }
  /**
   * @param {Token} token
   * @param {boolean} [eof]
   * @returns {void}
   */

  function writeToChild(token, eof) {
    const stream = self.sliceStream(token);
    if (eof) stream.push(null);
    token.previous = childToken;
    if (childToken) childToken.next = token;
    childToken = token;
    childFlow.defineSkip(token.start);
    childFlow.write(stream); // Alright, so we just added a lazy line:
    //
    // ```markdown
    // > a
    // b.
    //
    // Or:
    //
    // > ~~~c
    // d
    //
    // Or:
    //
    // > | e |
    // f
    // ```
    //
    // The construct in the second example (fenced code) does not accept lazy
    // lines, so it marked itself as done at the end of its first line, and
    // then the content construct parses `d`.
    // Most constructs in markdown match on the first line: if the first line
    // forms a construct, a non-lazy line can‚Äôt ‚Äúunmake‚Äù it.
    //
    // The construct in the third example is potentially a GFM table, and
    // those are *weird*.
    // It *could* be a table, from the first line, if the following line
    // matches a condition.
    // In this case, that second line is lazy, which ‚Äúunmakes‚Äù the first line
    // and turns the whole into one content block.
    //
    // We‚Äôve now parsed the non-lazy and the lazy line, and can figure out
    // whether the lazy line started a new flow block.
    // If it did, we exit the current containers between the two flow blocks.

    if (self.parser.lazy[token.start.line]) {
      let index = childFlow.events.length;

      while (index--) {
        if (
          // The token starts before the line ending‚Ä¶
          childFlow.events[index][1].start.offset < lineStartOffset && // ‚Ä¶and either is not ended yet‚Ä¶
          (!childFlow.events[index][1].end || // ‚Ä¶or ends after it.
            childFlow.events[index][1].end.offset > lineStartOffset)
        ) {
          // Exit: there‚Äôs still something open, which means it‚Äôs a lazy line
          // part of something.
          return
        }
      } // Note: this algorithm for moving events around is similar to the
      // algorithm when closing flow in `documentContinue`.

      const indexBeforeExits = self.events.length;
      let indexBeforeFlow = indexBeforeExits;
      /** @type {boolean|undefined} */

      let seen;
      /** @type {Point|undefined} */

      let point; // Find the previous chunk (the one before the lazy line).

      while (indexBeforeFlow--) {
        if (
          self.events[indexBeforeFlow][0] === 'exit' &&
          self.events[indexBeforeFlow][1].type === 'chunkFlow'
        ) {
          if (seen) {
            point = self.events[indexBeforeFlow][1].end;
            break
          }

          seen = true;
        }
      }

      exitContainers(continued); // Fix positions.

      index = indexBeforeExits;

      while (index < self.events.length) {
        self.events[index][1].end = Object.assign({}, point);
        index++;
      } // Inject the exits earlier (they‚Äôre still also at the end).

      splice(
        self.events,
        indexBeforeFlow + 1,
        0,
        self.events.slice(indexBeforeExits)
      ); // Discard the duplicate exits.

      self.events.length = index;
    }
  }
  /**
   * @param {number} size
   * @returns {void}
   */

  function exitContainers(size) {
    let index = stack.length; // Exit open containers.

    while (index-- > size) {
      const entry = stack[index];
      self.containerState = entry[1];
      entry[0].exit.call(self, effects);
    }

    stack.length = size;
  }

  function closeFlow() {
    childFlow.write([null]);
    childToken = undefined;
    childFlow = undefined;
    self.containerState._closeFlow = undefined;
  }
}
/** @type {Tokenizer} */

function tokenizeContainer(effects, ok, nok) {
  return factorySpace(
    effects,
    effects.attempt(this.parser.constructs.document, ok, nok),
    'linePrefix',
    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4
  )
}

/**
 * @typedef {import('micromark-util-types').Code} Code
 */

/**
 * Classify whether a character code represents whitespace, punctuation, or
 * something else.
 *
 * Used for attention (emphasis, strong), whose sequences can open or close
 * based on the class of surrounding characters.
 *
 * Note that eof (`null`) is seen as whitespace.
 *
 * @param {Code} code
 * @returns {number|undefined}
 */
function classifyCharacter(code) {
  if (
    code === null ||
    markdownLineEndingOrSpace$1(code) ||
    unicodeWhitespace(code)
  ) {
    return 1
  }

  if (unicodePunctuation(code)) {
    return 2
  }
}

/**
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Resolver} Resolver
 */

/**
 * Call all `resolveAll`s.
 *
 * @param {{resolveAll?: Resolver}[]} constructs
 * @param {Event[]} events
 * @param {TokenizeContext} context
 * @returns {Event[]}
 */
function resolveAll(constructs, events, context) {
  /** @type {Resolver[]} */
  const called = [];
  let index = -1;

  while (++index < constructs.length) {
    const resolve = constructs[index].resolveAll;

    if (resolve && !called.includes(resolve)) {
      events = resolve(events, context);
      called.push(resolve);
    }
  }

  return events
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Code} Code
 * @typedef {import('micromark-util-types').Point} Point
 */

/** @type {Construct} */
const attention = {
  name: 'attention',
  tokenize: tokenizeAttention,
  resolveAll: resolveAllAttention
};
/**
 * Take all events and resolve attention to emphasis or strong.
 *
 * @type {Resolver}
 */

function resolveAllAttention(events, context) {
  let index = -1;
  /** @type {number} */

  let open;
  /** @type {Token} */

  let group;
  /** @type {Token} */

  let text;
  /** @type {Token} */

  let openingSequence;
  /** @type {Token} */

  let closingSequence;
  /** @type {number} */

  let use;
  /** @type {Event[]} */

  let nextEvents;
  /** @type {number} */

  let offset; // Walk through all events.
  //
  // Note: performance of this is fine on an mb of normal markdown, but it‚Äôs
  // a bottleneck for malicious stuff.

  while (++index < events.length) {
    // Find a token that can close.
    if (
      events[index][0] === 'enter' &&
      events[index][1].type === 'attentionSequence' &&
      events[index][1]._close
    ) {
      open = index; // Now walk back to find an opener.

      while (open--) {
        // Find a token that can open the closer.
        if (
          events[open][0] === 'exit' &&
          events[open][1].type === 'attentionSequence' &&
          events[open][1]._open && // If the markers are the same:
          context.sliceSerialize(events[open][1]).charCodeAt(0) ===
            context.sliceSerialize(events[index][1]).charCodeAt(0)
        ) {
          // If the opening can close or the closing can open,
          // and the close size *is not* a multiple of three,
          // but the sum of the opening and closing size *is* multiple of three,
          // then don‚Äôt match.
          if (
            (events[open][1]._close || events[index][1]._open) &&
            (events[index][1].end.offset - events[index][1].start.offset) % 3 &&
            !(
              (events[open][1].end.offset -
                events[open][1].start.offset +
                events[index][1].end.offset -
                events[index][1].start.offset) %
              3
            )
          ) {
            continue
          } // Number of markers to use from the sequence.

          use =
            events[open][1].end.offset - events[open][1].start.offset > 1 &&
            events[index][1].end.offset - events[index][1].start.offset > 1
              ? 2
              : 1;
          const start = Object.assign({}, events[open][1].end);
          const end = Object.assign({}, events[index][1].start);
          movePoint(start, -use);
          movePoint(end, use);
          openingSequence = {
            type: use > 1 ? 'strongSequence' : 'emphasisSequence',
            start,
            end: Object.assign({}, events[open][1].end)
          };
          closingSequence = {
            type: use > 1 ? 'strongSequence' : 'emphasisSequence',
            start: Object.assign({}, events[index][1].start),
            end
          };
          text = {
            type: use > 1 ? 'strongText' : 'emphasisText',
            start: Object.assign({}, events[open][1].end),
            end: Object.assign({}, events[index][1].start)
          };
          group = {
            type: use > 1 ? 'strong' : 'emphasis',
            start: Object.assign({}, openingSequence.start),
            end: Object.assign({}, closingSequence.end)
          };
          events[open][1].end = Object.assign({}, openingSequence.start);
          events[index][1].start = Object.assign({}, closingSequence.end);
          nextEvents = []; // If there are more markers in the opening, add them before.

          if (events[open][1].end.offset - events[open][1].start.offset) {
            nextEvents = push(nextEvents, [
              ['enter', events[open][1], context],
              ['exit', events[open][1], context]
            ]);
          } // Opening.

          nextEvents = push(nextEvents, [
            ['enter', group, context],
            ['enter', openingSequence, context],
            ['exit', openingSequence, context],
            ['enter', text, context]
          ]); // Between.

          nextEvents = push(
            nextEvents,
            resolveAll(
              context.parser.constructs.insideSpan.null,
              events.slice(open + 1, index),
              context
            )
          ); // Closing.

          nextEvents = push(nextEvents, [
            ['exit', text, context],
            ['enter', closingSequence, context],
            ['exit', closingSequence, context],
            ['exit', group, context]
          ]); // If there are more markers in the closing, add them after.

          if (events[index][1].end.offset - events[index][1].start.offset) {
            offset = 2;
            nextEvents = push(nextEvents, [
              ['enter', events[index][1], context],
              ['exit', events[index][1], context]
            ]);
          } else {
            offset = 0;
          }

          splice(events, open - 1, index - open + 3, nextEvents);
          index = open + nextEvents.length - offset - 2;
          break
        }
      }
    }
  } // Remove remaining sequences.

  index = -1;

  while (++index < events.length) {
    if (events[index][1].type === 'attentionSequence') {
      events[index][1].type = 'data';
    }
  }

  return events
}
/** @type {Tokenizer} */

function tokenizeAttention(effects, ok) {
  const attentionMarkers = this.parser.constructs.attentionMarkers.null;
  const previous = this.previous;
  const before = classifyCharacter(previous);
  /** @type {NonNullable<Code>} */

  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('attentionSequence');
    marker = code;
    return sequence(code)
  }
  /** @type {State} */

  function sequence(code) {
    if (code === marker) {
      effects.consume(code);
      return sequence
    }

    const token = effects.exit('attentionSequence');
    const after = classifyCharacter(code);
    const open =
      !after || (after === 2 && before) || attentionMarkers.includes(code);
    const close =
      !before || (before === 2 && after) || attentionMarkers.includes(previous);
    token._open = Boolean(marker === 42 ? open : open && (before || !close));
    token._close = Boolean(marker === 42 ? close : close && (after || !open));
    return ok(code)
  }
}
/**
 * Move a point a bit.
 *
 * Note: `move` only works inside lines! It‚Äôs not possible to move past other
 * chunks (replacement characters, tabs, or line endings).
 *
 * @param {Point} point
 * @param {number} offset
 * @returns {void}
 */

function movePoint(point, offset) {
  point.column += offset;
  point.offset += offset;
  point._bufferIndex += offset;
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const autolink = {
  name: 'autolink',
  tokenize: tokenizeAutolink
};
/** @type {Tokenizer} */

function tokenizeAutolink(effects, ok, nok) {
  let size = 1;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('autolink');
    effects.enter('autolinkMarker');
    effects.consume(code);
    effects.exit('autolinkMarker');
    effects.enter('autolinkProtocol');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (asciiAlpha(code)) {
      effects.consume(code);
      return schemeOrEmailAtext
    }

    return asciiAtext(code) ? emailAtext(code) : nok(code)
  }
  /** @type {State} */

  function schemeOrEmailAtext(code) {
    return code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)
      ? schemeInsideOrEmailAtext(code)
      : emailAtext(code)
  }
  /** @type {State} */

  function schemeInsideOrEmailAtext(code) {
    if (code === 58) {
      effects.consume(code);
      return urlInside
    }

    if (
      (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) &&
      size++ < 32
    ) {
      effects.consume(code);
      return schemeInsideOrEmailAtext
    }

    return emailAtext(code)
  }
  /** @type {State} */

  function urlInside(code) {
    if (code === 62) {
      effects.exit('autolinkProtocol');
      return end(code)
    }

    if (code === null || code === 32 || code === 60 || asciiControl(code)) {
      return nok(code)
    }

    effects.consume(code);
    return urlInside
  }
  /** @type {State} */

  function emailAtext(code) {
    if (code === 64) {
      effects.consume(code);
      size = 0;
      return emailAtSignOrDot
    }

    if (asciiAtext(code)) {
      effects.consume(code);
      return emailAtext
    }

    return nok(code)
  }
  /** @type {State} */

  function emailAtSignOrDot(code) {
    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code)
  }
  /** @type {State} */

  function emailLabel(code) {
    if (code === 46) {
      effects.consume(code);
      size = 0;
      return emailAtSignOrDot
    }

    if (code === 62) {
      // Exit, then change the type.
      effects.exit('autolinkProtocol').type = 'autolinkEmail';
      return end(code)
    }

    return emailValue(code)
  }
  /** @type {State} */

  function emailValue(code) {
    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {
      effects.consume(code);
      return code === 45 ? emailValue : emailLabel
    }

    return nok(code)
  }
  /** @type {State} */

  function end(code) {
    effects.enter('autolinkMarker');
    effects.consume(code);
    effects.exit('autolinkMarker');
    effects.exit('autolink');
    return ok
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const blankLine = {
  tokenize: tokenizeBlankLine,
  partial: true
};
/** @type {Tokenizer} */

function tokenizeBlankLine(effects, ok, nok) {
  return factorySpace(effects, afterWhitespace, 'linePrefix')
  /** @type {State} */

  function afterWhitespace(code) {
    return code === null || markdownLineEnding$1(code) ? ok(code) : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Exiter} Exiter
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const blockQuote = {
  name: 'blockQuote',
  tokenize: tokenizeBlockQuoteStart,
  continuation: {
    tokenize: tokenizeBlockQuoteContinuation
  },
  exit: exit$1
};
/** @type {Tokenizer} */

function tokenizeBlockQuoteStart(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    if (code === 62) {
      const state = self.containerState;

      if (!state.open) {
        effects.enter('blockQuote', {
          _container: true
        });
        state.open = true;
      }

      effects.enter('blockQuotePrefix');
      effects.enter('blockQuoteMarker');
      effects.consume(code);
      effects.exit('blockQuoteMarker');
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    if (markdownSpace(code)) {
      effects.enter('blockQuotePrefixWhitespace');
      effects.consume(code);
      effects.exit('blockQuotePrefixWhitespace');
      effects.exit('blockQuotePrefix');
      return ok
    }

    effects.exit('blockQuotePrefix');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeBlockQuoteContinuation(effects, ok, nok) {
  return factorySpace(
    effects,
    effects.attempt(blockQuote, ok, nok),
    'linePrefix',
    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4
  )
}
/** @type {Exiter} */

function exit$1(effects) {
  effects.exit('blockQuote');
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const characterEscape = {
  name: 'characterEscape',
  tokenize: tokenizeCharacterEscape
};
/** @type {Tokenizer} */

function tokenizeCharacterEscape(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('characterEscape');
    effects.enter('escapeMarker');
    effects.consume(code);
    effects.exit('escapeMarker');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (asciiPunctuation(code)) {
      effects.enter('characterEscapeValue');
      effects.consume(code);
      effects.exit('characterEscapeValue');
      effects.exit('characterEscape');
      return ok
    }

    return nok(code)
  }
}

/**
 * Map of named character references.
 *
 * @type {Record<string, string>}
 */
const characterEntities = {
  AEli: '√Ü',
  AElig: '√Ü',
  AM: '&',
  AMP: '&',
  Aacut: '√Å',
  Aacute: '√Å',
  Abreve: 'ƒÇ',
  Acir: '√Ç',
  Acirc: '√Ç',
  Acy: '–ê',
  Afr: 'ùîÑ',
  Agrav: '√Ä',
  Agrave: '√Ä',
  Alpha: 'Œë',
  Amacr: 'ƒÄ',
  And: '‚©ì',
  Aogon: 'ƒÑ',
  Aopf: 'ùî∏',
  ApplyFunction: '‚Å°',
  Arin: '√Ö',
  Aring: '√Ö',
  Ascr: 'ùíú',
  Assign: '‚âî',
  Atild: '√É',
  Atilde: '√É',
  Aum: '√Ñ',
  Auml: '√Ñ',
  Backslash: '‚àñ',
  Barv: '‚´ß',
  Barwed: '‚åÜ',
  Bcy: '–ë',
  Because: '‚àµ',
  Bernoullis: '‚Ñ¨',
  Beta: 'Œí',
  Bfr: 'ùîÖ',
  Bopf: 'ùîπ',
  Breve: 'Àò',
  Bscr: '‚Ñ¨',
  Bumpeq: '‚âé',
  CHcy: '–ß',
  COP: '¬©',
  COPY: '¬©',
  Cacute: 'ƒÜ',
  Cap: '‚ãí',
  CapitalDifferentialD: '‚ÖÖ',
  Cayleys: '‚Ñ≠',
  Ccaron: 'ƒå',
  Ccedi: '√á',
  Ccedil: '√á',
  Ccirc: 'ƒà',
  Cconint: '‚à∞',
  Cdot: 'ƒä',
  Cedilla: '¬∏',
  CenterDot: '¬∑',
  Cfr: '‚Ñ≠',
  Chi: 'Œß',
  CircleDot: '‚äô',
  CircleMinus: '‚äñ',
  CirclePlus: '‚äï',
  CircleTimes: '‚äó',
  ClockwiseContourIntegral: '‚à≤',
  CloseCurlyDoubleQuote: '‚Äù',
  CloseCurlyQuote: '‚Äô',
  Colon: '‚à∑',
  Colone: '‚©¥',
  Congruent: '‚â°',
  Conint: '‚àØ',
  ContourIntegral: '‚àÆ',
  Copf: '‚ÑÇ',
  Coproduct: '‚àê',
  CounterClockwiseContourIntegral: '‚à≥',
  Cross: '‚®Ø',
  Cscr: 'ùíû',
  Cup: '‚ãì',
  CupCap: '‚âç',
  DD: '‚ÖÖ',
  DDotrahd: '‚§ë',
  DJcy: '–Ç',
  DScy: '–Ö',
  DZcy: '–è',
  Dagger: '‚Ä°',
  Darr: '‚Ü°',
  Dashv: '‚´§',
  Dcaron: 'ƒé',
  Dcy: '–î',
  Del: '‚àá',
  Delta: 'Œî',
  Dfr: 'ùîá',
  DiacriticalAcute: '¬¥',
  DiacriticalDot: 'Àô',
  DiacriticalDoubleAcute: 'Àù',
  DiacriticalGrave: '`',
  DiacriticalTilde: 'Àú',
  Diamond: '‚ãÑ',
  DifferentialD: '‚ÖÜ',
  Dopf: 'ùîª',
  Dot: '¬®',
  DotDot: '‚Éú',
  DotEqual: '‚âê',
  DoubleContourIntegral: '‚àØ',
  DoubleDot: '¬®',
  DoubleDownArrow: '‚áì',
  DoubleLeftArrow: '‚áê',
  DoubleLeftRightArrow: '‚áî',
  DoubleLeftTee: '‚´§',
  DoubleLongLeftArrow: '‚ü∏',
  DoubleLongLeftRightArrow: '‚ü∫',
  DoubleLongRightArrow: '‚üπ',
  DoubleRightArrow: '‚áí',
  DoubleRightTee: '‚ä®',
  DoubleUpArrow: '‚áë',
  DoubleUpDownArrow: '‚áï',
  DoubleVerticalBar: '‚à•',
  DownArrow: '‚Üì',
  DownArrowBar: '‚§ì',
  DownArrowUpArrow: '‚áµ',
  DownBreve: 'Ãë',
  DownLeftRightVector: '‚•ê',
  DownLeftTeeVector: '‚•û',
  DownLeftVector: '‚ÜΩ',
  DownLeftVectorBar: '‚•ñ',
  DownRightTeeVector: '‚•ü',
  DownRightVector: '‚áÅ',
  DownRightVectorBar: '‚•ó',
  DownTee: '‚ä§',
  DownTeeArrow: '‚Üß',
  Downarrow: '‚áì',
  Dscr: 'ùíü',
  Dstrok: 'ƒê',
  ENG: '≈ä',
  ET: '√ê',
  ETH: '√ê',
  Eacut: '√â',
  Eacute: '√â',
  Ecaron: 'ƒö',
  Ecir: '√ä',
  Ecirc: '√ä',
  Ecy: '–≠',
  Edot: 'ƒñ',
  Efr: 'ùîà',
  Egrav: '√à',
  Egrave: '√à',
  Element: '‚àà',
  Emacr: 'ƒí',
  EmptySmallSquare: '‚óª',
  EmptyVerySmallSquare: '‚ñ´',
  Eogon: 'ƒò',
  Eopf: 'ùîº',
  Epsilon: 'Œï',
  Equal: '‚©µ',
  EqualTilde: '‚âÇ',
  Equilibrium: '‚áå',
  Escr: '‚Ñ∞',
  Esim: '‚©≥',
  Eta: 'Œó',
  Eum: '√ã',
  Euml: '√ã',
  Exists: '‚àÉ',
  ExponentialE: '‚Öá',
  Fcy: '–§',
  Ffr: 'ùîâ',
  FilledSmallSquare: '‚óº',
  FilledVerySmallSquare: '‚ñ™',
  Fopf: 'ùîΩ',
  ForAll: '‚àÄ',
  Fouriertrf: '‚Ñ±',
  Fscr: '‚Ñ±',
  GJcy: '–É',
  G: '>',
  GT: '>',
  Gamma: 'Œì',
  Gammad: 'œú',
  Gbreve: 'ƒû',
  Gcedil: 'ƒ¢',
  Gcirc: 'ƒú',
  Gcy: '–ì',
  Gdot: 'ƒ†',
  Gfr: 'ùîä',
  Gg: '‚ãô',
  Gopf: 'ùîæ',
  GreaterEqual: '‚â•',
  GreaterEqualLess: '‚ãõ',
  GreaterFullEqual: '‚âß',
  GreaterGreater: '‚™¢',
  GreaterLess: '‚â∑',
  GreaterSlantEqual: '‚©æ',
  GreaterTilde: '‚â≥',
  Gscr: 'ùí¢',
  Gt: '‚â´',
  HARDcy: '–™',
  Hacek: 'Àá',
  Hat: '^',
  Hcirc: 'ƒ§',
  Hfr: '‚Ñå',
  HilbertSpace: '‚Ñã',
  Hopf: '‚Ñç',
  HorizontalLine: '‚îÄ',
  Hscr: '‚Ñã',
  Hstrok: 'ƒ¶',
  HumpDownHump: '‚âé',
  HumpEqual: '‚âè',
  IEcy: '–ï',
  IJlig: 'ƒ≤',
  IOcy: '–Å',
  Iacut: '√ç',
  Iacute: '√ç',
  Icir: '√é',
  Icirc: '√é',
  Icy: '–ò',
  Idot: 'ƒ∞',
  Ifr: '‚Ñë',
  Igrav: '√å',
  Igrave: '√å',
  Im: '‚Ñë',
  Imacr: 'ƒ™',
  ImaginaryI: '‚Öà',
  Implies: '‚áí',
  Int: '‚à¨',
  Integral: '‚à´',
  Intersection: '‚ãÇ',
  InvisibleComma: '‚Å£',
  InvisibleTimes: '‚Å¢',
  Iogon: 'ƒÆ',
  Iopf: 'ùïÄ',
  Iota: 'Œô',
  Iscr: '‚Ñê',
  Itilde: 'ƒ®',
  Iukcy: '–Ü',
  Ium: '√è',
  Iuml: '√è',
  Jcirc: 'ƒ¥',
  Jcy: '–ô',
  Jfr: 'ùîç',
  Jopf: 'ùïÅ',
  Jscr: 'ùí•',
  Jsercy: '–à',
  Jukcy: '–Ñ',
  KHcy: '–•',
  KJcy: '–å',
  Kappa: 'Œö',
  Kcedil: 'ƒ∂',
  Kcy: '–ö',
  Kfr: 'ùîé',
  Kopf: 'ùïÇ',
  Kscr: 'ùí¶',
  LJcy: '–â',
  L: '<',
  LT: '<',
  Lacute: 'ƒπ',
  Lambda: 'Œõ',
  Lang: '‚ü™',
  Laplacetrf: '‚Ñí',
  Larr: '‚Üû',
  Lcaron: 'ƒΩ',
  Lcedil: 'ƒª',
  Lcy: '–õ',
  LeftAngleBracket: '‚ü®',
  LeftArrow: '‚Üê',
  LeftArrowBar: '‚á§',
  LeftArrowRightArrow: '‚áÜ',
  LeftCeiling: '‚åà',
  LeftDoubleBracket: '‚ü¶',
  LeftDownTeeVector: '‚•°',
  LeftDownVector: '‚áÉ',
  LeftDownVectorBar: '‚•ô',
  LeftFloor: '‚åä',
  LeftRightArrow: '‚Üî',
  LeftRightVector: '‚•é',
  LeftTee: '‚ä£',
  LeftTeeArrow: '‚Ü§',
  LeftTeeVector: '‚•ö',
  LeftTriangle: '‚ä≤',
  LeftTriangleBar: '‚ßè',
  LeftTriangleEqual: '‚ä¥',
  LeftUpDownVector: '‚•ë',
  LeftUpTeeVector: '‚•†',
  LeftUpVector: '‚Üø',
  LeftUpVectorBar: '‚•ò',
  LeftVector: '‚Üº',
  LeftVectorBar: '‚•í',
  Leftarrow: '‚áê',
  Leftrightarrow: '‚áî',
  LessEqualGreater: '‚ãö',
  LessFullEqual: '‚â¶',
  LessGreater: '‚â∂',
  LessLess: '‚™°',
  LessSlantEqual: '‚©Ω',
  LessTilde: '‚â≤',
  Lfr: 'ùîè',
  Ll: '‚ãò',
  Lleftarrow: '‚áö',
  Lmidot: 'ƒø',
  LongLeftArrow: '‚üµ',
  LongLeftRightArrow: '‚ü∑',
  LongRightArrow: '‚ü∂',
  Longleftarrow: '‚ü∏',
  Longleftrightarrow: '‚ü∫',
  Longrightarrow: '‚üπ',
  Lopf: 'ùïÉ',
  LowerLeftArrow: '‚Üô',
  LowerRightArrow: '‚Üò',
  Lscr: '‚Ñí',
  Lsh: '‚Ü∞',
  Lstrok: '≈Å',
  Lt: '‚â™',
  Map: '‚§Ö',
  Mcy: '–ú',
  MediumSpace: '‚Åü',
  Mellintrf: '‚Ñ≥',
  Mfr: 'ùîê',
  MinusPlus: '‚àì',
  Mopf: 'ùïÑ',
  Mscr: '‚Ñ≥',
  Mu: 'Œú',
  NJcy: '–ä',
  Nacute: '≈É',
  Ncaron: '≈á',
  Ncedil: '≈Ö',
  Ncy: '–ù',
  NegativeMediumSpace: '‚Äã',
  NegativeThickSpace: '‚Äã',
  NegativeThinSpace: '‚Äã',
  NegativeVeryThinSpace: '‚Äã',
  NestedGreaterGreater: '‚â´',
  NestedLessLess: '‚â™',
  NewLine: '\n',
  Nfr: 'ùîë',
  NoBreak: '‚Å†',
  NonBreakingSpace: '¬†',
  Nopf: '‚Ñï',
  Not: '‚´¨',
  NotCongruent: '‚â¢',
  NotCupCap: '‚â≠',
  NotDoubleVerticalBar: '‚à¶',
  NotElement: '‚àâ',
  NotEqual: '‚â†',
  NotEqualTilde: '‚âÇÃ∏',
  NotExists: '‚àÑ',
  NotGreater: '‚âØ',
  NotGreaterEqual: '‚â±',
  NotGreaterFullEqual: '‚âßÃ∏',
  NotGreaterGreater: '‚â´Ã∏',
  NotGreaterLess: '‚âπ',
  NotGreaterSlantEqual: '‚©æÃ∏',
  NotGreaterTilde: '‚âµ',
  NotHumpDownHump: '‚âéÃ∏',
  NotHumpEqual: '‚âèÃ∏',
  NotLeftTriangle: '‚ã™',
  NotLeftTriangleBar: '‚ßèÃ∏',
  NotLeftTriangleEqual: '‚ã¨',
  NotLess: '‚âÆ',
  NotLessEqual: '‚â∞',
  NotLessGreater: '‚â∏',
  NotLessLess: '‚â™Ã∏',
  NotLessSlantEqual: '‚©ΩÃ∏',
  NotLessTilde: '‚â¥',
  NotNestedGreaterGreater: '‚™¢Ã∏',
  NotNestedLessLess: '‚™°Ã∏',
  NotPrecedes: '‚äÄ',
  NotPrecedesEqual: '‚™ØÃ∏',
  NotPrecedesSlantEqual: '‚ã†',
  NotReverseElement: '‚àå',
  NotRightTriangle: '‚ã´',
  NotRightTriangleBar: '‚ßêÃ∏',
  NotRightTriangleEqual: '‚ã≠',
  NotSquareSubset: '‚äèÃ∏',
  NotSquareSubsetEqual: '‚ã¢',
  NotSquareSuperset: '‚äêÃ∏',
  NotSquareSupersetEqual: '‚ã£',
  NotSubset: '‚äÇ‚Éí',
  NotSubsetEqual: '‚äà',
  NotSucceeds: '‚äÅ',
  NotSucceedsEqual: '‚™∞Ã∏',
  NotSucceedsSlantEqual: '‚ã°',
  NotSucceedsTilde: '‚âøÃ∏',
  NotSuperset: '‚äÉ‚Éí',
  NotSupersetEqual: '‚äâ',
  NotTilde: '‚âÅ',
  NotTildeEqual: '‚âÑ',
  NotTildeFullEqual: '‚âá',
  NotTildeTilde: '‚ââ',
  NotVerticalBar: '‚à§',
  Nscr: 'ùí©',
  Ntild: '√ë',
  Ntilde: '√ë',
  Nu: 'Œù',
  OElig: '≈í',
  Oacut: '√ì',
  Oacute: '√ì',
  Ocir: '√î',
  Ocirc: '√î',
  Ocy: '–û',
  Odblac: '≈ê',
  Ofr: 'ùîí',
  Ograv: '√í',
  Ograve: '√í',
  Omacr: '≈å',
  Omega: 'Œ©',
  Omicron: 'Œü',
  Oopf: 'ùïÜ',
  OpenCurlyDoubleQuote: '‚Äú',
  OpenCurlyQuote: '‚Äò',
  Or: '‚©î',
  Oscr: 'ùí™',
  Oslas: '√ò',
  Oslash: '√ò',
  Otild: '√ï',
  Otilde: '√ï',
  Otimes: '‚®∑',
  Oum: '√ñ',
  Ouml: '√ñ',
  OverBar: '‚Äæ',
  OverBrace: '‚èû',
  OverBracket: '‚é¥',
  OverParenthesis: '‚èú',
  PartialD: '‚àÇ',
  Pcy: '–ü',
  Pfr: 'ùîì',
  Phi: 'Œ¶',
  Pi: 'Œ†',
  PlusMinus: '¬±',
  Poincareplane: '‚Ñå',
  Popf: '‚Ñô',
  Pr: '‚™ª',
  Precedes: '‚â∫',
  PrecedesEqual: '‚™Ø',
  PrecedesSlantEqual: '‚âº',
  PrecedesTilde: '‚âæ',
  Prime: '‚Ä≥',
  Product: '‚àè',
  Proportion: '‚à∑',
  Proportional: '‚àù',
  Pscr: 'ùí´',
  Psi: 'Œ®',
  QUO: '"',
  QUOT: '"',
  Qfr: 'ùîî',
  Qopf: '‚Ñö',
  Qscr: 'ùí¨',
  RBarr: '‚§ê',
  RE: '¬Æ',
  REG: '¬Æ',
  Racute: '≈î',
  Rang: '‚ü´',
  Rarr: '‚Ü†',
  Rarrtl: '‚§ñ',
  Rcaron: '≈ò',
  Rcedil: '≈ñ',
  Rcy: '–†',
  Re: '‚Ñú',
  ReverseElement: '‚àã',
  ReverseEquilibrium: '‚áã',
  ReverseUpEquilibrium: '‚•Ø',
  Rfr: '‚Ñú',
  Rho: 'Œ°',
  RightAngleBracket: '‚ü©',
  RightArrow: '‚Üí',
  RightArrowBar: '‚á•',
  RightArrowLeftArrow: '‚áÑ',
  RightCeiling: '‚åâ',
  RightDoubleBracket: '‚üß',
  RightDownTeeVector: '‚•ù',
  RightDownVector: '‚áÇ',
  RightDownVectorBar: '‚•ï',
  RightFloor: '‚åã',
  RightTee: '‚ä¢',
  RightTeeArrow: '‚Ü¶',
  RightTeeVector: '‚•õ',
  RightTriangle: '‚ä≥',
  RightTriangleBar: '‚ßê',
  RightTriangleEqual: '‚äµ',
  RightUpDownVector: '‚•è',
  RightUpTeeVector: '‚•ú',
  RightUpVector: '‚Üæ',
  RightUpVectorBar: '‚•î',
  RightVector: '‚áÄ',
  RightVectorBar: '‚•ì',
  Rightarrow: '‚áí',
  Ropf: '‚Ñù',
  RoundImplies: '‚•∞',
  Rrightarrow: '‚áõ',
  Rscr: '‚Ñõ',
  Rsh: '‚Ü±',
  RuleDelayed: '‚ß¥',
  SHCHcy: '–©',
  SHcy: '–®',
  SOFTcy: '–¨',
  Sacute: '≈ö',
  Sc: '‚™º',
  Scaron: '≈†',
  Scedil: '≈û',
  Scirc: '≈ú',
  Scy: '–°',
  Sfr: 'ùîñ',
  ShortDownArrow: '‚Üì',
  ShortLeftArrow: '‚Üê',
  ShortRightArrow: '‚Üí',
  ShortUpArrow: '‚Üë',
  Sigma: 'Œ£',
  SmallCircle: '‚àò',
  Sopf: 'ùïä',
  Sqrt: '‚àö',
  Square: '‚ñ°',
  SquareIntersection: '‚äì',
  SquareSubset: '‚äè',
  SquareSubsetEqual: '‚äë',
  SquareSuperset: '‚äê',
  SquareSupersetEqual: '‚äí',
  SquareUnion: '‚äî',
  Sscr: 'ùíÆ',
  Star: '‚ãÜ',
  Sub: '‚ãê',
  Subset: '‚ãê',
  SubsetEqual: '‚äÜ',
  Succeeds: '‚âª',
  SucceedsEqual: '‚™∞',
  SucceedsSlantEqual: '‚âΩ',
  SucceedsTilde: '‚âø',
  SuchThat: '‚àã',
  Sum: '‚àë',
  Sup: '‚ãë',
  Superset: '‚äÉ',
  SupersetEqual: '‚äá',
  Supset: '‚ãë',
  THOR: '√û',
  THORN: '√û',
  TRADE: '‚Ñ¢',
  TSHcy: '–ã',
  TScy: '–¶',
  Tab: '\t',
  Tau: 'Œ§',
  Tcaron: '≈§',
  Tcedil: '≈¢',
  Tcy: '–¢',
  Tfr: 'ùîó',
  Therefore: '‚à¥',
  Theta: 'Œò',
  ThickSpace: '‚Åü‚Ää',
  ThinSpace: '‚Äâ',
  Tilde: '‚àº',
  TildeEqual: '‚âÉ',
  TildeFullEqual: '‚âÖ',
  TildeTilde: '‚âà',
  Topf: 'ùïã',
  TripleDot: '‚Éõ',
  Tscr: 'ùíØ',
  Tstrok: '≈¶',
  Uacut: '√ö',
  Uacute: '√ö',
  Uarr: '‚Üü',
  Uarrocir: '‚•â',
  Ubrcy: '–é',
  Ubreve: '≈¨',
  Ucir: '√õ',
  Ucirc: '√õ',
  Ucy: '–£',
  Udblac: '≈∞',
  Ufr: 'ùîò',
  Ugrav: '√ô',
  Ugrave: '√ô',
  Umacr: '≈™',
  UnderBar: '_',
  UnderBrace: '‚èü',
  UnderBracket: '‚éµ',
  UnderParenthesis: '‚èù',
  Union: '‚ãÉ',
  UnionPlus: '‚äé',
  Uogon: '≈≤',
  Uopf: 'ùïå',
  UpArrow: '‚Üë',
  UpArrowBar: '‚§í',
  UpArrowDownArrow: '‚áÖ',
  UpDownArrow: '‚Üï',
  UpEquilibrium: '‚•Æ',
  UpTee: '‚ä•',
  UpTeeArrow: '‚Ü•',
  Uparrow: '‚áë',
  Updownarrow: '‚áï',
  UpperLeftArrow: '‚Üñ',
  UpperRightArrow: '‚Üó',
  Upsi: 'œí',
  Upsilon: 'Œ•',
  Uring: '≈Æ',
  Uscr: 'ùí∞',
  Utilde: '≈®',
  Uum: '√ú',
  Uuml: '√ú',
  VDash: '‚ä´',
  Vbar: '‚´´',
  Vcy: '–í',
  Vdash: '‚ä©',
  Vdashl: '‚´¶',
  Vee: '‚ãÅ',
  Verbar: '‚Äñ',
  Vert: '‚Äñ',
  VerticalBar: '‚à£',
  VerticalLine: '|',
  VerticalSeparator: '‚ùò',
  VerticalTilde: '‚âÄ',
  VeryThinSpace: '‚Ää',
  Vfr: 'ùîô',
  Vopf: 'ùïç',
  Vscr: 'ùí±',
  Vvdash: '‚ä™',
  Wcirc: '≈¥',
  Wedge: '‚ãÄ',
  Wfr: 'ùîö',
  Wopf: 'ùïé',
  Wscr: 'ùí≤',
  Xfr: 'ùîõ',
  Xi: 'Œû',
  Xopf: 'ùïè',
  Xscr: 'ùí≥',
  YAcy: '–Ø',
  YIcy: '–á',
  YUcy: '–Æ',
  Yacut: '√ù',
  Yacute: '√ù',
  Ycirc: '≈∂',
  Ycy: '–´',
  Yfr: 'ùîú',
  Yopf: 'ùïê',
  Yscr: 'ùí¥',
  Yuml: '≈∏',
  ZHcy: '–ñ',
  Zacute: '≈π',
  Zcaron: '≈Ω',
  Zcy: '–ó',
  Zdot: '≈ª',
  ZeroWidthSpace: '‚Äã',
  Zeta: 'Œñ',
  Zfr: '‚Ñ®',
  Zopf: '‚Ñ§',
  Zscr: 'ùíµ',
  aacut: '√°',
  aacute: '√°',
  abreve: 'ƒÉ',
  ac: '‚àæ',
  acE: '‚àæÃ≥',
  acd: '‚àø',
  acir: '√¢',
  acirc: '√¢',
  acut: '¬¥',
  acute: '¬¥',
  acy: '–∞',
  aeli: '√¶',
  aelig: '√¶',
  af: '‚Å°',
  afr: 'ùîû',
  agrav: '√†',
  agrave: '√†',
  alefsym: '‚Ñµ',
  aleph: '‚Ñµ',
  alpha: 'Œ±',
  amacr: 'ƒÅ',
  amalg: '‚®ø',
  am: '&',
  amp: '&',
  and: '‚àß',
  andand: '‚©ï',
  andd: '‚©ú',
  andslope: '‚©ò',
  andv: '‚©ö',
  ang: '‚à†',
  ange: '‚¶§',
  angle: '‚à†',
  angmsd: '‚à°',
  angmsdaa: '‚¶®',
  angmsdab: '‚¶©',
  angmsdac: '‚¶™',
  angmsdad: '‚¶´',
  angmsdae: '‚¶¨',
  angmsdaf: '‚¶≠',
  angmsdag: '‚¶Æ',
  angmsdah: '‚¶Ø',
  angrt: '‚àü',
  angrtvb: '‚äæ',
  angrtvbd: '‚¶ù',
  angsph: '‚à¢',
  angst: '√Ö',
  angzarr: '‚çº',
  aogon: 'ƒÖ',
  aopf: 'ùïí',
  ap: '‚âà',
  apE: '‚©∞',
  apacir: '‚©Ø',
  ape: '‚âä',
  apid: '‚âã',
  apos: "'",
  approx: '‚âà',
  approxeq: '‚âä',
  arin: '√•',
  aring: '√•',
  ascr: 'ùí∂',
  ast: '*',
  asymp: '‚âà',
  asympeq: '‚âç',
  atild: '√£',
  atilde: '√£',
  aum: '√§',
  auml: '√§',
  awconint: '‚à≥',
  awint: '‚®ë',
  bNot: '‚´≠',
  backcong: '‚âå',
  backepsilon: 'œ∂',
  backprime: '‚Äµ',
  backsim: '‚àΩ',
  backsimeq: '‚ãç',
  barvee: '‚äΩ',
  barwed: '‚åÖ',
  barwedge: '‚åÖ',
  bbrk: '‚éµ',
  bbrktbrk: '‚é∂',
  bcong: '‚âå',
  bcy: '–±',
  bdquo: '‚Äû',
  becaus: '‚àµ',
  because: '‚àµ',
  bemptyv: '‚¶∞',
  bepsi: 'œ∂',
  bernou: '‚Ñ¨',
  beta: 'Œ≤',
  beth: '‚Ñ∂',
  between: '‚â¨',
  bfr: 'ùîü',
  bigcap: '‚ãÇ',
  bigcirc: '‚óØ',
  bigcup: '‚ãÉ',
  bigodot: '‚®Ä',
  bigoplus: '‚®Å',
  bigotimes: '‚®Ç',
  bigsqcup: '‚®Ü',
  bigstar: '‚òÖ',
  bigtriangledown: '‚ñΩ',
  bigtriangleup: '‚ñ≥',
  biguplus: '‚®Ñ',
  bigvee: '‚ãÅ',
  bigwedge: '‚ãÄ',
  bkarow: '‚§ç',
  blacklozenge: '‚ß´',
  blacksquare: '‚ñ™',
  blacktriangle: '‚ñ¥',
  blacktriangledown: '‚ñæ',
  blacktriangleleft: '‚óÇ',
  blacktriangleright: '‚ñ∏',
  blank: '‚ê£',
  blk12: '‚ñí',
  blk14: '‚ñë',
  blk34: '‚ñì',
  block: '‚ñà',
  bne: '=‚É•',
  bnequiv: '‚â°‚É•',
  bnot: '‚åê',
  bopf: 'ùïì',
  bot: '‚ä•',
  bottom: '‚ä•',
  bowtie: '‚ãà',
  boxDL: '‚ïó',
  boxDR: '‚ïî',
  boxDl: '‚ïñ',
  boxDr: '‚ïì',
  boxH: '‚ïê',
  boxHD: '‚ï¶',
  boxHU: '‚ï©',
  boxHd: '‚ï§',
  boxHu: '‚ïß',
  boxUL: '‚ïù',
  boxUR: '‚ïö',
  boxUl: '‚ïú',
  boxUr: '‚ïô',
  boxV: '‚ïë',
  boxVH: '‚ï¨',
  boxVL: '‚ï£',
  boxVR: '‚ï†',
  boxVh: '‚ï´',
  boxVl: '‚ï¢',
  boxVr: '‚ïü',
  boxbox: '‚ßâ',
  boxdL: '‚ïï',
  boxdR: '‚ïí',
  boxdl: '‚îê',
  boxdr: '‚îå',
  boxh: '‚îÄ',
  boxhD: '‚ï•',
  boxhU: '‚ï®',
  boxhd: '‚î¨',
  boxhu: '‚î¥',
  boxminus: '‚äü',
  boxplus: '‚äû',
  boxtimes: '‚ä†',
  boxuL: '‚ïõ',
  boxuR: '‚ïò',
  boxul: '‚îò',
  boxur: '‚îî',
  boxv: '‚îÇ',
  boxvH: '‚ï™',
  boxvL: '‚ï°',
  boxvR: '‚ïû',
  boxvh: '‚îº',
  boxvl: '‚î§',
  boxvr: '‚îú',
  bprime: '‚Äµ',
  breve: 'Àò',
  brvba: '¬¶',
  brvbar: '¬¶',
  bscr: 'ùí∑',
  bsemi: '‚Åè',
  bsim: '‚àΩ',
  bsime: '‚ãç',
  bsol: '\\',
  bsolb: '‚ßÖ',
  bsolhsub: '‚üà',
  bull: '‚Ä¢',
  bullet: '‚Ä¢',
  bump: '‚âé',
  bumpE: '‚™Æ',
  bumpe: '‚âè',
  bumpeq: '‚âè',
  cacute: 'ƒá',
  cap: '‚à©',
  capand: '‚©Ñ',
  capbrcup: '‚©â',
  capcap: '‚©ã',
  capcup: '‚©á',
  capdot: '‚©Ä',
  caps: '‚à©Ô∏Ä',
  caret: '‚ÅÅ',
  caron: 'Àá',
  ccaps: '‚©ç',
  ccaron: 'ƒç',
  ccedi: '√ß',
  ccedil: '√ß',
  ccirc: 'ƒâ',
  ccups: '‚©å',
  ccupssm: '‚©ê',
  cdot: 'ƒã',
  cedi: '¬∏',
  cedil: '¬∏',
  cemptyv: '‚¶≤',
  cen: '¬¢',
  cent: '¬¢',
  centerdot: '¬∑',
  cfr: 'ùî†',
  chcy: '—á',
  check: '‚úì',
  checkmark: '‚úì',
  chi: 'œá',
  cir: '‚óã',
  cirE: '‚ßÉ',
  circ: 'ÀÜ',
  circeq: '‚âó',
  circlearrowleft: '‚Ü∫',
  circlearrowright: '‚Üª',
  circledR: '¬Æ',
  circledS: '‚ìà',
  circledast: '‚äõ',
  circledcirc: '‚äö',
  circleddash: '‚äù',
  cire: '‚âó',
  cirfnint: '‚®ê',
  cirmid: '‚´Ø',
  cirscir: '‚ßÇ',
  clubs: '‚ô£',
  clubsuit: '‚ô£',
  colon: ':',
  colone: '‚âî',
  coloneq: '‚âî',
  comma: ',',
  commat: '@',
  comp: '‚àÅ',
  compfn: '‚àò',
  complement: '‚àÅ',
  complexes: '‚ÑÇ',
  cong: '‚âÖ',
  congdot: '‚©≠',
  conint: '‚àÆ',
  copf: 'ùïî',
  coprod: '‚àê',
  cop: '¬©',
  copy: '¬©',
  copysr: '‚Ñó',
  crarr: '‚Üµ',
  cross: '‚úó',
  cscr: 'ùí∏',
  csub: '‚´è',
  csube: '‚´ë',
  csup: '‚´ê',
  csupe: '‚´í',
  ctdot: '‚ãØ',
  cudarrl: '‚§∏',
  cudarrr: '‚§µ',
  cuepr: '‚ãû',
  cuesc: '‚ãü',
  cularr: '‚Ü∂',
  cularrp: '‚§Ω',
  cup: '‚à™',
  cupbrcap: '‚©à',
  cupcap: '‚©Ü',
  cupcup: '‚©ä',
  cupdot: '‚äç',
  cupor: '‚©Ö',
  cups: '‚à™Ô∏Ä',
  curarr: '‚Ü∑',
  curarrm: '‚§º',
  curlyeqprec: '‚ãû',
  curlyeqsucc: '‚ãü',
  curlyvee: '‚ãé',
  curlywedge: '‚ãè',
  curre: '¬§',
  curren: '¬§',
  curvearrowleft: '‚Ü∂',
  curvearrowright: '‚Ü∑',
  cuvee: '‚ãé',
  cuwed: '‚ãè',
  cwconint: '‚à≤',
  cwint: '‚à±',
  cylcty: '‚å≠',
  dArr: '‚áì',
  dHar: '‚••',
  dagger: '‚Ä†',
  daleth: '‚Ñ∏',
  darr: '‚Üì',
  dash: '‚Äê',
  dashv: '‚ä£',
  dbkarow: '‚§è',
  dblac: 'Àù',
  dcaron: 'ƒè',
  dcy: '–¥',
  dd: '‚ÖÜ',
  ddagger: '‚Ä°',
  ddarr: '‚áä',
  ddotseq: '‚©∑',
  de: '¬∞',
  deg: '¬∞',
  delta: 'Œ¥',
  demptyv: '‚¶±',
  dfisht: '‚•ø',
  dfr: 'ùî°',
  dharl: '‚áÉ',
  dharr: '‚áÇ',
  diam: '‚ãÑ',
  diamond: '‚ãÑ',
  diamondsuit: '‚ô¶',
  diams: '‚ô¶',
  die: '¬®',
  digamma: 'œù',
  disin: '‚ã≤',
  div: '√∑',
  divid: '√∑',
  divide: '√∑',
  divideontimes: '‚ãá',
  divonx: '‚ãá',
  djcy: '—í',
  dlcorn: '‚åû',
  dlcrop: '‚åç',
  dollar: '$',
  dopf: 'ùïï',
  dot: 'Àô',
  doteq: '‚âê',
  doteqdot: '‚âë',
  dotminus: '‚à∏',
  dotplus: '‚àî',
  dotsquare: '‚ä°',
  doublebarwedge: '‚åÜ',
  downarrow: '‚Üì',
  downdownarrows: '‚áä',
  downharpoonleft: '‚áÉ',
  downharpoonright: '‚áÇ',
  drbkarow: '‚§ê',
  drcorn: '‚åü',
  drcrop: '‚åå',
  dscr: 'ùíπ',
  dscy: '—ï',
  dsol: '‚ß∂',
  dstrok: 'ƒë',
  dtdot: '‚ã±',
  dtri: '‚ñø',
  dtrif: '‚ñæ',
  duarr: '‚áµ',
  duhar: '‚•Ø',
  dwangle: '‚¶¶',
  dzcy: '—ü',
  dzigrarr: '‚üø',
  eDDot: '‚©∑',
  eDot: '‚âë',
  eacut: '√©',
  eacute: '√©',
  easter: '‚©Æ',
  ecaron: 'ƒõ',
  ecir: '√™',
  ecirc: '√™',
  ecolon: '‚âï',
  ecy: '—ç',
  edot: 'ƒó',
  ee: '‚Öá',
  efDot: '‚âí',
  efr: 'ùî¢',
  eg: '‚™ö',
  egrav: '√®',
  egrave: '√®',
  egs: '‚™ñ',
  egsdot: '‚™ò',
  el: '‚™ô',
  elinters: '‚èß',
  ell: '‚Ñì',
  els: '‚™ï',
  elsdot: '‚™ó',
  emacr: 'ƒì',
  empty: '‚àÖ',
  emptyset: '‚àÖ',
  emptyv: '‚àÖ',
  emsp13: '‚ÄÑ',
  emsp14: '‚ÄÖ',
  emsp: '‚ÄÉ',
  eng: '≈ã',
  ensp: '‚ÄÇ',
  eogon: 'ƒô',
  eopf: 'ùïñ',
  epar: '‚ãï',
  eparsl: '‚ß£',
  eplus: '‚©±',
  epsi: 'Œµ',
  epsilon: 'Œµ',
  epsiv: 'œµ',
  eqcirc: '‚âñ',
  eqcolon: '‚âï',
  eqsim: '‚âÇ',
  eqslantgtr: '‚™ñ',
  eqslantless: '‚™ï',
  equals: '=',
  equest: '‚âü',
  equiv: '‚â°',
  equivDD: '‚©∏',
  eqvparsl: '‚ß•',
  erDot: '‚âì',
  erarr: '‚•±',
  escr: '‚ÑØ',
  esdot: '‚âê',
  esim: '‚âÇ',
  eta: 'Œ∑',
  et: '√∞',
  eth: '√∞',
  eum: '√´',
  euml: '√´',
  euro: '‚Ç¨',
  excl: '!',
  exist: '‚àÉ',
  expectation: '‚Ñ∞',
  exponentiale: '‚Öá',
  fallingdotseq: '‚âí',
  fcy: '—Ñ',
  female: '‚ôÄ',
  ffilig: 'Ô¨É',
  fflig: 'Ô¨Ä',
  ffllig: 'Ô¨Ñ',
  ffr: 'ùî£',
  filig: 'Ô¨Å',
  fjlig: 'fj',
  flat: '‚ô≠',
  fllig: 'Ô¨Ç',
  fltns: '‚ñ±',
  fnof: '∆í',
  fopf: 'ùïó',
  forall: '‚àÄ',
  fork: '‚ãî',
  forkv: '‚´ô',
  fpartint: '‚®ç',
  frac1: '¬º',
  frac12: '¬Ω',
  frac13: '‚Öì',
  frac14: '¬º',
  frac15: '‚Öï',
  frac16: '‚Öô',
  frac18: '‚Öõ',
  frac23: '‚Öî',
  frac25: '‚Öñ',
  frac3: '¬æ',
  frac34: '¬æ',
  frac35: '‚Öó',
  frac38: '‚Öú',
  frac45: '‚Öò',
  frac56: '‚Öö',
  frac58: '‚Öù',
  frac78: '‚Öû',
  frasl: '‚ÅÑ',
  frown: '‚å¢',
  fscr: 'ùíª',
  gE: '‚âß',
  gEl: '‚™å',
  gacute: '«µ',
  gamma: 'Œ≥',
  gammad: 'œù',
  gap: '‚™Ü',
  gbreve: 'ƒü',
  gcirc: 'ƒù',
  gcy: '–≥',
  gdot: 'ƒ°',
  ge: '‚â•',
  gel: '‚ãõ',
  geq: '‚â•',
  geqq: '‚âß',
  geqslant: '‚©æ',
  ges: '‚©æ',
  gescc: '‚™©',
  gesdot: '‚™Ä',
  gesdoto: '‚™Ç',
  gesdotol: '‚™Ñ',
  gesl: '‚ãõÔ∏Ä',
  gesles: '‚™î',
  gfr: 'ùî§',
  gg: '‚â´',
  ggg: '‚ãô',
  gimel: '‚Ñ∑',
  gjcy: '—ì',
  gl: '‚â∑',
  glE: '‚™í',
  gla: '‚™•',
  glj: '‚™§',
  gnE: '‚â©',
  gnap: '‚™ä',
  gnapprox: '‚™ä',
  gne: '‚™à',
  gneq: '‚™à',
  gneqq: '‚â©',
  gnsim: '‚ãß',
  gopf: 'ùïò',
  grave: '`',
  gscr: '‚Ñä',
  gsim: '‚â≥',
  gsime: '‚™é',
  gsiml: '‚™ê',
  g: '>',
  gt: '>',
  gtcc: '‚™ß',
  gtcir: '‚©∫',
  gtdot: '‚ãó',
  gtlPar: '‚¶ï',
  gtquest: '‚©º',
  gtrapprox: '‚™Ü',
  gtrarr: '‚•∏',
  gtrdot: '‚ãó',
  gtreqless: '‚ãõ',
  gtreqqless: '‚™å',
  gtrless: '‚â∑',
  gtrsim: '‚â≥',
  gvertneqq: '‚â©Ô∏Ä',
  gvnE: '‚â©Ô∏Ä',
  hArr: '‚áî',
  hairsp: '‚Ää',
  half: '¬Ω',
  hamilt: '‚Ñã',
  hardcy: '—ä',
  harr: '‚Üî',
  harrcir: '‚•à',
  harrw: '‚Ü≠',
  hbar: '‚Ñè',
  hcirc: 'ƒ•',
  hearts: '‚ô•',
  heartsuit: '‚ô•',
  hellip: '‚Ä¶',
  hercon: '‚äπ',
  hfr: 'ùî•',
  hksearow: '‚§•',
  hkswarow: '‚§¶',
  hoarr: '‚áø',
  homtht: '‚àª',
  hookleftarrow: '‚Ü©',
  hookrightarrow: '‚Ü™',
  hopf: 'ùïô',
  horbar: '‚Äï',
  hscr: 'ùíΩ',
  hslash: '‚Ñè',
  hstrok: 'ƒß',
  hybull: '‚ÅÉ',
  hyphen: '‚Äê',
  iacut: '√≠',
  iacute: '√≠',
  ic: '‚Å£',
  icir: '√Æ',
  icirc: '√Æ',
  icy: '–∏',
  iecy: '–µ',
  iexc: '¬°',
  iexcl: '¬°',
  iff: '‚áî',
  ifr: 'ùî¶',
  igrav: '√¨',
  igrave: '√¨',
  ii: '‚Öà',
  iiiint: '‚®å',
  iiint: '‚à≠',
  iinfin: '‚ßú',
  iiota: '‚Ñ©',
  ijlig: 'ƒ≥',
  imacr: 'ƒ´',
  image: '‚Ñë',
  imagline: '‚Ñê',
  imagpart: '‚Ñë',
  imath: 'ƒ±',
  imof: '‚ä∑',
  imped: '∆µ',
  in: '‚àà',
  incare: '‚ÑÖ',
  infin: '‚àû',
  infintie: '‚ßù',
  inodot: 'ƒ±',
  int: '‚à´',
  intcal: '‚ä∫',
  integers: '‚Ñ§',
  intercal: '‚ä∫',
  intlarhk: '‚®ó',
  intprod: '‚®º',
  iocy: '—ë',
  iogon: 'ƒØ',
  iopf: 'ùïö',
  iota: 'Œπ',
  iprod: '‚®º',
  iques: '¬ø',
  iquest: '¬ø',
  iscr: 'ùíæ',
  isin: '‚àà',
  isinE: '‚ãπ',
  isindot: '‚ãµ',
  isins: '‚ã¥',
  isinsv: '‚ã≥',
  isinv: '‚àà',
  it: '‚Å¢',
  itilde: 'ƒ©',
  iukcy: '—ñ',
  ium: '√Ø',
  iuml: '√Ø',
  jcirc: 'ƒµ',
  jcy: '–π',
  jfr: 'ùîß',
  jmath: '»∑',
  jopf: 'ùïõ',
  jscr: 'ùíø',
  jsercy: '—ò',
  jukcy: '—î',
  kappa: 'Œ∫',
  kappav: 'œ∞',
  kcedil: 'ƒ∑',
  kcy: '–∫',
  kfr: 'ùî®',
  kgreen: 'ƒ∏',
  khcy: '—Ö',
  kjcy: '—ú',
  kopf: 'ùïú',
  kscr: 'ùìÄ',
  lAarr: '‚áö',
  lArr: '‚áê',
  lAtail: '‚§õ',
  lBarr: '‚§é',
  lE: '‚â¶',
  lEg: '‚™ã',
  lHar: '‚•¢',
  lacute: 'ƒ∫',
  laemptyv: '‚¶¥',
  lagran: '‚Ñí',
  lambda: 'Œª',
  lang: '‚ü®',
  langd: '‚¶ë',
  langle: '‚ü®',
  lap: '‚™Ö',
  laqu: '¬´',
  laquo: '¬´',
  larr: '‚Üê',
  larrb: '‚á§',
  larrbfs: '‚§ü',
  larrfs: '‚§ù',
  larrhk: '‚Ü©',
  larrlp: '‚Ü´',
  larrpl: '‚§π',
  larrsim: '‚•≥',
  larrtl: '‚Ü¢',
  lat: '‚™´',
  latail: '‚§ô',
  late: '‚™≠',
  lates: '‚™≠Ô∏Ä',
  lbarr: '‚§å',
  lbbrk: '‚ù≤',
  lbrace: '{',
  lbrack: '[',
  lbrke: '‚¶ã',
  lbrksld: '‚¶è',
  lbrkslu: '‚¶ç',
  lcaron: 'ƒæ',
  lcedil: 'ƒº',
  lceil: '‚åà',
  lcub: '{',
  lcy: '–ª',
  ldca: '‚§∂',
  ldquo: '‚Äú',
  ldquor: '‚Äû',
  ldrdhar: '‚•ß',
  ldrushar: '‚•ã',
  ldsh: '‚Ü≤',
  le: '‚â§',
  leftarrow: '‚Üê',
  leftarrowtail: '‚Ü¢',
  leftharpoondown: '‚ÜΩ',
  leftharpoonup: '‚Üº',
  leftleftarrows: '‚áá',
  leftrightarrow: '‚Üî',
  leftrightarrows: '‚áÜ',
  leftrightharpoons: '‚áã',
  leftrightsquigarrow: '‚Ü≠',
  leftthreetimes: '‚ãã',
  leg: '‚ãö',
  leq: '‚â§',
  leqq: '‚â¶',
  leqslant: '‚©Ω',
  les: '‚©Ω',
  lescc: '‚™®',
  lesdot: '‚©ø',
  lesdoto: '‚™Å',
  lesdotor: '‚™É',
  lesg: '‚ãöÔ∏Ä',
  lesges: '‚™ì',
  lessapprox: '‚™Ö',
  lessdot: '‚ãñ',
  lesseqgtr: '‚ãö',
  lesseqqgtr: '‚™ã',
  lessgtr: '‚â∂',
  lesssim: '‚â≤',
  lfisht: '‚•º',
  lfloor: '‚åä',
  lfr: 'ùî©',
  lg: '‚â∂',
  lgE: '‚™ë',
  lhard: '‚ÜΩ',
  lharu: '‚Üº',
  lharul: '‚•™',
  lhblk: '‚ñÑ',
  ljcy: '—ô',
  ll: '‚â™',
  llarr: '‚áá',
  llcorner: '‚åû',
  llhard: '‚•´',
  lltri: '‚ó∫',
  lmidot: '≈Ä',
  lmoust: '‚é∞',
  lmoustache: '‚é∞',
  lnE: '‚â®',
  lnap: '‚™â',
  lnapprox: '‚™â',
  lne: '‚™á',
  lneq: '‚™á',
  lneqq: '‚â®',
  lnsim: '‚ã¶',
  loang: '‚ü¨',
  loarr: '‚áΩ',
  lobrk: '‚ü¶',
  longleftarrow: '‚üµ',
  longleftrightarrow: '‚ü∑',
  longmapsto: '‚üº',
  longrightarrow: '‚ü∂',
  looparrowleft: '‚Ü´',
  looparrowright: '‚Ü¨',
  lopar: '‚¶Ö',
  lopf: 'ùïù',
  loplus: '‚®≠',
  lotimes: '‚®¥',
  lowast: '‚àó',
  lowbar: '_',
  loz: '‚óä',
  lozenge: '‚óä',
  lozf: '‚ß´',
  lpar: '(',
  lparlt: '‚¶ì',
  lrarr: '‚áÜ',
  lrcorner: '‚åü',
  lrhar: '‚áã',
  lrhard: '‚•≠',
  lrm: '‚Äé',
  lrtri: '‚äø',
  lsaquo: '‚Äπ',
  lscr: 'ùìÅ',
  lsh: '‚Ü∞',
  lsim: '‚â≤',
  lsime: '‚™ç',
  lsimg: '‚™è',
  lsqb: '[',
  lsquo: '‚Äò',
  lsquor: '‚Äö',
  lstrok: '≈Ç',
  l: '<',
  lt: '<',
  ltcc: '‚™¶',
  ltcir: '‚©π',
  ltdot: '‚ãñ',
  lthree: '‚ãã',
  ltimes: '‚ãâ',
  ltlarr: '‚•∂',
  ltquest: '‚©ª',
  ltrPar: '‚¶ñ',
  ltri: '‚óÉ',
  ltrie: '‚ä¥',
  ltrif: '‚óÇ',
  lurdshar: '‚•ä',
  luruhar: '‚•¶',
  lvertneqq: '‚â®Ô∏Ä',
  lvnE: '‚â®Ô∏Ä',
  mDDot: '‚à∫',
  mac: '¬Ø',
  macr: '¬Ø',
  male: '‚ôÇ',
  malt: '‚ú†',
  maltese: '‚ú†',
  map: '‚Ü¶',
  mapsto: '‚Ü¶',
  mapstodown: '‚Üß',
  mapstoleft: '‚Ü§',
  mapstoup: '‚Ü•',
  marker: '‚ñÆ',
  mcomma: '‚®©',
  mcy: '–º',
  mdash: '‚Äî',
  measuredangle: '‚à°',
  mfr: 'ùî™',
  mho: '‚Ñß',
  micr: '¬µ',
  micro: '¬µ',
  mid: '‚à£',
  midast: '*',
  midcir: '‚´∞',
  middo: '¬∑',
  middot: '¬∑',
  minus: '‚àí',
  minusb: '‚äü',
  minusd: '‚à∏',
  minusdu: '‚®™',
  mlcp: '‚´õ',
  mldr: '‚Ä¶',
  mnplus: '‚àì',
  models: '‚äß',
  mopf: 'ùïû',
  mp: '‚àì',
  mscr: 'ùìÇ',
  mstpos: '‚àæ',
  mu: 'Œº',
  multimap: '‚ä∏',
  mumap: '‚ä∏',
  nGg: '‚ãôÃ∏',
  nGt: '‚â´‚Éí',
  nGtv: '‚â´Ã∏',
  nLeftarrow: '‚áç',
  nLeftrightarrow: '‚áé',
  nLl: '‚ãòÃ∏',
  nLt: '‚â™‚Éí',
  nLtv: '‚â™Ã∏',
  nRightarrow: '‚áè',
  nVDash: '‚äØ',
  nVdash: '‚äÆ',
  nabla: '‚àá',
  nacute: '≈Ñ',
  nang: '‚à†‚Éí',
  nap: '‚ââ',
  napE: '‚©∞Ã∏',
  napid: '‚âãÃ∏',
  napos: '≈â',
  napprox: '‚ââ',
  natur: '‚ôÆ',
  natural: '‚ôÆ',
  naturals: '‚Ñï',
  nbs: '¬†',
  nbsp: '¬†',
  nbump: '‚âéÃ∏',
  nbumpe: '‚âèÃ∏',
  ncap: '‚©É',
  ncaron: '≈à',
  ncedil: '≈Ü',
  ncong: '‚âá',
  ncongdot: '‚©≠Ã∏',
  ncup: '‚©Ç',
  ncy: '–Ω',
  ndash: '‚Äì',
  ne: '‚â†',
  neArr: '‚áó',
  nearhk: '‚§§',
  nearr: '‚Üó',
  nearrow: '‚Üó',
  nedot: '‚âêÃ∏',
  nequiv: '‚â¢',
  nesear: '‚§®',
  nesim: '‚âÇÃ∏',
  nexist: '‚àÑ',
  nexists: '‚àÑ',
  nfr: 'ùî´',
  ngE: '‚âßÃ∏',
  nge: '‚â±',
  ngeq: '‚â±',
  ngeqq: '‚âßÃ∏',
  ngeqslant: '‚©æÃ∏',
  nges: '‚©æÃ∏',
  ngsim: '‚âµ',
  ngt: '‚âØ',
  ngtr: '‚âØ',
  nhArr: '‚áé',
  nharr: '‚ÜÆ',
  nhpar: '‚´≤',
  ni: '‚àã',
  nis: '‚ãº',
  nisd: '‚ã∫',
  niv: '‚àã',
  njcy: '—ö',
  nlArr: '‚áç',
  nlE: '‚â¶Ã∏',
  nlarr: '‚Üö',
  nldr: '‚Ä•',
  nle: '‚â∞',
  nleftarrow: '‚Üö',
  nleftrightarrow: '‚ÜÆ',
  nleq: '‚â∞',
  nleqq: '‚â¶Ã∏',
  nleqslant: '‚©ΩÃ∏',
  nles: '‚©ΩÃ∏',
  nless: '‚âÆ',
  nlsim: '‚â¥',
  nlt: '‚âÆ',
  nltri: '‚ã™',
  nltrie: '‚ã¨',
  nmid: '‚à§',
  nopf: 'ùïü',
  no: '¬¨',
  not: '¬¨',
  notin: '‚àâ',
  notinE: '‚ãπÃ∏',
  notindot: '‚ãµÃ∏',
  notinva: '‚àâ',
  notinvb: '‚ã∑',
  notinvc: '‚ã∂',
  notni: '‚àå',
  notniva: '‚àå',
  notnivb: '‚ãæ',
  notnivc: '‚ãΩ',
  npar: '‚à¶',
  nparallel: '‚à¶',
  nparsl: '‚´Ω‚É•',
  npart: '‚àÇÃ∏',
  npolint: '‚®î',
  npr: '‚äÄ',
  nprcue: '‚ã†',
  npre: '‚™ØÃ∏',
  nprec: '‚äÄ',
  npreceq: '‚™ØÃ∏',
  nrArr: '‚áè',
  nrarr: '‚Üõ',
  nrarrc: '‚§≥Ã∏',
  nrarrw: '‚ÜùÃ∏',
  nrightarrow: '‚Üõ',
  nrtri: '‚ã´',
  nrtrie: '‚ã≠',
  nsc: '‚äÅ',
  nsccue: '‚ã°',
  nsce: '‚™∞Ã∏',
  nscr: 'ùìÉ',
  nshortmid: '‚à§',
  nshortparallel: '‚à¶',
  nsim: '‚âÅ',
  nsime: '‚âÑ',
  nsimeq: '‚âÑ',
  nsmid: '‚à§',
  nspar: '‚à¶',
  nsqsube: '‚ã¢',
  nsqsupe: '‚ã£',
  nsub: '‚äÑ',
  nsubE: '‚´ÖÃ∏',
  nsube: '‚äà',
  nsubset: '‚äÇ‚Éí',
  nsubseteq: '‚äà',
  nsubseteqq: '‚´ÖÃ∏',
  nsucc: '‚äÅ',
  nsucceq: '‚™∞Ã∏',
  nsup: '‚äÖ',
  nsupE: '‚´ÜÃ∏',
  nsupe: '‚äâ',
  nsupset: '‚äÉ‚Éí',
  nsupseteq: '‚äâ',
  nsupseteqq: '‚´ÜÃ∏',
  ntgl: '‚âπ',
  ntild: '√±',
  ntilde: '√±',
  ntlg: '‚â∏',
  ntriangleleft: '‚ã™',
  ntrianglelefteq: '‚ã¨',
  ntriangleright: '‚ã´',
  ntrianglerighteq: '‚ã≠',
  nu: 'ŒΩ',
  num: '#',
  numero: '‚Ññ',
  numsp: '‚Äá',
  nvDash: '‚ä≠',
  nvHarr: '‚§Ñ',
  nvap: '‚âç‚Éí',
  nvdash: '‚ä¨',
  nvge: '‚â•‚Éí',
  nvgt: '>‚Éí',
  nvinfin: '‚ßû',
  nvlArr: '‚§Ç',
  nvle: '‚â§‚Éí',
  nvlt: '<‚Éí',
  nvltrie: '‚ä¥‚Éí',
  nvrArr: '‚§É',
  nvrtrie: '‚äµ‚Éí',
  nvsim: '‚àº‚Éí',
  nwArr: '‚áñ',
  nwarhk: '‚§£',
  nwarr: '‚Üñ',
  nwarrow: '‚Üñ',
  nwnear: '‚§ß',
  oS: '‚ìà',
  oacut: '√≥',
  oacute: '√≥',
  oast: '‚äõ',
  ocir: '√¥',
  ocirc: '√¥',
  ocy: '–æ',
  odash: '‚äù',
  odblac: '≈ë',
  odiv: '‚®∏',
  odot: '‚äô',
  odsold: '‚¶º',
  oelig: '≈ì',
  ofcir: '‚¶ø',
  ofr: 'ùî¨',
  ogon: 'Àõ',
  ograv: '√≤',
  ograve: '√≤',
  ogt: '‚ßÅ',
  ohbar: '‚¶µ',
  ohm: 'Œ©',
  oint: '‚àÆ',
  olarr: '‚Ü∫',
  olcir: '‚¶æ',
  olcross: '‚¶ª',
  oline: '‚Äæ',
  olt: '‚ßÄ',
  omacr: '≈ç',
  omega: 'œâ',
  omicron: 'Œø',
  omid: '‚¶∂',
  ominus: '‚äñ',
  oopf: 'ùï†',
  opar: '‚¶∑',
  operp: '‚¶π',
  oplus: '‚äï',
  or: '‚à®',
  orarr: '‚Üª',
  ord: '¬∫',
  order: '‚Ñ¥',
  orderof: '‚Ñ¥',
  ordf: '¬™',
  ordm: '¬∫',
  origof: '‚ä∂',
  oror: '‚©ñ',
  orslope: '‚©ó',
  orv: '‚©õ',
  oscr: '‚Ñ¥',
  oslas: '√∏',
  oslash: '√∏',
  osol: '‚äò',
  otild: '√µ',
  otilde: '√µ',
  otimes: '‚äó',
  otimesas: '‚®∂',
  oum: '√∂',
  ouml: '√∂',
  ovbar: '‚åΩ',
  par: '¬∂',
  para: '¬∂',
  parallel: '‚à•',
  parsim: '‚´≥',
  parsl: '‚´Ω',
  part: '‚àÇ',
  pcy: '–ø',
  percnt: '%',
  period: '.',
  permil: '‚Ä∞',
  perp: '‚ä•',
  pertenk: '‚Ä±',
  pfr: 'ùî≠',
  phi: 'œÜ',
  phiv: 'œï',
  phmmat: '‚Ñ≥',
  phone: '‚òé',
  pi: 'œÄ',
  pitchfork: '‚ãî',
  piv: 'œñ',
  planck: '‚Ñè',
  planckh: '‚Ñé',
  plankv: '‚Ñè',
  plus: '+',
  plusacir: '‚®£',
  plusb: '‚äû',
  pluscir: '‚®¢',
  plusdo: '‚àî',
  plusdu: '‚®•',
  pluse: '‚©≤',
  plusm: '¬±',
  plusmn: '¬±',
  plussim: '‚®¶',
  plustwo: '‚®ß',
  pm: '¬±',
  pointint: '‚®ï',
  popf: 'ùï°',
  poun: '¬£',
  pound: '¬£',
  pr: '‚â∫',
  prE: '‚™≥',
  prap: '‚™∑',
  prcue: '‚âº',
  pre: '‚™Ø',
  prec: '‚â∫',
  precapprox: '‚™∑',
  preccurlyeq: '‚âº',
  preceq: '‚™Ø',
  precnapprox: '‚™π',
  precneqq: '‚™µ',
  precnsim: '‚ã®',
  precsim: '‚âæ',
  prime: '‚Ä≤',
  primes: '‚Ñô',
  prnE: '‚™µ',
  prnap: '‚™π',
  prnsim: '‚ã®',
  prod: '‚àè',
  profalar: '‚åÆ',
  profline: '‚åí',
  profsurf: '‚åì',
  prop: '‚àù',
  propto: '‚àù',
  prsim: '‚âæ',
  prurel: '‚ä∞',
  pscr: 'ùìÖ',
  psi: 'œà',
  puncsp: '‚Äà',
  qfr: 'ùîÆ',
  qint: '‚®å',
  qopf: 'ùï¢',
  qprime: '‚Åó',
  qscr: 'ùìÜ',
  quaternions: '‚Ñç',
  quatint: '‚®ñ',
  quest: '?',
  questeq: '‚âü',
  quo: '"',
  quot: '"',
  rAarr: '‚áõ',
  rArr: '‚áí',
  rAtail: '‚§ú',
  rBarr: '‚§è',
  rHar: '‚•§',
  race: '‚àΩÃ±',
  racute: '≈ï',
  radic: '‚àö',
  raemptyv: '‚¶≥',
  rang: '‚ü©',
  rangd: '‚¶í',
  range: '‚¶•',
  rangle: '‚ü©',
  raqu: '¬ª',
  raquo: '¬ª',
  rarr: '‚Üí',
  rarrap: '‚•µ',
  rarrb: '‚á•',
  rarrbfs: '‚§†',
  rarrc: '‚§≥',
  rarrfs: '‚§û',
  rarrhk: '‚Ü™',
  rarrlp: '‚Ü¨',
  rarrpl: '‚•Ö',
  rarrsim: '‚•¥',
  rarrtl: '‚Ü£',
  rarrw: '‚Üù',
  ratail: '‚§ö',
  ratio: '‚à∂',
  rationals: '‚Ñö',
  rbarr: '‚§ç',
  rbbrk: '‚ù≥',
  rbrace: '}',
  rbrack: ']',
  rbrke: '‚¶å',
  rbrksld: '‚¶é',
  rbrkslu: '‚¶ê',
  rcaron: '≈ô',
  rcedil: '≈ó',
  rceil: '‚åâ',
  rcub: '}',
  rcy: '—Ä',
  rdca: '‚§∑',
  rdldhar: '‚•©',
  rdquo: '‚Äù',
  rdquor: '‚Äù',
  rdsh: '‚Ü≥',
  real: '‚Ñú',
  realine: '‚Ñõ',
  realpart: '‚Ñú',
  reals: '‚Ñù',
  rect: '‚ñ≠',
  re: '¬Æ',
  reg: '¬Æ',
  rfisht: '‚•Ω',
  rfloor: '‚åã',
  rfr: 'ùîØ',
  rhard: '‚áÅ',
  rharu: '‚áÄ',
  rharul: '‚•¨',
  rho: 'œÅ',
  rhov: 'œ±',
  rightarrow: '‚Üí',
  rightarrowtail: '‚Ü£',
  rightharpoondown: '‚áÅ',
  rightharpoonup: '‚áÄ',
  rightleftarrows: '‚áÑ',
  rightleftharpoons: '‚áå',
  rightrightarrows: '‚áâ',
  rightsquigarrow: '‚Üù',
  rightthreetimes: '‚ãå',
  ring: 'Àö',
  risingdotseq: '‚âì',
  rlarr: '‚áÑ',
  rlhar: '‚áå',
  rlm: '‚Äè',
  rmoust: '‚é±',
  rmoustache: '‚é±',
  rnmid: '‚´Æ',
  roang: '‚ü≠',
  roarr: '‚áæ',
  robrk: '‚üß',
  ropar: '‚¶Ü',
  ropf: 'ùï£',
  roplus: '‚®Æ',
  rotimes: '‚®µ',
  rpar: ')',
  rpargt: '‚¶î',
  rppolint: '‚®í',
  rrarr: '‚áâ',
  rsaquo: '‚Ä∫',
  rscr: 'ùìá',
  rsh: '‚Ü±',
  rsqb: ']',
  rsquo: '‚Äô',
  rsquor: '‚Äô',
  rthree: '‚ãå',
  rtimes: '‚ãä',
  rtri: '‚ñπ',
  rtrie: '‚äµ',
  rtrif: '‚ñ∏',
  rtriltri: '‚ßé',
  ruluhar: '‚•®',
  rx: '‚Ñû',
  sacute: '≈õ',
  sbquo: '‚Äö',
  sc: '‚âª',
  scE: '‚™¥',
  scap: '‚™∏',
  scaron: '≈°',
  sccue: '‚âΩ',
  sce: '‚™∞',
  scedil: '≈ü',
  scirc: '≈ù',
  scnE: '‚™∂',
  scnap: '‚™∫',
  scnsim: '‚ã©',
  scpolint: '‚®ì',
  scsim: '‚âø',
  scy: '—Å',
  sdot: '‚ãÖ',
  sdotb: '‚ä°',
  sdote: '‚©¶',
  seArr: '‚áò',
  searhk: '‚§•',
  searr: '‚Üò',
  searrow: '‚Üò',
  sec: '¬ß',
  sect: '¬ß',
  semi: ';',
  seswar: '‚§©',
  setminus: '‚àñ',
  setmn: '‚àñ',
  sext: '‚ú∂',
  sfr: 'ùî∞',
  sfrown: '‚å¢',
  sharp: '‚ôØ',
  shchcy: '—â',
  shcy: '—à',
  shortmid: '‚à£',
  shortparallel: '‚à•',
  sh: '¬≠',
  shy: '¬≠',
  sigma: 'œÉ',
  sigmaf: 'œÇ',
  sigmav: 'œÇ',
  sim: '‚àº',
  simdot: '‚©™',
  sime: '‚âÉ',
  simeq: '‚âÉ',
  simg: '‚™û',
  simgE: '‚™†',
  siml: '‚™ù',
  simlE: '‚™ü',
  simne: '‚âÜ',
  simplus: '‚®§',
  simrarr: '‚•≤',
  slarr: '‚Üê',
  smallsetminus: '‚àñ',
  smashp: '‚®≥',
  smeparsl: '‚ß§',
  smid: '‚à£',
  smile: '‚å£',
  smt: '‚™™',
  smte: '‚™¨',
  smtes: '‚™¨Ô∏Ä',
  softcy: '—å',
  sol: '/',
  solb: '‚ßÑ',
  solbar: '‚åø',
  sopf: 'ùï§',
  spades: '‚ô†',
  spadesuit: '‚ô†',
  spar: '‚à•',
  sqcap: '‚äì',
  sqcaps: '‚äìÔ∏Ä',
  sqcup: '‚äî',
  sqcups: '‚äîÔ∏Ä',
  sqsub: '‚äè',
  sqsube: '‚äë',
  sqsubset: '‚äè',
  sqsubseteq: '‚äë',
  sqsup: '‚äê',
  sqsupe: '‚äí',
  sqsupset: '‚äê',
  sqsupseteq: '‚äí',
  squ: '‚ñ°',
  square: '‚ñ°',
  squarf: '‚ñ™',
  squf: '‚ñ™',
  srarr: '‚Üí',
  sscr: 'ùìà',
  ssetmn: '‚àñ',
  ssmile: '‚å£',
  sstarf: '‚ãÜ',
  star: '‚òÜ',
  starf: '‚òÖ',
  straightepsilon: 'œµ',
  straightphi: 'œï',
  strns: '¬Ø',
  sub: '‚äÇ',
  subE: '‚´Ö',
  subdot: '‚™Ω',
  sube: '‚äÜ',
  subedot: '‚´É',
  submult: '‚´Å',
  subnE: '‚´ã',
  subne: '‚ää',
  subplus: '‚™ø',
  subrarr: '‚•π',
  subset: '‚äÇ',
  subseteq: '‚äÜ',
  subseteqq: '‚´Ö',
  subsetneq: '‚ää',
  subsetneqq: '‚´ã',
  subsim: '‚´á',
  subsub: '‚´ï',
  subsup: '‚´ì',
  succ: '‚âª',
  succapprox: '‚™∏',
  succcurlyeq: '‚âΩ',
  succeq: '‚™∞',
  succnapprox: '‚™∫',
  succneqq: '‚™∂',
  succnsim: '‚ã©',
  succsim: '‚âø',
  sum: '‚àë',
  sung: '‚ô™',
  sup: '‚äÉ',
  sup1: '¬π',
  sup2: '¬≤',
  sup3: '¬≥',
  supE: '‚´Ü',
  supdot: '‚™æ',
  supdsub: '‚´ò',
  supe: '‚äá',
  supedot: '‚´Ñ',
  suphsol: '‚üâ',
  suphsub: '‚´ó',
  suplarr: '‚•ª',
  supmult: '‚´Ç',
  supnE: '‚´å',
  supne: '‚äã',
  supplus: '‚´Ä',
  supset: '‚äÉ',
  supseteq: '‚äá',
  supseteqq: '‚´Ü',
  supsetneq: '‚äã',
  supsetneqq: '‚´å',
  supsim: '‚´à',
  supsub: '‚´î',
  supsup: '‚´ñ',
  swArr: '‚áô',
  swarhk: '‚§¶',
  swarr: '‚Üô',
  swarrow: '‚Üô',
  swnwar: '‚§™',
  szli: '√ü',
  szlig: '√ü',
  target: '‚åñ',
  tau: 'œÑ',
  tbrk: '‚é¥',
  tcaron: '≈•',
  tcedil: '≈£',
  tcy: '—Ç',
  tdot: '‚Éõ',
  telrec: '‚åï',
  tfr: 'ùî±',
  there4: '‚à¥',
  therefore: '‚à¥',
  theta: 'Œ∏',
  thetasym: 'œë',
  thetav: 'œë',
  thickapprox: '‚âà',
  thicksim: '‚àº',
  thinsp: '‚Äâ',
  thkap: '‚âà',
  thksim: '‚àº',
  thor: '√æ',
  thorn: '√æ',
  tilde: 'Àú',
  time: '√ó',
  times: '√ó',
  timesb: '‚ä†',
  timesbar: '‚®±',
  timesd: '‚®∞',
  tint: '‚à≠',
  toea: '‚§®',
  top: '‚ä§',
  topbot: '‚å∂',
  topcir: '‚´±',
  topf: 'ùï•',
  topfork: '‚´ö',
  tosa: '‚§©',
  tprime: '‚Ä¥',
  trade: '‚Ñ¢',
  triangle: '‚ñµ',
  triangledown: '‚ñø',
  triangleleft: '‚óÉ',
  trianglelefteq: '‚ä¥',
  triangleq: '‚âú',
  triangleright: '‚ñπ',
  trianglerighteq: '‚äµ',
  tridot: '‚ó¨',
  trie: '‚âú',
  triminus: '‚®∫',
  triplus: '‚®π',
  trisb: '‚ßç',
  tritime: '‚®ª',
  trpezium: '‚è¢',
  tscr: 'ùìâ',
  tscy: '—Ü',
  tshcy: '—õ',
  tstrok: '≈ß',
  twixt: '‚â¨',
  twoheadleftarrow: '‚Üû',
  twoheadrightarrow: '‚Ü†',
  uArr: '‚áë',
  uHar: '‚•£',
  uacut: '√∫',
  uacute: '√∫',
  uarr: '‚Üë',
  ubrcy: '—û',
  ubreve: '≈≠',
  ucir: '√ª',
  ucirc: '√ª',
  ucy: '—É',
  udarr: '‚áÖ',
  udblac: '≈±',
  udhar: '‚•Æ',
  ufisht: '‚•æ',
  ufr: 'ùî≤',
  ugrav: '√π',
  ugrave: '√π',
  uharl: '‚Üø',
  uharr: '‚Üæ',
  uhblk: '‚ñÄ',
  ulcorn: '‚åú',
  ulcorner: '‚åú',
  ulcrop: '‚åè',
  ultri: '‚ó∏',
  umacr: '≈´',
  um: '¬®',
  uml: '¬®',
  uogon: '≈≥',
  uopf: 'ùï¶',
  uparrow: '‚Üë',
  updownarrow: '‚Üï',
  upharpoonleft: '‚Üø',
  upharpoonright: '‚Üæ',
  uplus: '‚äé',
  upsi: 'œÖ',
  upsih: 'œí',
  upsilon: 'œÖ',
  upuparrows: '‚áà',
  urcorn: '‚åù',
  urcorner: '‚åù',
  urcrop: '‚åé',
  uring: '≈Ø',
  urtri: '‚óπ',
  uscr: 'ùìä',
  utdot: '‚ã∞',
  utilde: '≈©',
  utri: '‚ñµ',
  utrif: '‚ñ¥',
  uuarr: '‚áà',
  uum: '√º',
  uuml: '√º',
  uwangle: '‚¶ß',
  vArr: '‚áï',
  vBar: '‚´®',
  vBarv: '‚´©',
  vDash: '‚ä®',
  vangrt: '‚¶ú',
  varepsilon: 'œµ',
  varkappa: 'œ∞',
  varnothing: '‚àÖ',
  varphi: 'œï',
  varpi: 'œñ',
  varpropto: '‚àù',
  varr: '‚Üï',
  varrho: 'œ±',
  varsigma: 'œÇ',
  varsubsetneq: '‚ääÔ∏Ä',
  varsubsetneqq: '‚´ãÔ∏Ä',
  varsupsetneq: '‚äãÔ∏Ä',
  varsupsetneqq: '‚´åÔ∏Ä',
  vartheta: 'œë',
  vartriangleleft: '‚ä≤',
  vartriangleright: '‚ä≥',
  vcy: '–≤',
  vdash: '‚ä¢',
  vee: '‚à®',
  veebar: '‚äª',
  veeeq: '‚âö',
  vellip: '‚ãÆ',
  verbar: '|',
  vert: '|',
  vfr: 'ùî≥',
  vltri: '‚ä≤',
  vnsub: '‚äÇ‚Éí',
  vnsup: '‚äÉ‚Éí',
  vopf: 'ùïß',
  vprop: '‚àù',
  vrtri: '‚ä≥',
  vscr: 'ùìã',
  vsubnE: '‚´ãÔ∏Ä',
  vsubne: '‚ääÔ∏Ä',
  vsupnE: '‚´åÔ∏Ä',
  vsupne: '‚äãÔ∏Ä',
  vzigzag: '‚¶ö',
  wcirc: '≈µ',
  wedbar: '‚©ü',
  wedge: '‚àß',
  wedgeq: '‚âô',
  weierp: '‚Ñò',
  wfr: 'ùî¥',
  wopf: 'ùï®',
  wp: '‚Ñò',
  wr: '‚âÄ',
  wreath: '‚âÄ',
  wscr: 'ùìå',
  xcap: '‚ãÇ',
  xcirc: '‚óØ',
  xcup: '‚ãÉ',
  xdtri: '‚ñΩ',
  xfr: 'ùîµ',
  xhArr: '‚ü∫',
  xharr: '‚ü∑',
  xi: 'Œæ',
  xlArr: '‚ü∏',
  xlarr: '‚üµ',
  xmap: '‚üº',
  xnis: '‚ãª',
  xodot: '‚®Ä',
  xopf: 'ùï©',
  xoplus: '‚®Å',
  xotime: '‚®Ç',
  xrArr: '‚üπ',
  xrarr: '‚ü∂',
  xscr: 'ùìç',
  xsqcup: '‚®Ü',
  xuplus: '‚®Ñ',
  xutri: '‚ñ≥',
  xvee: '‚ãÅ',
  xwedge: '‚ãÄ',
  yacut: '√Ω',
  yacute: '√Ω',
  yacy: '—è',
  ycirc: '≈∑',
  ycy: '—ã',
  ye: '¬•',
  yen: '¬•',
  yfr: 'ùî∂',
  yicy: '—ó',
  yopf: 'ùï™',
  yscr: 'ùìé',
  yucy: '—é',
  yum: '√ø',
  yuml: '√ø',
  zacute: '≈∫',
  zcaron: '≈æ',
  zcy: '–∑',
  zdot: '≈º',
  zeetrf: '‚Ñ®',
  zeta: 'Œ∂',
  zfr: 'ùî∑',
  zhcy: '–∂',
  zigrarr: '‚áù',
  zopf: 'ùï´',
  zscr: 'ùìè',
  zwj: '‚Äç',
  zwnj: '‚Äå'
};

const own$3 = {}.hasOwnProperty;

/**
 * Decode a single character reference (without the `&` or `;`).
 * You probably only need this when you‚Äôre building parsers yourself that follow
 * different rules compared to HTML.
 * This is optimized to be tiny in browsers.
 *
 * @param {string} value
 *   `notin` (named), `#123` (deci), `#x123` (hexa).
 * @returns {string|false}
 *   Decoded reference.
 */
function decodeNamedCharacterReference(value) {
  return own$3.call(characterEntities, value) ? characterEntities[value] : false
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const characterReference = {
  name: 'characterReference',
  tokenize: tokenizeCharacterReference
};
/** @type {Tokenizer} */

function tokenizeCharacterReference(effects, ok, nok) {
  const self = this;
  let size = 0;
  /** @type {number} */

  let max;
  /** @type {(code: Code) => code is number} */

  let test;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('characterReference');
    effects.enter('characterReferenceMarker');
    effects.consume(code);
    effects.exit('characterReferenceMarker');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 35) {
      effects.enter('characterReferenceMarkerNumeric');
      effects.consume(code);
      effects.exit('characterReferenceMarkerNumeric');
      return numeric
    }

    effects.enter('characterReferenceValue');
    max = 31;
    test = asciiAlphanumeric;
    return value(code)
  }
  /** @type {State} */

  function numeric(code) {
    if (code === 88 || code === 120) {
      effects.enter('characterReferenceMarkerHexadecimal');
      effects.consume(code);
      effects.exit('characterReferenceMarkerHexadecimal');
      effects.enter('characterReferenceValue');
      max = 6;
      test = asciiHexDigit;
      return value
    }

    effects.enter('characterReferenceValue');
    max = 7;
    test = asciiDigit;
    return value(code)
  }
  /** @type {State} */

  function value(code) {
    /** @type {Token} */
    let token;

    if (code === 59 && size) {
      token = effects.exit('characterReferenceValue');

      if (
        test === asciiAlphanumeric &&
        !decodeNamedCharacterReference(self.sliceSerialize(token))
      ) {
        return nok(code)
      }

      effects.enter('characterReferenceMarker');
      effects.consume(code);
      effects.exit('characterReferenceMarker');
      effects.exit('characterReference');
      return ok
    }

    if (test(code) && size++ < max) {
      effects.consume(code);
      return value
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const codeFenced = {
  name: 'codeFenced',
  tokenize: tokenizeCodeFenced,
  concrete: true
};
/** @type {Tokenizer} */

function tokenizeCodeFenced(effects, ok, nok) {
  const self = this;
  /** @type {Construct} */

  const closingFenceConstruct = {
    tokenize: tokenizeClosingFence,
    partial: true
  };
  /** @type {Construct} */

  const nonLazyLine = {
    tokenize: tokenizeNonLazyLine,
    partial: true
  };
  const tail = this.events[this.events.length - 1];
  const initialPrefix =
    tail && tail[1].type === 'linePrefix'
      ? tail[2].sliceSerialize(tail[1], true).length
      : 0;
  let sizeOpen = 0;
  /** @type {NonNullable<Code>} */

  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('codeFenced');
    effects.enter('codeFencedFence');
    effects.enter('codeFencedFenceSequence');
    marker = code;
    return sequenceOpen(code)
  }
  /** @type {State} */

  function sequenceOpen(code) {
    if (code === marker) {
      effects.consume(code);
      sizeOpen++;
      return sequenceOpen
    }

    effects.exit('codeFencedFenceSequence');
    return sizeOpen < 3
      ? nok(code)
      : factorySpace(effects, infoOpen, 'whitespace')(code)
  }
  /** @type {State} */

  function infoOpen(code) {
    if (code === null || markdownLineEnding$1(code)) {
      return openAfter(code)
    }

    effects.enter('codeFencedFenceInfo');
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return info(code)
  }
  /** @type {State} */

  function info(code) {
    if (code === null || markdownLineEndingOrSpace$1(code)) {
      effects.exit('chunkString');
      effects.exit('codeFencedFenceInfo');
      return factorySpace(effects, infoAfter, 'whitespace')(code)
    }

    if (code === 96 && code === marker) return nok(code)
    effects.consume(code);
    return info
  }
  /** @type {State} */

  function infoAfter(code) {
    if (code === null || markdownLineEnding$1(code)) {
      return openAfter(code)
    }

    effects.enter('codeFencedFenceMeta');
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return meta(code)
  }
  /** @type {State} */

  function meta(code) {
    if (code === null || markdownLineEnding$1(code)) {
      effects.exit('chunkString');
      effects.exit('codeFencedFenceMeta');
      return openAfter(code)
    }

    if (code === 96 && code === marker) return nok(code)
    effects.consume(code);
    return meta
  }
  /** @type {State} */

  function openAfter(code) {
    effects.exit('codeFencedFence');
    return self.interrupt ? ok(code) : contentStart(code)
  }
  /** @type {State} */

  function contentStart(code) {
    if (code === null) {
      return after(code)
    }

    if (markdownLineEnding$1(code)) {
      return effects.attempt(
        nonLazyLine,
        effects.attempt(
          closingFenceConstruct,
          after,
          initialPrefix
            ? factorySpace(
                effects,
                contentStart,
                'linePrefix',
                initialPrefix + 1
              )
            : contentStart
        ),
        after
      )(code)
    }

    effects.enter('codeFlowValue');
    return contentContinue(code)
  }
  /** @type {State} */

  function contentContinue(code) {
    if (code === null || markdownLineEnding$1(code)) {
      effects.exit('codeFlowValue');
      return contentStart(code)
    }

    effects.consume(code);
    return contentContinue
  }
  /** @type {State} */

  function after(code) {
    effects.exit('codeFenced');
    return ok(code)
  }
  /** @type {Tokenizer} */

  function tokenizeNonLazyLine(effects, ok, nok) {
    const self = this;
    return start
    /** @type {State} */

    function start(code) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return lineStart
    }
    /** @type {State} */

    function lineStart(code) {
      return self.parser.lazy[self.now().line] ? nok(code) : ok(code)
    }
  }
  /** @type {Tokenizer} */

  function tokenizeClosingFence(effects, ok, nok) {
    let size = 0;
    return factorySpace(
      effects,
      closingSequenceStart,
      'linePrefix',
      this.parser.constructs.disable.null.includes('codeIndented')
        ? undefined
        : 4
    )
    /** @type {State} */

    function closingSequenceStart(code) {
      effects.enter('codeFencedFence');
      effects.enter('codeFencedFenceSequence');
      return closingSequence(code)
    }
    /** @type {State} */

    function closingSequence(code) {
      if (code === marker) {
        effects.consume(code);
        size++;
        return closingSequence
      }

      if (size < sizeOpen) return nok(code)
      effects.exit('codeFencedFenceSequence');
      return factorySpace(effects, closingSequenceEnd, 'whitespace')(code)
    }
    /** @type {State} */

    function closingSequenceEnd(code) {
      if (code === null || markdownLineEnding$1(code)) {
        effects.exit('codeFencedFence');
        return ok(code)
      }

      return nok(code)
    }
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const codeIndented = {
  name: 'codeIndented',
  tokenize: tokenizeCodeIndented
};
/** @type {Construct} */

const indentedContent = {
  tokenize: tokenizeIndentedContent,
  partial: true
};
/** @type {Tokenizer} */

function tokenizeCodeIndented(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('codeIndented');
    return factorySpace(effects, afterStartPrefix, 'linePrefix', 4 + 1)(code)
  }
  /** @type {State} */

  function afterStartPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail &&
      tail[1].type === 'linePrefix' &&
      tail[2].sliceSerialize(tail[1], true).length >= 4
      ? afterPrefix(code)
      : nok(code)
  }
  /** @type {State} */

  function afterPrefix(code) {
    if (code === null) {
      return after(code)
    }

    if (markdownLineEnding$1(code)) {
      return effects.attempt(indentedContent, afterPrefix, after)(code)
    }

    effects.enter('codeFlowValue');
    return content(code)
  }
  /** @type {State} */

  function content(code) {
    if (code === null || markdownLineEnding$1(code)) {
      effects.exit('codeFlowValue');
      return afterPrefix(code)
    }

    effects.consume(code);
    return content
  }
  /** @type {State} */

  function after(code) {
    effects.exit('codeIndented');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeIndentedContent(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    // If this is a lazy line, it can‚Äôt be code.
    if (self.parser.lazy[self.now().line]) {
      return nok(code)
    }

    if (markdownLineEnding$1(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return start
    }

    return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)(code)
  }
  /** @type {State} */

  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail &&
      tail[1].type === 'linePrefix' &&
      tail[2].sliceSerialize(tail[1], true).length >= 4
      ? ok(code)
      : markdownLineEnding$1(code)
      ? start(code)
      : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Previous} Previous
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const codeText = {
  name: 'codeText',
  tokenize: tokenizeCodeText,
  resolve: resolveCodeText,
  previous: previous$2
};
/** @type {Resolver} */

function resolveCodeText(events) {
  let tailExitIndex = events.length - 4;
  let headEnterIndex = 3;
  /** @type {number} */

  let index;
  /** @type {number|undefined} */

  let enter; // If we start and end with an EOL or a space.

  if (
    (events[headEnterIndex][1].type === 'lineEnding' ||
      events[headEnterIndex][1].type === 'space') &&
    (events[tailExitIndex][1].type === 'lineEnding' ||
      events[tailExitIndex][1].type === 'space')
  ) {
    index = headEnterIndex; // And we have data.

    while (++index < tailExitIndex) {
      if (events[index][1].type === 'codeTextData') {
        // Then we have padding.
        events[headEnterIndex][1].type = 'codeTextPadding';
        events[tailExitIndex][1].type = 'codeTextPadding';
        headEnterIndex += 2;
        tailExitIndex -= 2;
        break
      }
    }
  } // Merge adjacent spaces and data.

  index = headEnterIndex - 1;
  tailExitIndex++;

  while (++index <= tailExitIndex) {
    if (enter === undefined) {
      if (index !== tailExitIndex && events[index][1].type !== 'lineEnding') {
        enter = index;
      }
    } else if (
      index === tailExitIndex ||
      events[index][1].type === 'lineEnding'
    ) {
      events[enter][1].type = 'codeTextData';

      if (index !== enter + 2) {
        events[enter][1].end = events[index - 1][1].end;
        events.splice(enter + 2, index - enter - 2);
        tailExitIndex -= index - enter - 2;
        index = enter + 2;
      }

      enter = undefined;
    }
  }

  return events
}
/** @type {Previous} */

function previous$2(code) {
  // If there is a previous code, there will always be a tail.
  return (
    code !== 96 ||
    this.events[this.events.length - 1][1].type === 'characterEscape'
  )
}
/** @type {Tokenizer} */

function tokenizeCodeText(effects, ok, nok) {
  let sizeOpen = 0;
  /** @type {number} */

  let size;
  /** @type {Token} */

  let token;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('codeText');
    effects.enter('codeTextSequence');
    return openingSequence(code)
  }
  /** @type {State} */

  function openingSequence(code) {
    if (code === 96) {
      effects.consume(code);
      sizeOpen++;
      return openingSequence
    }

    effects.exit('codeTextSequence');
    return gap(code)
  }
  /** @type {State} */

  function gap(code) {
    // EOF.
    if (code === null) {
      return nok(code)
    } // Closing fence?
    // Could also be data.

    if (code === 96) {
      token = effects.enter('codeTextSequence');
      size = 0;
      return closingSequence(code)
    } // Tabs don‚Äôt work, and virtual spaces don‚Äôt make sense.

    if (code === 32) {
      effects.enter('space');
      effects.consume(code);
      effects.exit('space');
      return gap
    }

    if (markdownLineEnding$1(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return gap
    } // Data.

    effects.enter('codeTextData');
    return data(code)
  } // In code.

  /** @type {State} */

  function data(code) {
    if (
      code === null ||
      code === 32 ||
      code === 96 ||
      markdownLineEnding$1(code)
    ) {
      effects.exit('codeTextData');
      return gap(code)
    }

    effects.consume(code);
    return data
  } // Closing fence.

  /** @type {State} */

  function closingSequence(code) {
    // More.
    if (code === 96) {
      effects.consume(code);
      size++;
      return closingSequence
    } // Done!

    if (size === sizeOpen) {
      effects.exit('codeTextSequence');
      effects.exit('codeText');
      return ok(code)
    } // More or less accents: mark as data.

    token.type = 'codeTextData';
    return data(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Chunk} Chunk
 * @typedef {import('micromark-util-types').Event} Event
 */

/**
 * Tokenize subcontent.
 *
 * @param {Event[]} events
 * @returns {boolean}
 */
function subtokenize(events) {
  /** @type {Record<string, number>} */
  const jumps = {};
  let index = -1;
  /** @type {Event} */

  let event;
  /** @type {number|undefined} */

  let lineIndex;
  /** @type {number} */

  let otherIndex;
  /** @type {Event} */

  let otherEvent;
  /** @type {Event[]} */

  let parameters;
  /** @type {Event[]} */

  let subevents;
  /** @type {boolean|undefined} */

  let more;

  while (++index < events.length) {
    while (index in jumps) {
      index = jumps[index];
    }

    event = events[index]; // Add a hook for the GFM tasklist extension, which needs to know if text
    // is in the first content of a list item.

    if (
      index &&
      event[1].type === 'chunkFlow' &&
      events[index - 1][1].type === 'listItemPrefix'
    ) {
      subevents = event[1]._tokenizer.events;
      otherIndex = 0;

      if (
        otherIndex < subevents.length &&
        subevents[otherIndex][1].type === 'lineEndingBlank'
      ) {
        otherIndex += 2;
      }

      if (
        otherIndex < subevents.length &&
        subevents[otherIndex][1].type === 'content'
      ) {
        while (++otherIndex < subevents.length) {
          if (subevents[otherIndex][1].type === 'content') {
            break
          }

          if (subevents[otherIndex][1].type === 'chunkText') {
            subevents[otherIndex][1]._isInFirstContentOfListItem = true;
            otherIndex++;
          }
        }
      }
    } // Enter.

    if (event[0] === 'enter') {
      if (event[1].contentType) {
        Object.assign(jumps, subcontent(events, index));
        index = jumps[index];
        more = true;
      }
    } // Exit.
    else if (event[1]._container) {
      otherIndex = index;
      lineIndex = undefined;

      while (otherIndex--) {
        otherEvent = events[otherIndex];

        if (
          otherEvent[1].type === 'lineEnding' ||
          otherEvent[1].type === 'lineEndingBlank'
        ) {
          if (otherEvent[0] === 'enter') {
            if (lineIndex) {
              events[lineIndex][1].type = 'lineEndingBlank';
            }

            otherEvent[1].type = 'lineEnding';
            lineIndex = otherIndex;
          }
        } else {
          break
        }
      }

      if (lineIndex) {
        // Fix position.
        event[1].end = Object.assign({}, events[lineIndex][1].start); // Switch container exit w/ line endings.

        parameters = events.slice(lineIndex, index);
        parameters.unshift(event);
        splice(events, lineIndex, index - lineIndex + 1, parameters);
      }
    }
  }

  return !more
}
/**
 * Tokenize embedded tokens.
 *
 * @param {Event[]} events
 * @param {number} eventIndex
 * @returns {Record<string, number>}
 */

function subcontent(events, eventIndex) {
  const token = events[eventIndex][1];
  const context = events[eventIndex][2];
  let startPosition = eventIndex - 1;
  /** @type {number[]} */

  const startPositions = [];
  const tokenizer =
    token._tokenizer || context.parser[token.contentType](token.start);
  const childEvents = tokenizer.events;
  /** @type {[number, number][]} */

  const jumps = [];
  /** @type {Record<string, number>} */

  const gaps = {};
  /** @type {Chunk[]} */

  let stream;
  /** @type {Token|undefined} */

  let previous;
  let index = -1;
  /** @type {Token|undefined} */

  let current = token;
  let adjust = 0;
  let start = 0;
  const breaks = [start]; // Loop forward through the linked tokens to pass them in order to the
  // subtokenizer.

  while (current) {
    // Find the position of the event for this token.
    while (events[++startPosition][1] !== current) {
      // Empty.
    }

    startPositions.push(startPosition);

    if (!current._tokenizer) {
      stream = context.sliceStream(current);

      if (!current.next) {
        stream.push(null);
      }

      if (previous) {
        tokenizer.defineSkip(current.start);
      }

      if (current._isInFirstContentOfListItem) {
        tokenizer._gfmTasklistFirstContentOfListItem = true;
      }

      tokenizer.write(stream);

      if (current._isInFirstContentOfListItem) {
        tokenizer._gfmTasklistFirstContentOfListItem = undefined;
      }
    } // Unravel the next token.

    previous = current;
    current = current.next;
  } // Now, loop back through all events (and linked tokens), to figure out which
  // parts belong where.

  current = token;

  while (++index < childEvents.length) {
    if (
      // Find a void token that includes a break.
      childEvents[index][0] === 'exit' &&
      childEvents[index - 1][0] === 'enter' &&
      childEvents[index][1].type === childEvents[index - 1][1].type &&
      childEvents[index][1].start.line !== childEvents[index][1].end.line
    ) {
      start = index + 1;
      breaks.push(start); // Help GC.

      current._tokenizer = undefined;
      current.previous = undefined;
      current = current.next;
    }
  } // Help GC.

  tokenizer.events = []; // If there‚Äôs one more token (which is the cases for lines that end in an
  // EOF), that‚Äôs perfect: the last point we found starts it.
  // If there isn‚Äôt then make sure any remaining content is added to it.

  if (current) {
    // Help GC.
    current._tokenizer = undefined;
    current.previous = undefined;
  } else {
    breaks.pop();
  } // Now splice the events from the subtokenizer into the current events,
  // moving back to front so that splice indices aren‚Äôt affected.

  index = breaks.length;

  while (index--) {
    const slice = childEvents.slice(breaks[index], breaks[index + 1]);
    const start = startPositions.pop();
    jumps.unshift([start, start + slice.length - 1]);
    splice(events, start, 2, slice);
  }

  index = -1;

  while (++index < jumps.length) {
    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];
    adjust += jumps[index][1] - jumps[index][0] - 1;
  }

  return gaps
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/**
 * No name because it must not be turned off.
 * @type {Construct}
 */
const content = {
  tokenize: tokenizeContent,
  resolve: resolveContent
};
/** @type {Construct} */

const continuationConstruct = {
  tokenize: tokenizeContinuation,
  partial: true
};
/**
 * Content is transparent: it‚Äôs parsed right now. That way, definitions are also
 * parsed right now: before text in paragraphs (specifically, media) are parsed.
 *
 * @type {Resolver}
 */

function resolveContent(events) {
  subtokenize(events);
  return events
}
/** @type {Tokenizer} */

function tokenizeContent(effects, ok) {
  /** @type {Token} */
  let previous;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('content');
    previous = effects.enter('chunkContent', {
      contentType: 'content'
    });
    return data(code)
  }
  /** @type {State} */

  function data(code) {
    if (code === null) {
      return contentEnd(code)
    }

    if (markdownLineEnding$1(code)) {
      return effects.check(
        continuationConstruct,
        contentContinue,
        contentEnd
      )(code)
    } // Data.

    effects.consume(code);
    return data
  }
  /** @type {State} */

  function contentEnd(code) {
    effects.exit('chunkContent');
    effects.exit('content');
    return ok(code)
  }
  /** @type {State} */

  function contentContinue(code) {
    effects.consume(code);
    effects.exit('chunkContent');
    previous.next = effects.enter('chunkContent', {
      contentType: 'content',
      previous
    });
    previous = previous.next;
    return data
  }
}
/** @type {Tokenizer} */

function tokenizeContinuation(effects, ok, nok) {
  const self = this;
  return startLookahead
  /** @type {State} */

  function startLookahead(code) {
    effects.exit('chunkContent');
    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return factorySpace(effects, prefixed, 'linePrefix')
  }
  /** @type {State} */

  function prefixed(code) {
    if (code === null || markdownLineEnding$1(code)) {
      return nok(code)
    }

    const tail = self.events[self.events.length - 1];

    if (
      !self.parser.constructs.disable.null.includes('codeIndented') &&
      tail &&
      tail[1].type === 'linePrefix' &&
      tail[2].sliceSerialize(tail[1], true).length >= 4
    ) {
      return ok(code)
    }

    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 */

/**
 * @param {Effects} effects
 * @param {State} ok
 * @param {State} nok
 * @param {string} type
 * @param {string} literalType
 * @param {string} literalMarkerType
 * @param {string} rawType
 * @param {string} stringType
 * @param {number} [max=Infinity]
 * @returns {State}
 */
// eslint-disable-next-line max-params
function factoryDestination(
  effects,
  ok,
  nok,
  type,
  literalType,
  literalMarkerType,
  rawType,
  stringType,
  max
) {
  const limit = max || Number.POSITIVE_INFINITY;
  let balance = 0;
  return start
  /** @type {State} */

  function start(code) {
    if (code === 60) {
      effects.enter(type);
      effects.enter(literalType);
      effects.enter(literalMarkerType);
      effects.consume(code);
      effects.exit(literalMarkerType);
      return destinationEnclosedBefore
    }

    if (code === null || code === 41 || asciiControl(code)) {
      return nok(code)
    }

    effects.enter(type);
    effects.enter(rawType);
    effects.enter(stringType);
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return destinationRaw(code)
  }
  /** @type {State} */

  function destinationEnclosedBefore(code) {
    if (code === 62) {
      effects.enter(literalMarkerType);
      effects.consume(code);
      effects.exit(literalMarkerType);
      effects.exit(literalType);
      effects.exit(type);
      return ok
    }

    effects.enter(stringType);
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return destinationEnclosed(code)
  }
  /** @type {State} */

  function destinationEnclosed(code) {
    if (code === 62) {
      effects.exit('chunkString');
      effects.exit(stringType);
      return destinationEnclosedBefore(code)
    }

    if (code === null || code === 60 || markdownLineEnding$1(code)) {
      return nok(code)
    }

    effects.consume(code);
    return code === 92 ? destinationEnclosedEscape : destinationEnclosed
  }
  /** @type {State} */

  function destinationEnclosedEscape(code) {
    if (code === 60 || code === 62 || code === 92) {
      effects.consume(code);
      return destinationEnclosed
    }

    return destinationEnclosed(code)
  }
  /** @type {State} */

  function destinationRaw(code) {
    if (code === 40) {
      if (++balance > limit) return nok(code)
      effects.consume(code);
      return destinationRaw
    }

    if (code === 41) {
      if (!balance--) {
        effects.exit('chunkString');
        effects.exit(stringType);
        effects.exit(rawType);
        effects.exit(type);
        return ok(code)
      }

      effects.consume(code);
      return destinationRaw
    }

    if (code === null || markdownLineEndingOrSpace$1(code)) {
      if (balance) return nok(code)
      effects.exit('chunkString');
      effects.exit(stringType);
      effects.exit(rawType);
      effects.exit(type);
      return ok(code)
    }

    if (asciiControl(code)) return nok(code)
    effects.consume(code);
    return code === 92 ? destinationRawEscape : destinationRaw
  }
  /** @type {State} */

  function destinationRawEscape(code) {
    if (code === 40 || code === 41 || code === 92) {
      effects.consume(code);
      return destinationRaw
    }

    return destinationRaw(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').State} State
 */

/**
 * @this {TokenizeContext}
 * @param {Effects} effects
 * @param {State} ok
 * @param {State} nok
 * @param {string} type
 * @param {string} markerType
 * @param {string} stringType
 * @returns {State}
 */
// eslint-disable-next-line max-params
function factoryLabel(effects, ok, nok, type, markerType, stringType) {
  const self = this;
  let size = 0;
  /** @type {boolean} */

  let data;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter(type);
    effects.enter(markerType);
    effects.consume(code);
    effects.exit(markerType);
    effects.enter(stringType);
    return atBreak
  }
  /** @type {State} */

  function atBreak(code) {
    if (
      code === null ||
      code === 91 ||
      (code === 93 && !data) ||
      /* To do: remove in the future once we‚Äôve switched from
       * `micromark-extension-footnote` to `micromark-extension-gfm-footnote`,
       * which doesn‚Äôt need this */

      /* Hidden footnotes hook */

      /* c8 ignore next 3 */
      (code === 94 &&
        !size &&
        '_hiddenFootnoteSupport' in self.parser.constructs) ||
      size > 999
    ) {
      return nok(code)
    }

    if (code === 93) {
      effects.exit(stringType);
      effects.enter(markerType);
      effects.consume(code);
      effects.exit(markerType);
      effects.exit(type);
      return ok
    }

    if (markdownLineEnding$1(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return atBreak
    }

    effects.enter('chunkString', {
      contentType: 'string'
    });
    return label(code)
  }
  /** @type {State} */

  function label(code) {
    if (
      code === null ||
      code === 91 ||
      code === 93 ||
      markdownLineEnding$1(code) ||
      size++ > 999
    ) {
      effects.exit('chunkString');
      return atBreak(code)
    }

    effects.consume(code);
    data = data || !markdownSpace(code);
    return code === 92 ? labelEscape : label
  }
  /** @type {State} */

  function labelEscape(code) {
    if (code === 91 || code === 92 || code === 93) {
      effects.consume(code);
      size++;
      return label
    }

    return label(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/**
 * @param {Effects} effects
 * @param {State} ok
 * @param {State} nok
 * @param {string} type
 * @param {string} markerType
 * @param {string} stringType
 * @returns {State}
 */
// eslint-disable-next-line max-params
function factoryTitle(effects, ok, nok, type, markerType, stringType) {
  /** @type {NonNullable<Code>} */
  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter(type);
    effects.enter(markerType);
    effects.consume(code);
    effects.exit(markerType);
    marker = code === 40 ? 41 : code;
    return atFirstTitleBreak
  }
  /** @type {State} */

  function atFirstTitleBreak(code) {
    if (code === marker) {
      effects.enter(markerType);
      effects.consume(code);
      effects.exit(markerType);
      effects.exit(type);
      return ok
    }

    effects.enter(stringType);
    return atTitleBreak(code)
  }
  /** @type {State} */

  function atTitleBreak(code) {
    if (code === marker) {
      effects.exit(stringType);
      return atFirstTitleBreak(marker)
    }

    if (code === null) {
      return nok(code)
    } // Note: blank lines can‚Äôt exist in content.

    if (markdownLineEnding$1(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return factorySpace(effects, atTitleBreak, 'linePrefix')
    }

    effects.enter('chunkString', {
      contentType: 'string'
    });
    return title(code)
  }
  /** @type {State} */

  function title(code) {
    if (code === marker || code === null || markdownLineEnding$1(code)) {
      effects.exit('chunkString');
      return atTitleBreak(code)
    }

    effects.consume(code);
    return code === 92 ? titleEscape : title
  }
  /** @type {State} */

  function titleEscape(code) {
    if (code === marker || code === 92) {
      effects.consume(code);
      return title
    }

    return title(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 */

/**
 * @param {Effects} effects
 * @param {State} ok
 */
function factoryWhitespace(effects, ok) {
  /** @type {boolean} */
  let seen;
  return start
  /** @type {State} */

  function start(code) {
    if (markdownLineEnding$1(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      seen = true;
      return start
    }

    if (markdownSpace(code)) {
      return factorySpace(
        effects,
        start,
        seen ? 'linePrefix' : 'lineSuffix'
      )(code)
    }

    return ok(code)
  }
}

/**
 * Normalize an identifier (such as used in definitions).
 *
 * @param {string} value
 * @returns {string}
 */
function normalizeIdentifier(value) {
  return (
    value // Collapse Markdown whitespace.
      .replace(/[\t\n\r ]+/g, ' ') // Trim.
      .replace(/^ | $/g, '') // Some characters are considered ‚Äúuppercase‚Äù, but if their lowercase
      // counterpart is uppercased will result in a different uppercase
      // character.
      // Hence, to get that form, we perform both lower- and uppercase.
      // Upper case makes sure keys will not interact with default prototypal
      // methods: no method is uppercase.
      .toLowerCase()
      .toUpperCase()
  )
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const definition = {
  name: 'definition',
  tokenize: tokenizeDefinition
};
/** @type {Construct} */

const titleConstruct = {
  tokenize: tokenizeTitle,
  partial: true
};
/** @type {Tokenizer} */

function tokenizeDefinition(effects, ok, nok) {
  const self = this;
  /** @type {string} */

  let identifier;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('definition');
    return factoryLabel.call(
      self,
      effects,
      labelAfter,
      nok,
      'definitionLabel',
      'definitionLabelMarker',
      'definitionLabelString'
    )(code)
  }
  /** @type {State} */

  function labelAfter(code) {
    identifier = normalizeIdentifier(
      self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)
    );

    if (code === 58) {
      effects.enter('definitionMarker');
      effects.consume(code);
      effects.exit('definitionMarker'); // Note: blank lines can‚Äôt exist in content.

      return factoryWhitespace(
        effects,
        factoryDestination(
          effects,
          effects.attempt(
            titleConstruct,
            factorySpace(effects, after, 'whitespace'),
            factorySpace(effects, after, 'whitespace')
          ),
          nok,
          'definitionDestination',
          'definitionDestinationLiteral',
          'definitionDestinationLiteralMarker',
          'definitionDestinationRaw',
          'definitionDestinationString'
        )
      )
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    if (code === null || markdownLineEnding$1(code)) {
      effects.exit('definition');

      if (!self.parser.defined.includes(identifier)) {
        self.parser.defined.push(identifier);
      }

      return ok(code)
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeTitle(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    return markdownLineEndingOrSpace$1(code)
      ? factoryWhitespace(effects, before)(code)
      : nok(code)
  }
  /** @type {State} */

  function before(code) {
    if (code === 34 || code === 39 || code === 40) {
      return factoryTitle(
        effects,
        factorySpace(effects, after, 'whitespace'),
        nok,
        'definitionTitle',
        'definitionTitleMarker',
        'definitionTitleString'
      )(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    return code === null || markdownLineEnding$1(code) ? ok(code) : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const hardBreakEscape = {
  name: 'hardBreakEscape',
  tokenize: tokenizeHardBreakEscape
};
/** @type {Tokenizer} */

function tokenizeHardBreakEscape(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('hardBreakEscape');
    effects.enter('escapeMarker');
    effects.consume(code);
    return open
  }
  /** @type {State} */

  function open(code) {
    if (markdownLineEnding$1(code)) {
      effects.exit('escapeMarker');
      effects.exit('hardBreakEscape');
      return ok(code)
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const headingAtx = {
  name: 'headingAtx',
  tokenize: tokenizeHeadingAtx,
  resolve: resolveHeadingAtx
};
/** @type {Resolver} */

function resolveHeadingAtx(events, context) {
  let contentEnd = events.length - 2;
  let contentStart = 3;
  /** @type {Token} */

  let content;
  /** @type {Token} */

  let text; // Prefix whitespace, part of the opening.

  if (events[contentStart][1].type === 'whitespace') {
    contentStart += 2;
  } // Suffix whitespace, part of the closing.

  if (
    contentEnd - 2 > contentStart &&
    events[contentEnd][1].type === 'whitespace'
  ) {
    contentEnd -= 2;
  }

  if (
    events[contentEnd][1].type === 'atxHeadingSequence' &&
    (contentStart === contentEnd - 1 ||
      (contentEnd - 4 > contentStart &&
        events[contentEnd - 2][1].type === 'whitespace'))
  ) {
    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4;
  }

  if (contentEnd > contentStart) {
    content = {
      type: 'atxHeadingText',
      start: events[contentStart][1].start,
      end: events[contentEnd][1].end
    };
    text = {
      type: 'chunkText',
      start: events[contentStart][1].start,
      end: events[contentEnd][1].end,
      // @ts-expect-error Constants are fine to assign.
      contentType: 'text'
    };
    splice(events, contentStart, contentEnd - contentStart + 1, [
      ['enter', content, context],
      ['enter', text, context],
      ['exit', text, context],
      ['exit', content, context]
    ]);
  }

  return events
}
/** @type {Tokenizer} */

function tokenizeHeadingAtx(effects, ok, nok) {
  const self = this;
  let size = 0;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('atxHeading');
    effects.enter('atxHeadingSequence');
    return fenceOpenInside(code)
  }
  /** @type {State} */

  function fenceOpenInside(code) {
    if (code === 35 && size++ < 6) {
      effects.consume(code);
      return fenceOpenInside
    }

    if (code === null || markdownLineEndingOrSpace$1(code)) {
      effects.exit('atxHeadingSequence');
      return self.interrupt ? ok(code) : headingBreak(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function headingBreak(code) {
    if (code === 35) {
      effects.enter('atxHeadingSequence');
      return sequence(code)
    }

    if (code === null || markdownLineEnding$1(code)) {
      effects.exit('atxHeading');
      return ok(code)
    }

    if (markdownSpace(code)) {
      return factorySpace(effects, headingBreak, 'whitespace')(code)
    }

    effects.enter('atxHeadingText');
    return data(code)
  }
  /** @type {State} */

  function sequence(code) {
    if (code === 35) {
      effects.consume(code);
      return sequence
    }

    effects.exit('atxHeadingSequence');
    return headingBreak(code)
  }
  /** @type {State} */

  function data(code) {
    if (code === null || code === 35 || markdownLineEndingOrSpace$1(code)) {
      effects.exit('atxHeadingText');
      return headingBreak(code)
    }

    effects.consume(code);
    return data
  }
}

/**
 * List of lowercase HTML tag names which when parsing HTML (flow), result
 * in more relaxed rules (condition 6): because they are known blocks, the
 * HTML-like syntax doesn‚Äôt have to be strictly parsed.
 * For tag names not in this list, a more strict algorithm (condition 7) is used
 * to detect whether the HTML-like syntax is seen as HTML (flow) or not.
 *
 * This is copied from:
 * <https://spec.commonmark.org/0.29/#html-blocks>.
 */
const htmlBlockNames = [
  'address',
  'article',
  'aside',
  'base',
  'basefont',
  'blockquote',
  'body',
  'caption',
  'center',
  'col',
  'colgroup',
  'dd',
  'details',
  'dialog',
  'dir',
  'div',
  'dl',
  'dt',
  'fieldset',
  'figcaption',
  'figure',
  'footer',
  'form',
  'frame',
  'frameset',
  'h1',
  'h2',
  'h3',
  'h4',
  'h5',
  'h6',
  'head',
  'header',
  'hr',
  'html',
  'iframe',
  'legend',
  'li',
  'link',
  'main',
  'menu',
  'menuitem',
  'nav',
  'noframes',
  'ol',
  'optgroup',
  'option',
  'p',
  'param',
  'section',
  'source',
  'summary',
  'table',
  'tbody',
  'td',
  'tfoot',
  'th',
  'thead',
  'title',
  'tr',
  'track',
  'ul'
];

/**
 * List of lowercase HTML tag names which when parsing HTML (flow), result in
 * HTML that can include lines w/o exiting, until a closing tag also in this
 * list is found (condition 1).
 *
 * This module is copied from:
 * <https://spec.commonmark.org/0.29/#html-blocks>.
 *
 * Note that `textarea` is not available in `CommonMark@0.29` but has been
 * merged to the primary branch and is slated to be released in the next release
 * of CommonMark.
 */
const htmlRawNames = ['pre', 'script', 'style', 'textarea'];

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */
/** @type {Construct} */

const htmlFlow = {
  name: 'htmlFlow',
  tokenize: tokenizeHtmlFlow,
  resolveTo: resolveToHtmlFlow,
  concrete: true
};
/** @type {Construct} */

const nextBlankConstruct = {
  tokenize: tokenizeNextBlank,
  partial: true
};
/** @type {Resolver} */

function resolveToHtmlFlow(events) {
  let index = events.length;

  while (index--) {
    if (events[index][0] === 'enter' && events[index][1].type === 'htmlFlow') {
      break
    }
  }

  if (index > 1 && events[index - 2][1].type === 'linePrefix') {
    // Add the prefix start to the HTML token.
    events[index][1].start = events[index - 2][1].start; // Add the prefix start to the HTML line token.

    events[index + 1][1].start = events[index - 2][1].start; // Remove the line prefix.

    events.splice(index - 2, 2);
  }

  return events
}
/** @type {Tokenizer} */

function tokenizeHtmlFlow(effects, ok, nok) {
  const self = this;
  /** @type {number} */

  let kind;
  /** @type {boolean} */

  let startTag;
  /** @type {string} */

  let buffer;
  /** @type {number} */

  let index;
  /** @type {Code} */

  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('htmlFlow');
    effects.enter('htmlFlowData');
    effects.consume(code);
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 33) {
      effects.consume(code);
      return declarationStart
    }

    if (code === 47) {
      effects.consume(code);
      return tagCloseStart
    }

    if (code === 63) {
      effects.consume(code);
      kind = 3; // While we‚Äôre in an instruction instead of a declaration, we‚Äôre on a `?`
      // right now, so we do need to search for `>`, similar to declarations.

      return self.interrupt ? ok : continuationDeclarationInside
    }

    if (asciiAlpha(code)) {
      effects.consume(code);
      buffer = String.fromCharCode(code);
      startTag = true;
      return tagName
    }

    return nok(code)
  }
  /** @type {State} */

  function declarationStart(code) {
    if (code === 45) {
      effects.consume(code);
      kind = 2;
      return commentOpenInside
    }

    if (code === 91) {
      effects.consume(code);
      kind = 5;
      buffer = 'CDATA[';
      index = 0;
      return cdataOpenInside
    }

    if (asciiAlpha(code)) {
      effects.consume(code);
      kind = 4;
      return self.interrupt ? ok : continuationDeclarationInside
    }

    return nok(code)
  }
  /** @type {State} */

  function commentOpenInside(code) {
    if (code === 45) {
      effects.consume(code);
      return self.interrupt ? ok : continuationDeclarationInside
    }

    return nok(code)
  }
  /** @type {State} */

  function cdataOpenInside(code) {
    if (code === buffer.charCodeAt(index++)) {
      effects.consume(code);
      return index === buffer.length
        ? self.interrupt
          ? ok
          : continuation
        : cdataOpenInside
    }

    return nok(code)
  }
  /** @type {State} */

  function tagCloseStart(code) {
    if (asciiAlpha(code)) {
      effects.consume(code);
      buffer = String.fromCharCode(code);
      return tagName
    }

    return nok(code)
  }
  /** @type {State} */

  function tagName(code) {
    if (
      code === null ||
      code === 47 ||
      code === 62 ||
      markdownLineEndingOrSpace$1(code)
    ) {
      if (
        code !== 47 &&
        startTag &&
        htmlRawNames.includes(buffer.toLowerCase())
      ) {
        kind = 1;
        return self.interrupt ? ok(code) : continuation(code)
      }

      if (htmlBlockNames.includes(buffer.toLowerCase())) {
        kind = 6;

        if (code === 47) {
          effects.consume(code);
          return basicSelfClosing
        }

        return self.interrupt ? ok(code) : continuation(code)
      }

      kind = 7; // Do not support complete HTML when interrupting

      return self.interrupt && !self.parser.lazy[self.now().line]
        ? nok(code)
        : startTag
        ? completeAttributeNameBefore(code)
        : completeClosingTagAfter(code)
    }

    if (code === 45 || asciiAlphanumeric(code)) {
      effects.consume(code);
      buffer += String.fromCharCode(code);
      return tagName
    }

    return nok(code)
  }
  /** @type {State} */

  function basicSelfClosing(code) {
    if (code === 62) {
      effects.consume(code);
      return self.interrupt ? ok : continuation
    }

    return nok(code)
  }
  /** @type {State} */

  function completeClosingTagAfter(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return completeClosingTagAfter
    }

    return completeEnd(code)
  }
  /** @type {State} */

  function completeAttributeNameBefore(code) {
    if (code === 47) {
      effects.consume(code);
      return completeEnd
    }

    if (code === 58 || code === 95 || asciiAlpha(code)) {
      effects.consume(code);
      return completeAttributeName
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAttributeNameBefore
    }

    return completeEnd(code)
  }
  /** @type {State} */

  function completeAttributeName(code) {
    if (
      code === 45 ||
      code === 46 ||
      code === 58 ||
      code === 95 ||
      asciiAlphanumeric(code)
    ) {
      effects.consume(code);
      return completeAttributeName
    }

    return completeAttributeNameAfter(code)
  }
  /** @type {State} */

  function completeAttributeNameAfter(code) {
    if (code === 61) {
      effects.consume(code);
      return completeAttributeValueBefore
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAttributeNameAfter
    }

    return completeAttributeNameBefore(code)
  }
  /** @type {State} */

  function completeAttributeValueBefore(code) {
    if (
      code === null ||
      code === 60 ||
      code === 61 ||
      code === 62 ||
      code === 96
    ) {
      return nok(code)
    }

    if (code === 34 || code === 39) {
      effects.consume(code);
      marker = code;
      return completeAttributeValueQuoted
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAttributeValueBefore
    }

    marker = null;
    return completeAttributeValueUnquoted(code)
  }
  /** @type {State} */

  function completeAttributeValueQuoted(code) {
    if (code === null || markdownLineEnding$1(code)) {
      return nok(code)
    }

    if (code === marker) {
      effects.consume(code);
      return completeAttributeValueQuotedAfter
    }

    effects.consume(code);
    return completeAttributeValueQuoted
  }
  /** @type {State} */

  function completeAttributeValueUnquoted(code) {
    if (
      code === null ||
      code === 34 ||
      code === 39 ||
      code === 60 ||
      code === 61 ||
      code === 62 ||
      code === 96 ||
      markdownLineEndingOrSpace$1(code)
    ) {
      return completeAttributeNameAfter(code)
    }

    effects.consume(code);
    return completeAttributeValueUnquoted
  }
  /** @type {State} */

  function completeAttributeValueQuotedAfter(code) {
    if (code === 47 || code === 62 || markdownSpace(code)) {
      return completeAttributeNameBefore(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function completeEnd(code) {
    if (code === 62) {
      effects.consume(code);
      return completeAfter
    }

    return nok(code)
  }
  /** @type {State} */

  function completeAfter(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAfter
    }

    return code === null || markdownLineEnding$1(code)
      ? continuation(code)
      : nok(code)
  }
  /** @type {State} */

  function continuation(code) {
    if (code === 45 && kind === 2) {
      effects.consume(code);
      return continuationCommentInside
    }

    if (code === 60 && kind === 1) {
      effects.consume(code);
      return continuationRawTagOpen
    }

    if (code === 62 && kind === 4) {
      effects.consume(code);
      return continuationClose
    }

    if (code === 63 && kind === 3) {
      effects.consume(code);
      return continuationDeclarationInside
    }

    if (code === 93 && kind === 5) {
      effects.consume(code);
      return continuationCharacterDataInside
    }

    if (markdownLineEnding$1(code) && (kind === 6 || kind === 7)) {
      return effects.check(
        nextBlankConstruct,
        continuationClose,
        continuationAtLineEnding
      )(code)
    }

    if (code === null || markdownLineEnding$1(code)) {
      return continuationAtLineEnding(code)
    }

    effects.consume(code);
    return continuation
  }
  /** @type {State} */

  function continuationAtLineEnding(code) {
    effects.exit('htmlFlowData');
    return htmlContinueStart(code)
  }
  /** @type {State} */

  function htmlContinueStart(code) {
    if (code === null) {
      return done(code)
    }

    if (markdownLineEnding$1(code)) {
      return effects.attempt(
        {
          tokenize: htmlLineEnd,
          partial: true
        },
        htmlContinueStart,
        done
      )(code)
    }

    effects.enter('htmlFlowData');
    return continuation(code)
  }
  /** @type {Tokenizer} */

  function htmlLineEnd(effects, ok, nok) {
    return start
    /** @type {State} */

    function start(code) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return lineStart
    }
    /** @type {State} */

    function lineStart(code) {
      return self.parser.lazy[self.now().line] ? nok(code) : ok(code)
    }
  }
  /** @type {State} */

  function continuationCommentInside(code) {
    if (code === 45) {
      effects.consume(code);
      return continuationDeclarationInside
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationRawTagOpen(code) {
    if (code === 47) {
      effects.consume(code);
      buffer = '';
      return continuationRawEndTag
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationRawEndTag(code) {
    if (code === 62 && htmlRawNames.includes(buffer.toLowerCase())) {
      effects.consume(code);
      return continuationClose
    }

    if (asciiAlpha(code) && buffer.length < 8) {
      effects.consume(code);
      buffer += String.fromCharCode(code);
      return continuationRawEndTag
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationCharacterDataInside(code) {
    if (code === 93) {
      effects.consume(code);
      return continuationDeclarationInside
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationDeclarationInside(code) {
    if (code === 62) {
      effects.consume(code);
      return continuationClose
    } // More dashes.

    if (code === 45 && kind === 2) {
      effects.consume(code);
      return continuationDeclarationInside
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationClose(code) {
    if (code === null || markdownLineEnding$1(code)) {
      effects.exit('htmlFlowData');
      return done(code)
    }

    effects.consume(code);
    return continuationClose
  }
  /** @type {State} */

  function done(code) {
    effects.exit('htmlFlow');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeNextBlank(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.exit('htmlFlowData');
    effects.enter('lineEndingBlank');
    effects.consume(code);
    effects.exit('lineEndingBlank');
    return effects.attempt(blankLine, ok, nok)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const htmlText = {
  name: 'htmlText',
  tokenize: tokenizeHtmlText
};
/** @type {Tokenizer} */

function tokenizeHtmlText(effects, ok, nok) {
  const self = this;
  /** @type {NonNullable<Code>|undefined} */

  let marker;
  /** @type {string} */

  let buffer;
  /** @type {number} */

  let index;
  /** @type {State} */

  let returnState;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('htmlText');
    effects.enter('htmlTextData');
    effects.consume(code);
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 33) {
      effects.consume(code);
      return declarationOpen
    }

    if (code === 47) {
      effects.consume(code);
      return tagCloseStart
    }

    if (code === 63) {
      effects.consume(code);
      return instruction
    }

    if (asciiAlpha(code)) {
      effects.consume(code);
      return tagOpen
    }

    return nok(code)
  }
  /** @type {State} */

  function declarationOpen(code) {
    if (code === 45) {
      effects.consume(code);
      return commentOpen
    }

    if (code === 91) {
      effects.consume(code);
      buffer = 'CDATA[';
      index = 0;
      return cdataOpen
    }

    if (asciiAlpha(code)) {
      effects.consume(code);
      return declaration
    }

    return nok(code)
  }
  /** @type {State} */

  function commentOpen(code) {
    if (code === 45) {
      effects.consume(code);
      return commentStart
    }

    return nok(code)
  }
  /** @type {State} */

  function commentStart(code) {
    if (code === null || code === 62) {
      return nok(code)
    }

    if (code === 45) {
      effects.consume(code);
      return commentStartDash
    }

    return comment(code)
  }
  /** @type {State} */

  function commentStartDash(code) {
    if (code === null || code === 62) {
      return nok(code)
    }

    return comment(code)
  }
  /** @type {State} */

  function comment(code) {
    if (code === null) {
      return nok(code)
    }

    if (code === 45) {
      effects.consume(code);
      return commentClose
    }

    if (markdownLineEnding$1(code)) {
      returnState = comment;
      return atLineEnding(code)
    }

    effects.consume(code);
    return comment
  }
  /** @type {State} */

  function commentClose(code) {
    if (code === 45) {
      effects.consume(code);
      return end
    }

    return comment(code)
  }
  /** @type {State} */

  function cdataOpen(code) {
    if (code === buffer.charCodeAt(index++)) {
      effects.consume(code);
      return index === buffer.length ? cdata : cdataOpen
    }

    return nok(code)
  }
  /** @type {State} */

  function cdata(code) {
    if (code === null) {
      return nok(code)
    }

    if (code === 93) {
      effects.consume(code);
      return cdataClose
    }

    if (markdownLineEnding$1(code)) {
      returnState = cdata;
      return atLineEnding(code)
    }

    effects.consume(code);
    return cdata
  }
  /** @type {State} */

  function cdataClose(code) {
    if (code === 93) {
      effects.consume(code);
      return cdataEnd
    }

    return cdata(code)
  }
  /** @type {State} */

  function cdataEnd(code) {
    if (code === 62) {
      return end(code)
    }

    if (code === 93) {
      effects.consume(code);
      return cdataEnd
    }

    return cdata(code)
  }
  /** @type {State} */

  function declaration(code) {
    if (code === null || code === 62) {
      return end(code)
    }

    if (markdownLineEnding$1(code)) {
      returnState = declaration;
      return atLineEnding(code)
    }

    effects.consume(code);
    return declaration
  }
  /** @type {State} */

  function instruction(code) {
    if (code === null) {
      return nok(code)
    }

    if (code === 63) {
      effects.consume(code);
      return instructionClose
    }

    if (markdownLineEnding$1(code)) {
      returnState = instruction;
      return atLineEnding(code)
    }

    effects.consume(code);
    return instruction
  }
  /** @type {State} */

  function instructionClose(code) {
    return code === 62 ? end(code) : instruction(code)
  }
  /** @type {State} */

  function tagCloseStart(code) {
    if (asciiAlpha(code)) {
      effects.consume(code);
      return tagClose
    }

    return nok(code)
  }
  /** @type {State} */

  function tagClose(code) {
    if (code === 45 || asciiAlphanumeric(code)) {
      effects.consume(code);
      return tagClose
    }

    return tagCloseBetween(code)
  }
  /** @type {State} */

  function tagCloseBetween(code) {
    if (markdownLineEnding$1(code)) {
      returnState = tagCloseBetween;
      return atLineEnding(code)
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return tagCloseBetween
    }

    return end(code)
  }
  /** @type {State} */

  function tagOpen(code) {
    if (code === 45 || asciiAlphanumeric(code)) {
      effects.consume(code);
      return tagOpen
    }

    if (code === 47 || code === 62 || markdownLineEndingOrSpace$1(code)) {
      return tagOpenBetween(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function tagOpenBetween(code) {
    if (code === 47) {
      effects.consume(code);
      return end
    }

    if (code === 58 || code === 95 || asciiAlpha(code)) {
      effects.consume(code);
      return tagOpenAttributeName
    }

    if (markdownLineEnding$1(code)) {
      returnState = tagOpenBetween;
      return atLineEnding(code)
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return tagOpenBetween
    }

    return end(code)
  }
  /** @type {State} */

  function tagOpenAttributeName(code) {
    if (
      code === 45 ||
      code === 46 ||
      code === 58 ||
      code === 95 ||
      asciiAlphanumeric(code)
    ) {
      effects.consume(code);
      return tagOpenAttributeName
    }

    return tagOpenAttributeNameAfter(code)
  }
  /** @type {State} */

  function tagOpenAttributeNameAfter(code) {
    if (code === 61) {
      effects.consume(code);
      return tagOpenAttributeValueBefore
    }

    if (markdownLineEnding$1(code)) {
      returnState = tagOpenAttributeNameAfter;
      return atLineEnding(code)
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return tagOpenAttributeNameAfter
    }

    return tagOpenBetween(code)
  }
  /** @type {State} */

  function tagOpenAttributeValueBefore(code) {
    if (
      code === null ||
      code === 60 ||
      code === 61 ||
      code === 62 ||
      code === 96
    ) {
      return nok(code)
    }

    if (code === 34 || code === 39) {
      effects.consume(code);
      marker = code;
      return tagOpenAttributeValueQuoted
    }

    if (markdownLineEnding$1(code)) {
      returnState = tagOpenAttributeValueBefore;
      return atLineEnding(code)
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return tagOpenAttributeValueBefore
    }

    effects.consume(code);
    marker = undefined;
    return tagOpenAttributeValueUnquoted
  }
  /** @type {State} */

  function tagOpenAttributeValueQuoted(code) {
    if (code === marker) {
      effects.consume(code);
      return tagOpenAttributeValueQuotedAfter
    }

    if (code === null) {
      return nok(code)
    }

    if (markdownLineEnding$1(code)) {
      returnState = tagOpenAttributeValueQuoted;
      return atLineEnding(code)
    }

    effects.consume(code);
    return tagOpenAttributeValueQuoted
  }
  /** @type {State} */

  function tagOpenAttributeValueQuotedAfter(code) {
    if (code === 62 || code === 47 || markdownLineEndingOrSpace$1(code)) {
      return tagOpenBetween(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function tagOpenAttributeValueUnquoted(code) {
    if (
      code === null ||
      code === 34 ||
      code === 39 ||
      code === 60 ||
      code === 61 ||
      code === 96
    ) {
      return nok(code)
    }

    if (code === 62 || markdownLineEndingOrSpace$1(code)) {
      return tagOpenBetween(code)
    }

    effects.consume(code);
    return tagOpenAttributeValueUnquoted
  } // We can‚Äôt have blank lines in content, so no need to worry about empty
  // tokens.

  /** @type {State} */

  function atLineEnding(code) {
    effects.exit('htmlTextData');
    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return factorySpace(
      effects,
      afterPrefix,
      'linePrefix',
      self.parser.constructs.disable.null.includes('codeIndented')
        ? undefined
        : 4
    )
  }
  /** @type {State} */

  function afterPrefix(code) {
    effects.enter('htmlTextData');
    return returnState(code)
  }
  /** @type {State} */

  function end(code) {
    if (code === 62) {
      effects.consume(code);
      effects.exit('htmlTextData');
      effects.exit('htmlText');
      return ok
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const labelEnd = {
  name: 'labelEnd',
  tokenize: tokenizeLabelEnd,
  resolveTo: resolveToLabelEnd,
  resolveAll: resolveAllLabelEnd
};
/** @type {Construct} */

const resourceConstruct = {
  tokenize: tokenizeResource
};
/** @type {Construct} */

const fullReferenceConstruct = {
  tokenize: tokenizeFullReference
};
/** @type {Construct} */

const collapsedReferenceConstruct = {
  tokenize: tokenizeCollapsedReference
};
/** @type {Resolver} */

function resolveAllLabelEnd(events) {
  let index = -1;
  /** @type {Token} */

  let token;

  while (++index < events.length) {
    token = events[index][1];

    if (
      token.type === 'labelImage' ||
      token.type === 'labelLink' ||
      token.type === 'labelEnd'
    ) {
      // Remove the marker.
      events.splice(index + 1, token.type === 'labelImage' ? 4 : 2);
      token.type = 'data';
      index++;
    }
  }

  return events
}
/** @type {Resolver} */

function resolveToLabelEnd(events, context) {
  let index = events.length;
  let offset = 0;
  /** @type {Token} */

  let token;
  /** @type {number|undefined} */

  let open;
  /** @type {number|undefined} */

  let close;
  /** @type {Event[]} */

  let media; // Find an opening.

  while (index--) {
    token = events[index][1];

    if (open) {
      // If we see another link, or inactive link label, we‚Äôve been here before.
      if (
        token.type === 'link' ||
        (token.type === 'labelLink' && token._inactive)
      ) {
        break
      } // Mark other link openings as inactive, as we can‚Äôt have links in
      // links.

      if (events[index][0] === 'enter' && token.type === 'labelLink') {
        token._inactive = true;
      }
    } else if (close) {
      if (
        events[index][0] === 'enter' &&
        (token.type === 'labelImage' || token.type === 'labelLink') &&
        !token._balanced
      ) {
        open = index;

        if (token.type !== 'labelLink') {
          offset = 2;
          break
        }
      }
    } else if (token.type === 'labelEnd') {
      close = index;
    }
  }

  const group = {
    type: events[open][1].type === 'labelLink' ? 'link' : 'image',
    start: Object.assign({}, events[open][1].start),
    end: Object.assign({}, events[events.length - 1][1].end)
  };
  const label = {
    type: 'label',
    start: Object.assign({}, events[open][1].start),
    end: Object.assign({}, events[close][1].end)
  };
  const text = {
    type: 'labelText',
    start: Object.assign({}, events[open + offset + 2][1].end),
    end: Object.assign({}, events[close - 2][1].start)
  };
  media = [
    ['enter', group, context],
    ['enter', label, context]
  ]; // Opening marker.

  media = push(media, events.slice(open + 1, open + offset + 3)); // Text open.

  media = push(media, [['enter', text, context]]); // Between.

  media = push(
    media,
    resolveAll(
      context.parser.constructs.insideSpan.null,
      events.slice(open + offset + 4, close - 3),
      context
    )
  ); // Text close, marker close, label close.

  media = push(media, [
    ['exit', text, context],
    events[close - 2],
    events[close - 1],
    ['exit', label, context]
  ]); // Reference, resource, or so.

  media = push(media, events.slice(close + 1)); // Media close.

  media = push(media, [['exit', group, context]]);
  splice(events, open, events.length, media);
  return events
}
/** @type {Tokenizer} */

function tokenizeLabelEnd(effects, ok, nok) {
  const self = this;
  let index = self.events.length;
  /** @type {Token} */

  let labelStart;
  /** @type {boolean} */

  let defined; // Find an opening.

  while (index--) {
    if (
      (self.events[index][1].type === 'labelImage' ||
        self.events[index][1].type === 'labelLink') &&
      !self.events[index][1]._balanced
    ) {
      labelStart = self.events[index][1];
      break
    }
  }

  return start
  /** @type {State} */

  function start(code) {
    if (!labelStart) {
      return nok(code)
    } // It‚Äôs a balanced bracket, but contains a link.

    if (labelStart._inactive) return balanced(code)
    defined = self.parser.defined.includes(
      normalizeIdentifier(
        self.sliceSerialize({
          start: labelStart.end,
          end: self.now()
        })
      )
    );
    effects.enter('labelEnd');
    effects.enter('labelMarker');
    effects.consume(code);
    effects.exit('labelMarker');
    effects.exit('labelEnd');
    return afterLabelEnd
  }
  /** @type {State} */

  function afterLabelEnd(code) {
    // Resource: `[asd](fgh)`.
    if (code === 40) {
      return effects.attempt(
        resourceConstruct,
        ok,
        defined ? ok : balanced
      )(code)
    } // Collapsed (`[asd][]`) or full (`[asd][fgh]`) reference?

    if (code === 91) {
      return effects.attempt(
        fullReferenceConstruct,
        ok,
        defined
          ? effects.attempt(collapsedReferenceConstruct, ok, balanced)
          : balanced
      )(code)
    } // Shortcut reference: `[asd]`?

    return defined ? ok(code) : balanced(code)
  }
  /** @type {State} */

  function balanced(code) {
    labelStart._balanced = true;
    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeResource(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('resource');
    effects.enter('resourceMarker');
    effects.consume(code);
    effects.exit('resourceMarker');
    return factoryWhitespace(effects, open)
  }
  /** @type {State} */

  function open(code) {
    if (code === 41) {
      return end(code)
    }

    return factoryDestination(
      effects,
      destinationAfter,
      nok,
      'resourceDestination',
      'resourceDestinationLiteral',
      'resourceDestinationLiteralMarker',
      'resourceDestinationRaw',
      'resourceDestinationString',
      32
    )(code)
  }
  /** @type {State} */

  function destinationAfter(code) {
    return markdownLineEndingOrSpace$1(code)
      ? factoryWhitespace(effects, between)(code)
      : end(code)
  }
  /** @type {State} */

  function between(code) {
    if (code === 34 || code === 39 || code === 40) {
      return factoryTitle(
        effects,
        factoryWhitespace(effects, end),
        nok,
        'resourceTitle',
        'resourceTitleMarker',
        'resourceTitleString'
      )(code)
    }

    return end(code)
  }
  /** @type {State} */

  function end(code) {
    if (code === 41) {
      effects.enter('resourceMarker');
      effects.consume(code);
      effects.exit('resourceMarker');
      effects.exit('resource');
      return ok
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeFullReference(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    return factoryLabel.call(
      self,
      effects,
      afterLabel,
      nok,
      'reference',
      'referenceMarker',
      'referenceString'
    )(code)
  }
  /** @type {State} */

  function afterLabel(code) {
    return self.parser.defined.includes(
      normalizeIdentifier(
        self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)
      )
    )
      ? ok(code)
      : nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeCollapsedReference(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('reference');
    effects.enter('referenceMarker');
    effects.consume(code);
    effects.exit('referenceMarker');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 93) {
      effects.enter('referenceMarker');
      effects.consume(code);
      effects.exit('referenceMarker');
      effects.exit('reference');
      return ok
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */
/** @type {Construct} */

const labelStartImage = {
  name: 'labelStartImage',
  tokenize: tokenizeLabelStartImage,
  resolveAll: labelEnd.resolveAll
};
/** @type {Tokenizer} */

function tokenizeLabelStartImage(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('labelImage');
    effects.enter('labelImageMarker');
    effects.consume(code);
    effects.exit('labelImageMarker');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 91) {
      effects.enter('labelMarker');
      effects.consume(code);
      effects.exit('labelMarker');
      effects.exit('labelImage');
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    /* To do: remove in the future once we‚Äôve switched from
     * `micromark-extension-footnote` to `micromark-extension-gfm-footnote`,
     * which doesn‚Äôt need this */

    /* Hidden footnotes hook */

    /* c8 ignore next 3 */
    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs
      ? nok(code)
      : ok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */
/** @type {Construct} */

const labelStartLink = {
  name: 'labelStartLink',
  tokenize: tokenizeLabelStartLink,
  resolveAll: labelEnd.resolveAll
};
/** @type {Tokenizer} */

function tokenizeLabelStartLink(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('labelLink');
    effects.enter('labelMarker');
    effects.consume(code);
    effects.exit('labelMarker');
    effects.exit('labelLink');
    return after
  }
  /** @type {State} */

  function after(code) {
    /* To do: remove in the future once we‚Äôve switched from
     * `micromark-extension-footnote` to `micromark-extension-gfm-footnote`,
     * which doesn‚Äôt need this */

    /* Hidden footnotes hook. */

    /* c8 ignore next 3 */
    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs
      ? nok(code)
      : ok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const lineEnding = {
  name: 'lineEnding',
  tokenize: tokenizeLineEnding
};
/** @type {Tokenizer} */

function tokenizeLineEnding(effects, ok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return factorySpace(effects, ok, 'linePrefix')
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const thematicBreak = {
  name: 'thematicBreak',
  tokenize: tokenizeThematicBreak
};
/** @type {Tokenizer} */

function tokenizeThematicBreak(effects, ok, nok) {
  let size = 0;
  /** @type {NonNullable<Code>} */

  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('thematicBreak');
    marker = code;
    return atBreak(code)
  }
  /** @type {State} */

  function atBreak(code) {
    if (code === marker) {
      effects.enter('thematicBreakSequence');
      return sequence(code)
    }

    if (markdownSpace(code)) {
      return factorySpace(effects, atBreak, 'whitespace')(code)
    }

    if (size < 3 || (code !== null && !markdownLineEnding$1(code))) {
      return nok(code)
    }

    effects.exit('thematicBreak');
    return ok(code)
  }
  /** @type {State} */

  function sequence(code) {
    if (code === marker) {
      effects.consume(code);
      size++;
      return sequence
    }

    effects.exit('thematicBreakSequence');
    return atBreak(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').Exiter} Exiter
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */
/** @type {Construct} */

const list$1 = {
  name: 'list',
  tokenize: tokenizeListStart,
  continuation: {
    tokenize: tokenizeListContinuation
  },
  exit: tokenizeListEnd
};
/** @type {Construct} */

const listItemPrefixWhitespaceConstruct = {
  tokenize: tokenizeListItemPrefixWhitespace,
  partial: true
};
/** @type {Construct} */

const indentConstruct = {
  tokenize: tokenizeIndent$1,
  partial: true
};
/**
 * @type {Tokenizer}
 * @this {TokenizeContextWithState}
 */

function tokenizeListStart(effects, ok, nok) {
  const self = this;
  const tail = self.events[self.events.length - 1];
  let initialSize =
    tail && tail[1].type === 'linePrefix'
      ? tail[2].sliceSerialize(tail[1], true).length
      : 0;
  let size = 0;
  return start
  /** @type {State} */

  function start(code) {
    const kind =
      self.containerState.type ||
      (code === 42 || code === 43 || code === 45
        ? 'listUnordered'
        : 'listOrdered');

    if (
      kind === 'listUnordered'
        ? !self.containerState.marker || code === self.containerState.marker
        : asciiDigit(code)
    ) {
      if (!self.containerState.type) {
        self.containerState.type = kind;
        effects.enter(kind, {
          _container: true
        });
      }

      if (kind === 'listUnordered') {
        effects.enter('listItemPrefix');
        return code === 42 || code === 45
          ? effects.check(thematicBreak, nok, atMarker)(code)
          : atMarker(code)
      }

      if (!self.interrupt || code === 49) {
        effects.enter('listItemPrefix');
        effects.enter('listItemValue');
        return inside(code)
      }
    }

    return nok(code)
  }
  /** @type {State} */

  function inside(code) {
    if (asciiDigit(code) && ++size < 10) {
      effects.consume(code);
      return inside
    }

    if (
      (!self.interrupt || size < 2) &&
      (self.containerState.marker
        ? code === self.containerState.marker
        : code === 41 || code === 46)
    ) {
      effects.exit('listItemValue');
      return atMarker(code)
    }

    return nok(code)
  }
  /**
   * @type {State}
   **/

  function atMarker(code) {
    effects.enter('listItemMarker');
    effects.consume(code);
    effects.exit('listItemMarker');
    self.containerState.marker = self.containerState.marker || code;
    return effects.check(
      blankLine, // Can‚Äôt be empty when interrupting.
      self.interrupt ? nok : onBlank,
      effects.attempt(
        listItemPrefixWhitespaceConstruct,
        endOfPrefix,
        otherPrefix
      )
    )
  }
  /** @type {State} */

  function onBlank(code) {
    self.containerState.initialBlankLine = true;
    initialSize++;
    return endOfPrefix(code)
  }
  /** @type {State} */

  function otherPrefix(code) {
    if (markdownSpace(code)) {
      effects.enter('listItemPrefixWhitespace');
      effects.consume(code);
      effects.exit('listItemPrefixWhitespace');
      return endOfPrefix
    }

    return nok(code)
  }
  /** @type {State} */

  function endOfPrefix(code) {
    self.containerState.size =
      initialSize +
      self.sliceSerialize(effects.exit('listItemPrefix'), true).length;
    return ok(code)
  }
}
/**
 * @type {Tokenizer}
 * @this {TokenizeContextWithState}
 */

function tokenizeListContinuation(effects, ok, nok) {
  const self = this;
  self.containerState._closeFlow = undefined;
  return effects.check(blankLine, onBlank, notBlank)
  /** @type {State} */

  function onBlank(code) {
    self.containerState.furtherBlankLines =
      self.containerState.furtherBlankLines ||
      self.containerState.initialBlankLine; // We have a blank line.
    // Still, try to consume at most the items size.

    return factorySpace(
      effects,
      ok,
      'listItemIndent',
      self.containerState.size + 1
    )(code)
  }
  /** @type {State} */

  function notBlank(code) {
    if (self.containerState.furtherBlankLines || !markdownSpace(code)) {
      self.containerState.furtherBlankLines = undefined;
      self.containerState.initialBlankLine = undefined;
      return notInCurrentItem(code)
    }

    self.containerState.furtherBlankLines = undefined;
    self.containerState.initialBlankLine = undefined;
    return effects.attempt(indentConstruct, ok, notInCurrentItem)(code)
  }
  /** @type {State} */

  function notInCurrentItem(code) {
    // While we do continue, we signal that the flow should be closed.
    self.containerState._closeFlow = true; // As we‚Äôre closing flow, we‚Äôre no longer interrupting.

    self.interrupt = undefined;
    return factorySpace(
      effects,
      effects.attempt(list$1, ok, nok),
      'linePrefix',
      self.parser.constructs.disable.null.includes('codeIndented')
        ? undefined
        : 4
    )(code)
  }
}
/**
 * @type {Tokenizer}
 * @this {TokenizeContextWithState}
 */

function tokenizeIndent$1(effects, ok, nok) {
  const self = this;
  return factorySpace(
    effects,
    afterPrefix,
    'listItemIndent',
    self.containerState.size + 1
  )
  /** @type {State} */

  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail &&
      tail[1].type === 'listItemIndent' &&
      tail[2].sliceSerialize(tail[1], true).length === self.containerState.size
      ? ok(code)
      : nok(code)
  }
}
/**
 * @type {Exiter}
 * @this {TokenizeContextWithState}
 */

function tokenizeListEnd(effects) {
  effects.exit(this.containerState.type);
}
/**
 * @type {Tokenizer}
 * @this {TokenizeContextWithState}
 */

function tokenizeListItemPrefixWhitespace(effects, ok, nok) {
  const self = this;
  return factorySpace(
    effects,
    afterPrefix,
    'listItemPrefixWhitespace',
    self.parser.constructs.disable.null.includes('codeIndented')
      ? undefined
      : 4 + 1
  )
  /** @type {State} */

  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return !markdownSpace(code) &&
      tail &&
      tail[1].type === 'listItemPrefixWhitespace'
      ? ok(code)
      : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const setextUnderline = {
  name: 'setextUnderline',
  tokenize: tokenizeSetextUnderline,
  resolveTo: resolveToSetextUnderline
};
/** @type {Resolver} */

function resolveToSetextUnderline(events, context) {
  let index = events.length;
  /** @type {number|undefined} */

  let content;
  /** @type {number|undefined} */

  let text;
  /** @type {number|undefined} */

  let definition; // Find the opening of the content.
  // It‚Äôll always exist: we don‚Äôt tokenize if it isn‚Äôt there.

  while (index--) {
    if (events[index][0] === 'enter') {
      if (events[index][1].type === 'content') {
        content = index;
        break
      }

      if (events[index][1].type === 'paragraph') {
        text = index;
      }
    } // Exit
    else {
      if (events[index][1].type === 'content') {
        // Remove the content end (if needed we‚Äôll add it later)
        events.splice(index, 1);
      }

      if (!definition && events[index][1].type === 'definition') {
        definition = index;
      }
    }
  }

  const heading = {
    type: 'setextHeading',
    start: Object.assign({}, events[text][1].start),
    end: Object.assign({}, events[events.length - 1][1].end)
  }; // Change the paragraph to setext heading text.

  events[text][1].type = 'setextHeadingText'; // If we have definitions in the content, we‚Äôll keep on having content,
  // but we need move it.

  if (definition) {
    events.splice(text, 0, ['enter', heading, context]);
    events.splice(definition + 1, 0, ['exit', events[content][1], context]);
    events[content][1].end = Object.assign({}, events[definition][1].end);
  } else {
    events[content][1] = heading;
  } // Add the heading exit at the end.

  events.push(['exit', heading, context]);
  return events
}
/** @type {Tokenizer} */

function tokenizeSetextUnderline(effects, ok, nok) {
  const self = this;
  let index = self.events.length;
  /** @type {NonNullable<Code>} */

  let marker;
  /** @type {boolean} */

  let paragraph; // Find an opening.

  while (index--) {
    // Skip enter/exit of line ending, line prefix, and content.
    // We can now either have a definition or a paragraph.
    if (
      self.events[index][1].type !== 'lineEnding' &&
      self.events[index][1].type !== 'linePrefix' &&
      self.events[index][1].type !== 'content'
    ) {
      paragraph = self.events[index][1].type === 'paragraph';
      break
    }
  }

  return start
  /** @type {State} */

  function start(code) {
    if (!self.parser.lazy[self.now().line] && (self.interrupt || paragraph)) {
      effects.enter('setextHeadingLine');
      effects.enter('setextHeadingLineSequence');
      marker = code;
      return closingSequence(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function closingSequence(code) {
    if (code === marker) {
      effects.consume(code);
      return closingSequence
    }

    effects.exit('setextHeadingLineSequence');
    return factorySpace(effects, closingSequenceEnd, 'lineSuffix')(code)
  }
  /** @type {State} */

  function closingSequenceEnd(code) {
    if (code === null || markdownLineEnding$1(code)) {
      effects.exit('setextHeadingLine');
      return ok(code)
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').Initializer} Initializer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {InitialConstruct} */
const flow$1 = {
  tokenize: initializeFlow
};
/** @type {Initializer} */

function initializeFlow(effects) {
  const self = this;
  const initial = effects.attempt(
    // Try to parse a blank line.
    blankLine,
    atBlankEnding, // Try to parse initial flow (essentially, only code).
    effects.attempt(
      this.parser.constructs.flowInitial,
      afterConstruct,
      factorySpace(
        effects,
        effects.attempt(
          this.parser.constructs.flow,
          afterConstruct,
          effects.attempt(content, afterConstruct)
        ),
        'linePrefix'
      )
    )
  );
  return initial
  /** @type {State} */

  function atBlankEnding(code) {
    if (code === null) {
      effects.consume(code);
      return
    }

    effects.enter('lineEndingBlank');
    effects.consume(code);
    effects.exit('lineEndingBlank');
    self.currentConstruct = undefined;
    return initial
  }
  /** @type {State} */

  function afterConstruct(code) {
    if (code === null) {
      effects.consume(code);
      return
    }

    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    self.currentConstruct = undefined;
    return initial
  }
}

/**
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Initializer} Initializer
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */
const resolver = {
  resolveAll: createResolver()
};
const string$1 = initializeFactory('string');
const text$2 = initializeFactory('text');
/**
 * @param {'string'|'text'} field
 * @returns {InitialConstruct}
 */

function initializeFactory(field) {
  return {
    tokenize: initializeText,
    resolveAll: createResolver(
      field === 'text' ? resolveAllLineSuffixes : undefined
    )
  }
  /** @type {Initializer} */

  function initializeText(effects) {
    const self = this;
    const constructs = this.parser.constructs[field];
    const text = effects.attempt(constructs, start, notText);
    return start
    /** @type {State} */

    function start(code) {
      return atBreak(code) ? text(code) : notText(code)
    }
    /** @type {State} */

    function notText(code) {
      if (code === null) {
        effects.consume(code);
        return
      }

      effects.enter('data');
      effects.consume(code);
      return data
    }
    /** @type {State} */

    function data(code) {
      if (atBreak(code)) {
        effects.exit('data');
        return text(code)
      } // Data.

      effects.consume(code);
      return data
    }
    /**
     * @param {Code} code
     * @returns {boolean}
     */

    function atBreak(code) {
      if (code === null) {
        return true
      }

      const list = constructs[code];
      let index = -1;

      if (list) {
        while (++index < list.length) {
          const item = list[index];

          if (!item.previous || item.previous.call(self, self.previous)) {
            return true
          }
        }
      }

      return false
    }
  }
}
/**
 * @param {Resolver} [extraResolver]
 * @returns {Resolver}
 */

function createResolver(extraResolver) {
  return resolveAllText
  /** @type {Resolver} */

  function resolveAllText(events, context) {
    let index = -1;
    /** @type {number|undefined} */

    let enter; // A rather boring computation (to merge adjacent `data` events) which
    // improves mm performance by 29%.

    while (++index <= events.length) {
      if (enter === undefined) {
        if (events[index] && events[index][1].type === 'data') {
          enter = index;
          index++;
        }
      } else if (!events[index] || events[index][1].type !== 'data') {
        // Don‚Äôt do anything if there is one data token.
        if (index !== enter + 2) {
          events[enter][1].end = events[index - 1][1].end;
          events.splice(enter + 2, index - enter - 2);
          index = enter + 2;
        }

        enter = undefined;
      }
    }

    return extraResolver ? extraResolver(events, context) : events
  }
}
/**
 * A rather ugly set of instructions which again looks at chunks in the input
 * stream.
 * The reason to do this here is that it is *much* faster to parse in reverse.
 * And that we can‚Äôt hook into `null` to split the line suffix before an EOF.
 * To do: figure out if we can make this into a clean utility, or even in core.
 * As it will be useful for GFMs literal autolink extension (and maybe even
 * tables?)
 *
 * @type {Resolver}
 */

function resolveAllLineSuffixes(events, context) {
  let eventIndex = 0; // Skip first.

  while (++eventIndex <= events.length) {
    if (
      (eventIndex === events.length ||
        events[eventIndex][1].type === 'lineEnding') &&
      events[eventIndex - 1][1].type === 'data'
    ) {
      const data = events[eventIndex - 1][1];
      const chunks = context.sliceStream(data);
      let index = chunks.length;
      let bufferIndex = -1;
      let size = 0;
      /** @type {boolean|undefined} */

      let tabs;

      while (index--) {
        const chunk = chunks[index];

        if (typeof chunk === 'string') {
          bufferIndex = chunk.length;

          while (chunk.charCodeAt(bufferIndex - 1) === 32) {
            size++;
            bufferIndex--;
          }

          if (bufferIndex) break
          bufferIndex = -1;
        } // Number
        else if (chunk === -2) {
          tabs = true;
          size++;
        } else if (chunk === -1) ; else {
          // Replacement character, exit.
          index++;
          break
        }
      }

      if (size) {
        const token = {
          type:
            eventIndex === events.length || tabs || size < 2
              ? 'lineSuffix'
              : 'hardBreakTrailing',
          start: {
            line: data.end.line,
            column: data.end.column - size,
            offset: data.end.offset - size,
            _index: data.start._index + index,
            _bufferIndex: index
              ? bufferIndex
              : data.start._bufferIndex + bufferIndex
          },
          end: Object.assign({}, data.end)
        };
        data.end = Object.assign({}, token.start);

        if (data.start.offset === data.end.offset) {
          Object.assign(data, token);
        } else {
          events.splice(
            eventIndex,
            0,
            ['enter', token, context],
            ['exit', token, context]
          );
          eventIndex += 2;
        }
      }

      eventIndex++;
    }
  }

  return events
}

/**
 * @typedef {import('micromark-util-types').Code} Code
 * @typedef {import('micromark-util-types').Chunk} Chunk
 * @typedef {import('micromark-util-types').Point} Point
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').ParseContext} ParseContext
 */

/**
 * Create a tokenizer.
 * Tokenizers deal with one type of data (e.g., containers, flow, text).
 * The parser is the object dealing with it all.
 * `initialize` works like other constructs, except that only its `tokenize`
 * function is used, in which case it doesn‚Äôt receive an `ok` or `nok`.
 * `from` can be given to set the point before the first character, although
 * when further lines are indented, they must be set with `defineSkip`.
 *
 * @param {ParseContext} parser
 * @param {InitialConstruct} initialize
 * @param {Omit<Point, '_index'|'_bufferIndex'>} [from]
 * @returns {TokenizeContext}
 */
function createTokenizer(parser, initialize, from) {
  /** @type {Point} */
  let point = Object.assign(
    from
      ? Object.assign({}, from)
      : {
          line: 1,
          column: 1,
          offset: 0
        },
    {
      _index: 0,
      _bufferIndex: -1
    }
  );
  /** @type {Record<string, number>} */

  const columnStart = {};
  /** @type {Construct[]} */

  const resolveAllConstructs = [];
  /** @type {Chunk[]} */

  let chunks = [];
  /** @type {Token[]} */

  let stack = [];
  /**
   * Tools used for tokenizing.
   *
   * @type {Effects}
   */

  const effects = {
    consume,
    enter,
    exit,
    attempt: constructFactory(onsuccessfulconstruct),
    check: constructFactory(onsuccessfulcheck),
    interrupt: constructFactory(onsuccessfulcheck, {
      interrupt: true
    })
  };
  /**
   * State and tools for resolving and serializing.
   *
   * @type {TokenizeContext}
   */

  const context = {
    previous: null,
    code: null,
    containerState: {},
    events: [],
    parser,
    sliceStream,
    sliceSerialize,
    now,
    defineSkip,
    write
  };
  /**
   * The state function.
   *
   * @type {State|void}
   */

  let state = initialize.tokenize.call(context, effects);

  if (initialize.resolveAll) {
    resolveAllConstructs.push(initialize);
  }

  return context
  /** @type {TokenizeContext['write']} */

  function write(slice) {
    chunks = push(chunks, slice);
    main(); // Exit if we‚Äôre not done, resolve might change stuff.

    if (chunks[chunks.length - 1] !== null) {
      return []
    }

    addResult(initialize, 0); // Otherwise, resolve, and exit.

    context.events = resolveAll(resolveAllConstructs, context.events, context);
    return context.events
  } //
  // Tools.
  //

  /** @type {TokenizeContext['sliceSerialize']} */

  function sliceSerialize(token, expandTabs) {
    return serializeChunks(sliceStream(token), expandTabs)
  }
  /** @type {TokenizeContext['sliceStream']} */

  function sliceStream(token) {
    return sliceChunks(chunks, token)
  }
  /** @type {TokenizeContext['now']} */

  function now() {
    return Object.assign({}, point)
  }
  /** @type {TokenizeContext['defineSkip']} */

  function defineSkip(value) {
    columnStart[value.line] = value.column;
    accountForPotentialSkip();
  } //
  // State management.
  //

  /**
   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by
   * `consume`).
   * Here is where we walk through the chunks, which either include strings of
   * several characters, or numerical character codes.
   * The reason to do this in a loop instead of a call is so the stack can
   * drain.
   *
   * @returns {void}
   */

  function main() {
    /** @type {number} */
    let chunkIndex;

    while (point._index < chunks.length) {
      const chunk = chunks[point._index]; // If we‚Äôre in a buffer chunk, loop through it.

      if (typeof chunk === 'string') {
        chunkIndex = point._index;

        if (point._bufferIndex < 0) {
          point._bufferIndex = 0;
        }

        while (
          point._index === chunkIndex &&
          point._bufferIndex < chunk.length
        ) {
          go(chunk.charCodeAt(point._bufferIndex));
        }
      } else {
        go(chunk);
      }
    }
  }
  /**
   * Deal with one code.
   *
   * @param {Code} code
   * @returns {void}
   */

  function go(code) {
    state = state(code);
  }
  /** @type {Effects['consume']} */

  function consume(code) {
    if (markdownLineEnding$1(code)) {
      point.line++;
      point.column = 1;
      point.offset += code === -3 ? 2 : 1;
      accountForPotentialSkip();
    } else if (code !== -1) {
      point.column++;
      point.offset++;
    } // Not in a string chunk.

    if (point._bufferIndex < 0) {
      point._index++;
    } else {
      point._bufferIndex++; // At end of string chunk.
      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference
      // strings.

      if (point._bufferIndex === chunks[point._index].length) {
        point._bufferIndex = -1;
        point._index++;
      }
    } // Expose the previous character.

    context.previous = code; // Mark as consumed.
  }
  /** @type {Effects['enter']} */

  function enter(type, fields) {
    /** @type {Token} */
    // @ts-expect-error Patch instead of assign required fields to help GC.
    const token = fields || {};
    token.type = type;
    token.start = now();
    context.events.push(['enter', token, context]);
    stack.push(token);
    return token
  }
  /** @type {Effects['exit']} */

  function exit(type) {
    const token = stack.pop();
    token.end = now();
    context.events.push(['exit', token, context]);
    return token
  }
  /**
   * Use results.
   *
   * @type {ReturnHandle}
   */

  function onsuccessfulconstruct(construct, info) {
    addResult(construct, info.from);
  }
  /**
   * Discard results.
   *
   * @type {ReturnHandle}
   */

  function onsuccessfulcheck(_, info) {
    info.restore();
  }
  /**
   * Factory to attempt/check/interrupt.
   *
   * @param {ReturnHandle} onreturn
   * @param {Record<string, unknown>} [fields]
   */

  function constructFactory(onreturn, fields) {
    return hook
    /**
     * Handle either an object mapping codes to constructs, a list of
     * constructs, or a single construct.
     *
     * @param {Construct|Construct[]|ConstructRecord} constructs
     * @param {State} returnState
     * @param {State} [bogusState]
     * @returns {State}
     */

    function hook(constructs, returnState, bogusState) {
      /** @type {Construct[]} */
      let listOfConstructs;
      /** @type {number} */

      let constructIndex;
      /** @type {Construct} */

      let currentConstruct;
      /** @type {Info} */

      let info;
      return Array.isArray(constructs)
        ? /* c8 ignore next 1 */
          handleListOfConstructs(constructs)
        : 'tokenize' in constructs // @ts-expect-error Looks like a construct.
        ? handleListOfConstructs([constructs])
        : handleMapOfConstructs(constructs)
      /**
       * Handle a list of construct.
       *
       * @param {ConstructRecord} map
       * @returns {State}
       */

      function handleMapOfConstructs(map) {
        return start
        /** @type {State} */

        function start(code) {
          const def = code !== null && map[code];
          const all = code !== null && map.null;
          const list = [
            // To do: add more extension tests.

            /* c8 ignore next 2 */
            ...(Array.isArray(def) ? def : def ? [def] : []),
            ...(Array.isArray(all) ? all : all ? [all] : [])
          ];
          return handleListOfConstructs(list)(code)
        }
      }
      /**
       * Handle a list of construct.
       *
       * @param {Construct[]} list
       * @returns {State}
       */

      function handleListOfConstructs(list) {
        listOfConstructs = list;
        constructIndex = 0;

        if (list.length === 0) {
          return bogusState
        }

        return handleConstruct(list[constructIndex])
      }
      /**
       * Handle a single construct.
       *
       * @param {Construct} construct
       * @returns {State}
       */

      function handleConstruct(construct) {
        return start
        /** @type {State} */

        function start(code) {
          // To do: not needed to store if there is no bogus state, probably?
          // Currently doesn‚Äôt work because `inspect` in document does a check
          // w/o a bogus, which doesn‚Äôt make sense. But it does seem to help perf
          // by not storing.
          info = store();
          currentConstruct = construct;

          if (!construct.partial) {
            context.currentConstruct = construct;
          }

          if (
            construct.name &&
            context.parser.constructs.disable.null.includes(construct.name)
          ) {
            return nok()
          }

          return construct.tokenize.call(
            // If we do have fields, create an object w/ `context` as its
            // prototype.
            // This allows a ‚Äúlive binding‚Äù, which is needed for `interrupt`.
            fields ? Object.assign(Object.create(context), fields) : context,
            effects,
            ok,
            nok
          )(code)
        }
      }
      /** @type {State} */

      function ok(code) {
        onreturn(currentConstruct, info);
        return returnState
      }
      /** @type {State} */

      function nok(code) {
        info.restore();

        if (++constructIndex < listOfConstructs.length) {
          return handleConstruct(listOfConstructs[constructIndex])
        }

        return bogusState
      }
    }
  }
  /**
   * @param {Construct} construct
   * @param {number} from
   * @returns {void}
   */

  function addResult(construct, from) {
    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {
      resolveAllConstructs.push(construct);
    }

    if (construct.resolve) {
      splice(
        context.events,
        from,
        context.events.length - from,
        construct.resolve(context.events.slice(from), context)
      );
    }

    if (construct.resolveTo) {
      context.events = construct.resolveTo(context.events, context);
    }
  }
  /**
   * Store state.
   *
   * @returns {Info}
   */

  function store() {
    const startPoint = now();
    const startPrevious = context.previous;
    const startCurrentConstruct = context.currentConstruct;
    const startEventsIndex = context.events.length;
    const startStack = Array.from(stack);
    return {
      restore,
      from: startEventsIndex
    }
    /**
     * Restore state.
     *
     * @returns {void}
     */

    function restore() {
      point = startPoint;
      context.previous = startPrevious;
      context.currentConstruct = startCurrentConstruct;
      context.events.length = startEventsIndex;
      stack = startStack;
      accountForPotentialSkip();
    }
  }
  /**
   * Move the current point a bit forward in the line when it‚Äôs on a column
   * skip.
   *
   * @returns {void}
   */

  function accountForPotentialSkip() {
    if (point.line in columnStart && point.column < 2) {
      point.column = columnStart[point.line];
      point.offset += columnStart[point.line] - 1;
    }
  }
}
/**
 * Get the chunks from a slice of chunks in the range of a token.
 *
 * @param {Chunk[]} chunks
 * @param {Pick<Token, 'start'|'end'>} token
 * @returns {Chunk[]}
 */

function sliceChunks(chunks, token) {
  const startIndex = token.start._index;
  const startBufferIndex = token.start._bufferIndex;
  const endIndex = token.end._index;
  const endBufferIndex = token.end._bufferIndex;
  /** @type {Chunk[]} */

  let view;

  if (startIndex === endIndex) {
    // @ts-expect-error `_bufferIndex` is used on string chunks.
    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];
  } else {
    view = chunks.slice(startIndex, endIndex);

    if (startBufferIndex > -1) {
      // @ts-expect-error `_bufferIndex` is used on string chunks.
      view[0] = view[0].slice(startBufferIndex);
    }

    if (endBufferIndex > 0) {
      // @ts-expect-error `_bufferIndex` is used on string chunks.
      view.push(chunks[endIndex].slice(0, endBufferIndex));
    }
  }

  return view
}
/**
 * Get the string value of a slice of chunks.
 *
 * @param {Chunk[]} chunks
 * @param {boolean} [expandTabs=false]
 * @returns {string}
 */

function serializeChunks(chunks, expandTabs) {
  let index = -1;
  /** @type {string[]} */

  const result = [];
  /** @type {boolean|undefined} */

  let atTab;

  while (++index < chunks.length) {
    const chunk = chunks[index];
    /** @type {string} */

    let value;

    if (typeof chunk === 'string') {
      value = chunk;
    } else
      switch (chunk) {
        case -5: {
          value = '\r';
          break
        }

        case -4: {
          value = '\n';
          break
        }

        case -3: {
          value = '\r' + '\n';
          break
        }

        case -2: {
          value = expandTabs ? ' ' : '\t';
          break
        }

        case -1: {
          if (!expandTabs && atTab) continue
          value = ' ';
          break
        }

        default: {
          // Currently only replacement character.
          value = String.fromCharCode(chunk);
        }
      }

    atTab = chunk === -2;
    result.push(value);
  }

  return result.join('')
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 */
/** @type {Extension['document']} */

const document = {
  [42]: list$1,
  [43]: list$1,
  [45]: list$1,
  [48]: list$1,
  [49]: list$1,
  [50]: list$1,
  [51]: list$1,
  [52]: list$1,
  [53]: list$1,
  [54]: list$1,
  [55]: list$1,
  [56]: list$1,
  [57]: list$1,
  [62]: blockQuote
};
/** @type {Extension['contentInitial']} */

const contentInitial = {
  [91]: definition
};
/** @type {Extension['flowInitial']} */

const flowInitial = {
  [-2]: codeIndented,
  [-1]: codeIndented,
  [32]: codeIndented
};
/** @type {Extension['flow']} */

const flow = {
  [35]: headingAtx,
  [42]: thematicBreak,
  [45]: [setextUnderline, thematicBreak],
  [60]: htmlFlow,
  [61]: setextUnderline,
  [95]: thematicBreak,
  [96]: codeFenced,
  [126]: codeFenced
};
/** @type {Extension['string']} */

const string = {
  [38]: characterReference,
  [92]: characterEscape
};
/** @type {Extension['text']} */

const text$1 = {
  [-5]: lineEnding,
  [-4]: lineEnding,
  [-3]: lineEnding,
  [33]: labelStartImage,
  [38]: characterReference,
  [42]: attention,
  [60]: [autolink, htmlText],
  [91]: labelStartLink,
  [92]: [hardBreakEscape, characterEscape],
  [93]: labelEnd,
  [95]: attention,
  [96]: codeText
};
/** @type {Extension['insideSpan']} */

const insideSpan = {
  null: [attention, resolver]
};
/** @type {Extension['attentionMarkers']} */

const attentionMarkers = {
  null: [42, 95]
};
/** @type {Extension['disable']} */

const disable = {
  null: []
};

var defaultConstructs = /*#__PURE__*/Object.freeze({
    __proto__: null,
    document: document,
    contentInitial: contentInitial,
    flowInitial: flowInitial,
    flow: flow,
    string: string,
    text: text$1,
    insideSpan: insideSpan,
    attentionMarkers: attentionMarkers,
    disable: disable
});

/**
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension
 * @typedef {import('micromark-util-types').ParseOptions} ParseOptions
 * @typedef {import('micromark-util-types').ParseContext} ParseContext
 * @typedef {import('micromark-util-types').Create} Create
 */
/**
 * @param {ParseOptions} [options]
 * @returns {ParseContext}
 */

function parse(options = {}) {
  /** @type {FullNormalizedExtension} */
  // @ts-expect-error `defaultConstructs` is full, so the result will be too.
  const constructs = combineExtensions(
    // @ts-expect-error Same as above.
    [defaultConstructs].concat(options.extensions || [])
  );
  /** @type {ParseContext} */

  const parser = {
    defined: [],
    lazy: {},
    constructs,
    content: create(content$1),
    document: create(document$1),
    flow: create(flow$1),
    string: create(string$1),
    text: create(text$2)
  };
  return parser
  /**
   * @param {InitialConstruct} initial
   */

  function create(initial) {
    return creator
    /** @type {Create} */

    function creator(from) {
      return createTokenizer(parser, initial, from)
    }
  }
}

/**
 * @typedef {import('micromark-util-types').Encoding} Encoding
 * @typedef {import('micromark-util-types').Value} Value
 * @typedef {import('micromark-util-types').Chunk} Chunk
 * @typedef {import('micromark-util-types').Code} Code
 */

/**
 * @callback Preprocessor
 * @param {Value} value
 * @param {Encoding} [encoding]
 * @param {boolean} [end=false]
 * @returns {Chunk[]}
 */
const search = /[\0\t\n\r]/g;
/**
 * @returns {Preprocessor}
 */

function preprocess() {
  let column = 1;
  let buffer = '';
  /** @type {boolean|undefined} */

  let start = true;
  /** @type {boolean|undefined} */

  let atCarriageReturn;
  return preprocessor
  /** @type {Preprocessor} */

  function preprocessor(value, encoding, end) {
    /** @type {Chunk[]} */
    const chunks = [];
    /** @type {RegExpMatchArray|null} */

    let match;
    /** @type {number} */

    let next;
    /** @type {number} */

    let startPosition;
    /** @type {number} */

    let endPosition;
    /** @type {Code} */

    let code; // @ts-expect-error `Buffer` does allow an encoding.

    value = buffer + value.toString(encoding);
    startPosition = 0;
    buffer = '';

    if (start) {
      if (value.charCodeAt(0) === 65279) {
        startPosition++;
      }

      start = undefined;
    }

    while (startPosition < value.length) {
      search.lastIndex = startPosition;
      match = search.exec(value);
      endPosition =
        match && match.index !== undefined ? match.index : value.length;
      code = value.charCodeAt(endPosition);

      if (!match) {
        buffer = value.slice(startPosition);
        break
      }

      if (code === 10 && startPosition === endPosition && atCarriageReturn) {
        chunks.push(-3);
        atCarriageReturn = undefined;
      } else {
        if (atCarriageReturn) {
          chunks.push(-5);
          atCarriageReturn = undefined;
        }

        if (startPosition < endPosition) {
          chunks.push(value.slice(startPosition, endPosition));
          column += endPosition - startPosition;
        }

        switch (code) {
          case 0: {
            chunks.push(65533);
            column++;
            break
          }

          case 9: {
            next = Math.ceil(column / 4) * 4;
            chunks.push(-2);

            while (column++ < next) chunks.push(-1);

            break
          }

          case 10: {
            chunks.push(-4);
            column = 1;
            break
          }

          default: {
            atCarriageReturn = true;
            column = 1;
          }
        }
      }

      startPosition = endPosition + 1;
    }

    if (end) {
      if (atCarriageReturn) chunks.push(-5);
      if (buffer) chunks.push(buffer);
      chunks.push(null);
    }

    return chunks
  }
}

/**
 * @typedef {import('micromark-util-types').Event} Event
 */
/**
 * @param {Event[]} events
 * @returns {Event[]}
 */

function postprocess(events) {
  while (!subtokenize(events)) {
    // Empty
  }

  return events
}

/**
 * Turn the number (in string form as either hexa- or plain decimal) coming from
 * a numeric character reference into a character.
 *
 * @param {string} value
 *   Value to decode.
 * @param {number} base
 *   Numeric base.
 * @returns {string}
 */
function decodeNumericCharacterReference(value, base) {
  const code = Number.parseInt(value, base);

  if (
    // C0 except for HT, LF, FF, CR, space
    code < 9 ||
    code === 11 ||
    (code > 13 && code < 32) || // Control character (DEL) of the basic block and C1 controls.
    (code > 126 && code < 160) || // Lone high surrogates and low surrogates.
    (code > 55295 && code < 57344) || // Noncharacters.
    (code > 64975 && code < 65008) ||
    (code & 65535) === 65535 ||
    (code & 65535) === 65534 || // Out of range
    code > 1114111
  ) {
    return '\uFFFD'
  }

  return String.fromCharCode(code)
}

const characterEscapeOrReference =
  /\\([!-/:-@[-`{-~])|&(#(?:\d{1,7}|x[\da-f]{1,6})|[\da-z]{1,31});/gi;
/**
 * Utility to decode markdown strings (which occur in places such as fenced
 * code info strings, destinations, labels, and titles).
 * The ‚Äústring‚Äù content type allows character escapes and -references.
 * This decodes those.
 *
 * @param {string} value
 * @returns {string}
 */

function decodeString(value) {
  return value.replace(characterEscapeOrReference, decode)
}
/**
 * @param {string} $0
 * @param {string} $1
 * @param {string} $2
 * @returns {string}
 */

function decode($0, $1, $2) {
  if ($1) {
    // Escape.
    return $1
  } // Reference.

  const head = $2.charCodeAt(0);

  if (head === 35) {
    const head = $2.charCodeAt(1);
    const hex = head === 120 || head === 88;
    return decodeNumericCharacterReference($2.slice(hex ? 2 : 1), hex ? 16 : 10)
  }

  return decodeNamedCharacterReference($2) || $0
}

var own$2 = {}.hasOwnProperty;

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Position} Position
 * @typedef {import('unist').Point} Point
 */

/**
 * Stringify one point, a position (start and end points), or a node‚Äôs
 * positional information.
 *
 * @param {Node|Position|Point} [value]
 * @returns {string}
 */
function stringifyPosition(value) {
  // Nothing.
  if (!value || typeof value !== 'object') {
    return ''
  }

  // Node.
  if (own$2.call(value, 'position') || own$2.call(value, 'type')) {
    // @ts-ignore looks like a node.
    return position(value.position)
  }

  // Position.
  if (own$2.call(value, 'start') || own$2.call(value, 'end')) {
    // @ts-ignore looks like a position.
    return position(value)
  }

  // Point.
  if (own$2.call(value, 'line') || own$2.call(value, 'column')) {
    // @ts-ignore looks like a point.
    return point(value)
  }

  // ?
  return ''
}

/**
 * @param {Point} point
 * @returns {string}
 */
function point(point) {
  return index(point && point.line) + ':' + index(point && point.column)
}

/**
 * @param {Position} pos
 * @returns {string}
 */
function position(pos) {
  return point(pos && pos.start) + '-' + point(pos && pos.end)
}

/**
 * @param {number} value
 * @returns {number}
 */
function index(value) {
  return value && typeof value === 'number' ? value : 1
}

/**
 * @typedef {import('micromark-util-types').Encoding} Encoding
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').ParseOptions} ParseOptions
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').Value} Value
 * @typedef {import('unist').Parent} UnistParent
 * @typedef {import('unist').Point} Point
 * @typedef {import('mdast').PhrasingContent} PhrasingContent
 * @typedef {import('mdast').Content} Content
 * @typedef {Root|Content} Node
 * @typedef {Extract<Node, UnistParent>} Parent
 * @typedef {import('mdast').Break} Break
 * @typedef {import('mdast').Blockquote} Blockquote
 * @typedef {import('mdast').Code} Code
 * @typedef {import('mdast').Definition} Definition
 * @typedef {import('mdast').Emphasis} Emphasis
 * @typedef {import('mdast').Heading} Heading
 * @typedef {import('mdast').HTML} HTML
 * @typedef {import('mdast').Image} Image
 * @typedef {import('mdast').ImageReference} ImageReference
 * @typedef {import('mdast').InlineCode} InlineCode
 * @typedef {import('mdast').Link} Link
 * @typedef {import('mdast').LinkReference} LinkReference
 * @typedef {import('mdast').List} List
 * @typedef {import('mdast').ListItem} ListItem
 * @typedef {import('mdast').Paragraph} Paragraph
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast').Strong} Strong
 * @typedef {import('mdast').Text} Text
 * @typedef {import('mdast').ThematicBreak} ThematicBreak
 *
 * @typedef {UnistParent & {type: 'fragment', children: Array<PhrasingContent>}} Fragment
 */
const own$1 = {}.hasOwnProperty;
/**
 * @param value Markdown to parse (`string` or `Buffer`).
 * @param [encoding] Character encoding to understand `value` as when it‚Äôs a `Buffer` (`string`, default: `'utf8'`).
 * @param [options] Configuration
 */

const fromMarkdown$1 =
  /**
   * @type {(
   *   ((value: Value, encoding: Encoding, options?: Options) => Root) &
   *   ((value: Value, options?: Options) => Root)
   * )}
   */

  /**
   * @param {Value} value
   * @param {Encoding} [encoding]
   * @param {Options} [options]
   * @returns {Root}
   */
  function (value, encoding, options) {
    if (typeof encoding !== 'string') {
      options = encoding;
      encoding = undefined;
    }

    return compiler(options)(
      postprocess(
        parse(options).document().write(preprocess()(value, encoding, true))
      )
    )
  };
/**
 * Note this compiler only understand complete buffering, not streaming.
 *
 * @param {Options} [options]
 */

function compiler(options = {}) {
  /** @type {NormalizedExtension} */
  // @ts-expect-error: our base has all required fields, so the result will too.
  const config = configure(
    {
      transforms: [],
      canContainEols: [
        'emphasis',
        'fragment',
        'heading',
        'paragraph',
        'strong'
      ],
      enter: {
        autolink: opener(link),
        autolinkProtocol: onenterdata,
        autolinkEmail: onenterdata,
        atxHeading: opener(heading),
        blockQuote: opener(blockQuote),
        characterEscape: onenterdata,
        characterReference: onenterdata,
        codeFenced: opener(codeFlow),
        codeFencedFenceInfo: buffer,
        codeFencedFenceMeta: buffer,
        codeIndented: opener(codeFlow, buffer),
        codeText: opener(codeText, buffer),
        codeTextData: onenterdata,
        data: onenterdata,
        codeFlowValue: onenterdata,
        definition: opener(definition),
        definitionDestinationString: buffer,
        definitionLabelString: buffer,
        definitionTitleString: buffer,
        emphasis: opener(emphasis),
        hardBreakEscape: opener(hardBreak),
        hardBreakTrailing: opener(hardBreak),
        htmlFlow: opener(html, buffer),
        htmlFlowData: onenterdata,
        htmlText: opener(html, buffer),
        htmlTextData: onenterdata,
        image: opener(image),
        label: buffer,
        link: opener(link),
        listItem: opener(listItem),
        listItemValue: onenterlistitemvalue,
        listOrdered: opener(list, onenterlistordered),
        listUnordered: opener(list),
        paragraph: opener(paragraph),
        reference: onenterreference,
        referenceString: buffer,
        resourceDestinationString: buffer,
        resourceTitleString: buffer,
        setextHeading: opener(heading),
        strong: opener(strong),
        thematicBreak: opener(thematicBreak)
      },
      exit: {
        atxHeading: closer(),
        atxHeadingSequence: onexitatxheadingsequence,
        autolink: closer(),
        autolinkEmail: onexitautolinkemail,
        autolinkProtocol: onexitautolinkprotocol,
        blockQuote: closer(),
        characterEscapeValue: onexitdata,
        characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,
        characterReferenceMarkerNumeric: onexitcharacterreferencemarker,
        characterReferenceValue: onexitcharacterreferencevalue,
        codeFenced: closer(onexitcodefenced),
        codeFencedFence: onexitcodefencedfence,
        codeFencedFenceInfo: onexitcodefencedfenceinfo,
        codeFencedFenceMeta: onexitcodefencedfencemeta,
        codeFlowValue: onexitdata,
        codeIndented: closer(onexitcodeindented),
        codeText: closer(onexitcodetext),
        codeTextData: onexitdata,
        data: onexitdata,
        definition: closer(),
        definitionDestinationString: onexitdefinitiondestinationstring,
        definitionLabelString: onexitdefinitionlabelstring,
        definitionTitleString: onexitdefinitiontitlestring,
        emphasis: closer(),
        hardBreakEscape: closer(onexithardbreak),
        hardBreakTrailing: closer(onexithardbreak),
        htmlFlow: closer(onexithtmlflow),
        htmlFlowData: onexitdata,
        htmlText: closer(onexithtmltext),
        htmlTextData: onexitdata,
        image: closer(onexitimage),
        label: onexitlabel,
        labelText: onexitlabeltext,
        lineEnding: onexitlineending,
        link: closer(onexitlink),
        listItem: closer(),
        listOrdered: closer(),
        listUnordered: closer(),
        paragraph: closer(),
        referenceString: onexitreferencestring,
        resourceDestinationString: onexitresourcedestinationstring,
        resourceTitleString: onexitresourcetitlestring,
        resource: onexitresource,
        setextHeading: closer(onexitsetextheading),
        setextHeadingLineSequence: onexitsetextheadinglinesequence,
        setextHeadingText: onexitsetextheadingtext,
        strong: closer(),
        thematicBreak: closer()
      }
    },
    options.mdastExtensions || []
  );
  /** @type {CompileData} */

  const data = {};
  return compile
  /**
   * @param {Array<Event>} events
   * @returns {Root}
   */

  function compile(events) {
    /** @type {Root} */
    let tree = {
      type: 'root',
      children: []
    };
    /** @type {CompileContext['stack']} */

    const stack = [tree];
    /** @type {CompileContext['tokenStack']} */

    const tokenStack = [];
    /** @type {Array<number>} */

    const listStack = [];
    /** @type {Omit<CompileContext, 'sliceSerialize'>} */

    const context = {
      stack,
      tokenStack,
      config,
      enter,
      exit,
      buffer,
      resume,
      setData,
      getData
    };
    let index = -1;

    while (++index < events.length) {
      // We preprocess lists to add `listItem` tokens, and to infer whether
      // items the list itself are spread out.
      if (
        events[index][1].type === 'listOrdered' ||
        events[index][1].type === 'listUnordered'
      ) {
        if (events[index][0] === 'enter') {
          listStack.push(index);
        } else {
          const tail = listStack.pop();
          index = prepareList(events, tail, index);
        }
      }
    }

    index = -1;

    while (++index < events.length) {
      const handler = config[events[index][0]];

      if (own$1.call(handler, events[index][1].type)) {
        handler[events[index][1].type].call(
          Object.assign(
            {
              sliceSerialize: events[index][2].sliceSerialize
            },
            context
          ),
          events[index][1]
        );
      }
    }

    if (tokenStack.length > 0) {
      const tail = tokenStack[tokenStack.length - 1];
      const handler = tail[1] || defaultOnError;
      handler.call(context, undefined, tail[0]);
    } // Figure out `root` position.

    tree.position = {
      start: point(
        events.length > 0
          ? events[0][1].start
          : {
              line: 1,
              column: 1,
              offset: 0
            }
      ),
      end: point(
        events.length > 0
          ? events[events.length - 2][1].end
          : {
              line: 1,
              column: 1,
              offset: 0
            }
      )
    };
    index = -1;

    while (++index < config.transforms.length) {
      tree = config.transforms[index](tree) || tree;
    }

    return tree
  }
  /**
   * @param {Array<Event>} events
   * @param {number} start
   * @param {number} length
   * @returns {number}
   */

  function prepareList(events, start, length) {
    let index = start - 1;
    let containerBalance = -1;
    let listSpread = false;
    /** @type {Token|undefined} */

    let listItem;
    /** @type {number|undefined} */

    let lineIndex;
    /** @type {number|undefined} */

    let firstBlankLineIndex;
    /** @type {boolean|undefined} */

    let atMarker;

    while (++index <= length) {
      const event = events[index];

      if (
        event[1].type === 'listUnordered' ||
        event[1].type === 'listOrdered' ||
        event[1].type === 'blockQuote'
      ) {
        if (event[0] === 'enter') {
          containerBalance++;
        } else {
          containerBalance--;
        }

        atMarker = undefined;
      } else if (event[1].type === 'lineEndingBlank') {
        if (event[0] === 'enter') {
          if (
            listItem &&
            !atMarker &&
            !containerBalance &&
            !firstBlankLineIndex
          ) {
            firstBlankLineIndex = index;
          }

          atMarker = undefined;
        }
      } else if (
        event[1].type === 'linePrefix' ||
        event[1].type === 'listItemValue' ||
        event[1].type === 'listItemMarker' ||
        event[1].type === 'listItemPrefix' ||
        event[1].type === 'listItemPrefixWhitespace'
      ) ; else {
        atMarker = undefined;
      }

      if (
        (!containerBalance &&
          event[0] === 'enter' &&
          event[1].type === 'listItemPrefix') ||
        (containerBalance === -1 &&
          event[0] === 'exit' &&
          (event[1].type === 'listUnordered' ||
            event[1].type === 'listOrdered'))
      ) {
        if (listItem) {
          let tailIndex = index;
          lineIndex = undefined;

          while (tailIndex--) {
            const tailEvent = events[tailIndex];

            if (
              tailEvent[1].type === 'lineEnding' ||
              tailEvent[1].type === 'lineEndingBlank'
            ) {
              if (tailEvent[0] === 'exit') continue

              if (lineIndex) {
                events[lineIndex][1].type = 'lineEndingBlank';
                listSpread = true;
              }

              tailEvent[1].type = 'lineEnding';
              lineIndex = tailIndex;
            } else if (
              tailEvent[1].type === 'linePrefix' ||
              tailEvent[1].type === 'blockQuotePrefix' ||
              tailEvent[1].type === 'blockQuotePrefixWhitespace' ||
              tailEvent[1].type === 'blockQuoteMarker' ||
              tailEvent[1].type === 'listItemIndent'
            ) ; else {
              break
            }
          }

          if (
            firstBlankLineIndex &&
            (!lineIndex || firstBlankLineIndex < lineIndex)
          ) {
            // @ts-expect-error Patched.
            listItem._spread = true;
          } // Fix position.

          listItem.end = Object.assign(
            {},
            lineIndex ? events[lineIndex][1].start : event[1].end
          );
          events.splice(lineIndex || index, 0, ['exit', listItem, event[2]]);
          index++;
          length++;
        } // Create a new list item.

        if (event[1].type === 'listItemPrefix') {
          listItem = {
            type: 'listItem',
            // @ts-expect-error Patched
            _spread: false,
            start: Object.assign({}, event[1].start)
          }; // @ts-expect-error: `listItem` is most definitely defined, TS...

          events.splice(index, 0, ['enter', listItem, event[2]]);
          index++;
          length++;
          firstBlankLineIndex = undefined;
          atMarker = true;
        }
      }
    } // @ts-expect-error Patched.

    events[start][1]._spread = listSpread;
    return length
  }
  /**
   * @type {CompileContext['setData']}
   * @param [value]
   */

  function setData(key, value) {
    data[key] = value;
  }
  /**
   * @type {CompileContext['getData']}
   * @template {string} K
   * @param {K} key
   * @returns {CompileData[K]}
   */

  function getData(key) {
    return data[key]
  }
  /**
   * @param {Point} d
   * @returns {Point}
   */

  function point(d) {
    return {
      line: d.line,
      column: d.column,
      offset: d.offset
    }
  }
  /**
   * @param {(token: Token) => Node} create
   * @param {Handle} [and]
   * @returns {Handle}
   */

  function opener(create, and) {
    return open
    /**
     * @this {CompileContext}
     * @param {Token} token
     * @returns {void}
     */

    function open(token) {
      enter.call(this, create(token), token);
      if (and) and.call(this, token);
    }
  }
  /** @type {CompileContext['buffer']} */

  function buffer() {
    this.stack.push({
      type: 'fragment',
      children: []
    });
  }
  /**
   * @type {CompileContext['enter']}
   * @template {Node} N
   * @this {CompileContext}
   * @param {N} node
   * @param {Token} token
   * @param {OnEnterError} [errorHandler]
   * @returns {N}
   */

  function enter(node, token, errorHandler) {
    const parent = this.stack[this.stack.length - 1];
    // @ts-expect-error: Assume `Node` can exist as a child of `parent`.
    parent.children.push(node);
    this.stack.push(node);
    this.tokenStack.push([token, errorHandler]); // @ts-expect-error: `end` will be patched later.

    node.position = {
      start: point(token.start)
    };
    return node
  }
  /**
   * @param {Handle} [and]
   * @returns {Handle}
   */

  function closer(and) {
    return close
    /**
     * @this {CompileContext}
     * @param {Token} token
     * @returns {void}
     */

    function close(token) {
      if (and) and.call(this, token);
      exit.call(this, token);
    }
  }
  /**
   * @type {CompileContext['exit']}
   * @this {CompileContext}
   * @param {Token} token
   * @param {OnExitError} [onExitError]
   * @returns {Node}
   */

  function exit(token, onExitError) {
    const node = this.stack.pop();
    const open = this.tokenStack.pop();

    if (!open) {
      throw new Error(
        'Cannot close `' +
          token.type +
          '` (' +
          stringifyPosition({
            start: token.start,
            end: token.end
          }) +
          '): it‚Äôs not open'
      )
    } else if (open[0].type !== token.type) {
      if (onExitError) {
        onExitError.call(this, token, open[0]);
      } else {
        const handler = open[1] || defaultOnError;
        handler.call(this, token, open[0]);
      }
    }

    node.position.end = point(token.end);
    return node
  }
  /**
   * @this {CompileContext}
   * @returns {string}
   */

  function resume() {
    return toString(this.stack.pop())
  } //
  // Handlers.
  //

  /** @type {Handle} */

  function onenterlistordered() {
    setData('expectingFirstListItemValue', true);
  }
  /** @type {Handle} */

  function onenterlistitemvalue(token) {
    if (getData('expectingFirstListItemValue')) {
      const ancestor =
        /** @type {List} */
        this.stack[this.stack.length - 2];
      ancestor.start = Number.parseInt(this.sliceSerialize(token), 10);
      setData('expectingFirstListItemValue');
    }
  }
  /** @type {Handle} */

  function onexitcodefencedfenceinfo() {
    const data = this.resume();
    const node =
      /** @type {Code} */
      this.stack[this.stack.length - 1];
    node.lang = data;
  }
  /** @type {Handle} */

  function onexitcodefencedfencemeta() {
    const data = this.resume();
    const node =
      /** @type {Code} */
      this.stack[this.stack.length - 1];
    node.meta = data;
  }
  /** @type {Handle} */

  function onexitcodefencedfence() {
    // Exit if this is the closing fence.
    if (getData('flowCodeInside')) return
    this.buffer();
    setData('flowCodeInside', true);
  }
  /** @type {Handle} */

  function onexitcodefenced() {
    const data = this.resume();
    const node =
      /** @type {Code} */
      this.stack[this.stack.length - 1];
    node.value = data.replace(/^(\r?\n|\r)|(\r?\n|\r)$/g, '');
    setData('flowCodeInside');
  }
  /** @type {Handle} */

  function onexitcodeindented() {
    const data = this.resume();
    const node =
      /** @type {Code} */
      this.stack[this.stack.length - 1];
    node.value = data.replace(/(\r?\n|\r)$/g, '');
  }
  /** @type {Handle} */

  function onexitdefinitionlabelstring(token) {
    // Discard label, use the source content instead.
    const label = this.resume();
    const node =
      /** @type {Definition} */
      this.stack[this.stack.length - 1];
    node.label = label;
    node.identifier = normalizeIdentifier(
      this.sliceSerialize(token)
    ).toLowerCase();
  }
  /** @type {Handle} */

  function onexitdefinitiontitlestring() {
    const data = this.resume();
    const node =
      /** @type {Definition} */
      this.stack[this.stack.length - 1];
    node.title = data;
  }
  /** @type {Handle} */

  function onexitdefinitiondestinationstring() {
    const data = this.resume();
    const node =
      /** @type {Definition} */
      this.stack[this.stack.length - 1];
    node.url = data;
  }
  /** @type {Handle} */

  function onexitatxheadingsequence(token) {
    const node =
      /** @type {Heading} */
      this.stack[this.stack.length - 1];

    if (!node.depth) {
      const depth = this.sliceSerialize(token).length;
      node.depth = depth;
    }
  }
  /** @type {Handle} */

  function onexitsetextheadingtext() {
    setData('setextHeadingSlurpLineEnding', true);
  }
  /** @type {Handle} */

  function onexitsetextheadinglinesequence(token) {
    const node =
      /** @type {Heading} */
      this.stack[this.stack.length - 1];
    node.depth = this.sliceSerialize(token).charCodeAt(0) === 61 ? 1 : 2;
  }
  /** @type {Handle} */

  function onexitsetextheading() {
    setData('setextHeadingSlurpLineEnding');
  }
  /** @type {Handle} */

  function onenterdata(token) {
    const parent =
      /** @type {Parent} */
      this.stack[this.stack.length - 1];
    /** @type {Node} */

    let tail = parent.children[parent.children.length - 1];

    if (!tail || tail.type !== 'text') {
      // Add a new text node.
      tail = text(); // @ts-expect-error: we‚Äôll add `end` later.

      tail.position = {
        start: point(token.start)
      }; // @ts-expect-error: Assume `parent` accepts `text`.

      parent.children.push(tail);
    }

    this.stack.push(tail);
  }
  /** @type {Handle} */

  function onexitdata(token) {
    const tail = this.stack.pop();
    tail.value += this.sliceSerialize(token);
    tail.position.end = point(token.end);
  }
  /** @type {Handle} */

  function onexitlineending(token) {
    const context = this.stack[this.stack.length - 1];

    // If we‚Äôre at a hard break, include the line ending in there.
    if (getData('atHardBreak')) {
      const tail = context.children[context.children.length - 1];
      tail.position.end = point(token.end);
      setData('atHardBreak');
      return
    }

    if (
      !getData('setextHeadingSlurpLineEnding') &&
      config.canContainEols.includes(context.type)
    ) {
      onenterdata.call(this, token);
      onexitdata.call(this, token);
    }
  }
  /** @type {Handle} */

  function onexithardbreak() {
    setData('atHardBreak', true);
  }
  /** @type {Handle} */

  function onexithtmlflow() {
    const data = this.resume();
    const node =
      /** @type {HTML} */
      this.stack[this.stack.length - 1];
    node.value = data;
  }
  /** @type {Handle} */

  function onexithtmltext() {
    const data = this.resume();
    const node =
      /** @type {HTML} */
      this.stack[this.stack.length - 1];
    node.value = data;
  }
  /** @type {Handle} */

  function onexitcodetext() {
    const data = this.resume();
    const node =
      /** @type {InlineCode} */
      this.stack[this.stack.length - 1];
    node.value = data;
  }
  /** @type {Handle} */

  function onexitlink() {
    const context =
      /** @type {Link & {identifier: string, label: string}} */
      this.stack[this.stack.length - 1]; // To do: clean.

    if (getData('inReference')) {
      context.type += 'Reference'; // @ts-expect-error: mutate.

      context.referenceType = getData('referenceType') || 'shortcut'; // @ts-expect-error: mutate.

      delete context.url;
      delete context.title;
    } else {
      // @ts-expect-error: mutate.
      delete context.identifier; // @ts-expect-error: mutate.

      delete context.label;
    }

    setData('referenceType');
  }
  /** @type {Handle} */

  function onexitimage() {
    const context =
      /** @type {Image & {identifier: string, label: string}} */
      this.stack[this.stack.length - 1]; // To do: clean.

    if (getData('inReference')) {
      context.type += 'Reference'; // @ts-expect-error: mutate.

      context.referenceType = getData('referenceType') || 'shortcut'; // @ts-expect-error: mutate.

      delete context.url;
      delete context.title;
    } else {
      // @ts-expect-error: mutate.
      delete context.identifier; // @ts-expect-error: mutate.

      delete context.label;
    }

    setData('referenceType');
  }
  /** @type {Handle} */

  function onexitlabeltext(token) {
    const ancestor =
      /** @type {(Link|Image) & {identifier: string, label: string}} */
      this.stack[this.stack.length - 2];
    const string = this.sliceSerialize(token);
    ancestor.label = decodeString(string);
    ancestor.identifier = normalizeIdentifier(string).toLowerCase();
  }
  /** @type {Handle} */

  function onexitlabel() {
    const fragment =
      /** @type {Fragment} */
      this.stack[this.stack.length - 1];
    const value = this.resume();
    const node =
      /** @type {(Link|Image) & {identifier: string, label: string}} */
      this.stack[this.stack.length - 1]; // Assume a reference.

    setData('inReference', true);

    if (node.type === 'link') {
      // @ts-expect-error: Assume static phrasing content.
      node.children = fragment.children;
    } else {
      node.alt = value;
    }
  }
  /** @type {Handle} */

  function onexitresourcedestinationstring() {
    const data = this.resume();
    const node =
      /** @type {Link|Image} */
      this.stack[this.stack.length - 1];
    node.url = data;
  }
  /** @type {Handle} */

  function onexitresourcetitlestring() {
    const data = this.resume();
    const node =
      /** @type {Link|Image} */
      this.stack[this.stack.length - 1];
    node.title = data;
  }
  /** @type {Handle} */

  function onexitresource() {
    setData('inReference');
  }
  /** @type {Handle} */

  function onenterreference() {
    setData('referenceType', 'collapsed');
  }
  /** @type {Handle} */

  function onexitreferencestring(token) {
    const label = this.resume();
    const node =
      /** @type {LinkReference|ImageReference} */
      this.stack[this.stack.length - 1];
    node.label = label;
    node.identifier = normalizeIdentifier(
      this.sliceSerialize(token)
    ).toLowerCase();
    setData('referenceType', 'full');
  }
  /** @type {Handle} */

  function onexitcharacterreferencemarker(token) {
    setData('characterReferenceType', token.type);
  }
  /** @type {Handle} */

  function onexitcharacterreferencevalue(token) {
    const data = this.sliceSerialize(token);
    const type = getData('characterReferenceType');
    /** @type {string} */

    let value;

    if (type) {
      value = decodeNumericCharacterReference(
        data,
        type === 'characterReferenceMarkerNumeric' ? 10 : 16
      );
      setData('characterReferenceType');
    } else {
      // @ts-expect-error `decodeNamedCharacterReference` can return false for
      // invalid named character references, but everything we‚Äôve tokenized is
      // valid.
      value = decodeNamedCharacterReference(data);
    }

    const tail = this.stack.pop();
    tail.value += value;
    tail.position.end = point(token.end);
  }
  /** @type {Handle} */

  function onexitautolinkprotocol(token) {
    onexitdata.call(this, token);
    const node =
      /** @type {Link} */
      this.stack[this.stack.length - 1];
    node.url = this.sliceSerialize(token);
  }
  /** @type {Handle} */

  function onexitautolinkemail(token) {
    onexitdata.call(this, token);
    const node =
      /** @type {Link} */
      this.stack[this.stack.length - 1];
    node.url = 'mailto:' + this.sliceSerialize(token);
  } //
  // Creaters.
  //

  /** @returns {Blockquote} */

  function blockQuote() {
    return {
      type: 'blockquote',
      children: []
    }
  }
  /** @returns {Code} */

  function codeFlow() {
    return {
      type: 'code',
      lang: null,
      meta: null,
      value: ''
    }
  }
  /** @returns {InlineCode} */

  function codeText() {
    return {
      type: 'inlineCode',
      value: ''
    }
  }
  /** @returns {Definition} */

  function definition() {
    return {
      type: 'definition',
      identifier: '',
      label: null,
      title: null,
      url: ''
    }
  }
  /** @returns {Emphasis} */

  function emphasis() {
    return {
      type: 'emphasis',
      children: []
    }
  }
  /** @returns {Heading} */

  function heading() {
    // @ts-expect-error `depth` will be set later.
    return {
      type: 'heading',
      depth: undefined,
      children: []
    }
  }
  /** @returns {Break} */

  function hardBreak() {
    return {
      type: 'break'
    }
  }
  /** @returns {HTML} */

  function html() {
    return {
      type: 'html',
      value: ''
    }
  }
  /** @returns {Image} */

  function image() {
    return {
      type: 'image',
      title: null,
      url: '',
      alt: null
    }
  }
  /** @returns {Link} */

  function link() {
    return {
      type: 'link',
      title: null,
      url: '',
      children: []
    }
  }
  /**
   * @param {Token} token
   * @returns {List}
   */

  function list(token) {
    return {
      type: 'list',
      ordered: token.type === 'listOrdered',
      start: null,
      // @ts-expect-error Patched.
      spread: token._spread,
      children: []
    }
  }
  /**
   * @param {Token} token
   * @returns {ListItem}
   */

  function listItem(token) {
    return {
      type: 'listItem',
      // @ts-expect-error Patched.
      spread: token._spread,
      checked: null,
      children: []
    }
  }
  /** @returns {Paragraph} */

  function paragraph() {
    return {
      type: 'paragraph',
      children: []
    }
  }
  /** @returns {Strong} */

  function strong() {
    return {
      type: 'strong',
      children: []
    }
  }
  /** @returns {Text} */

  function text() {
    return {
      type: 'text',
      value: ''
    }
  }
  /** @returns {ThematicBreak} */

  function thematicBreak() {
    return {
      type: 'thematicBreak'
    }
  }
}
/**
 * @param {Extension} combined
 * @param {Array<Extension|Array<Extension>>} extensions
 * @returns {Extension}
 */

function configure(combined, extensions) {
  let index = -1;

  while (++index < extensions.length) {
    const value = extensions[index];

    if (Array.isArray(value)) {
      configure(combined, value);
    } else {
      extension(combined, value);
    }
  }

  return combined
}
/**
 * @param {Extension} combined
 * @param {Extension} extension
 * @returns {void}
 */

function extension(combined, extension) {
  /** @type {string} */
  let key;

  for (key in extension) {
    if (own$1.call(extension, key)) {
      const list = key === 'canContainEols' || key === 'transforms';
      const maybe = own$1.call(combined, key) ? combined[key] : undefined;
      /* c8 ignore next */

      const left = maybe || (combined[key] = list ? [] : {});
      const right = extension[key];

      if (right) {
        if (list) {
          // @ts-expect-error: `left` is an array.
          combined[key] = [...left, ...right];
        } else {
          Object.assign(left, right);
        }
      }
    }
  }
}
/** @type {OnEnterError} */

function defaultOnError(left, right) {
  if (left) {
    throw new Error(
      'Cannot close `' +
        left.type +
        '` (' +
        stringifyPosition({
          start: left.start,
          end: left.end
        }) +
        '): a different token (`' +
        right.type +
        '`, ' +
        stringifyPosition({
          start: right.start,
          end: right.end
        }) +
        ') is open'
    )
  } else {
    throw new Error(
      'Cannot close document, a token (`' +
        right.type +
        '`, ' +
        stringifyPosition({
          start: right.start,
          end: right.end
        }) +
        ') is still open'
    )
  }
}

var codes = {
  horizontalTab: -2,
  virtualSpace: -1,
  nul: 0,
  eof: null,
  space: 32
};

function markdownLineEndingOrSpace(code) {
  return code < codes.nul || code === codes.space;
}

function markdownLineEnding(code) {
  return code < codes.horizontalTab;
}

function wikiLink() {
  var opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
  var aliasDivider = opts.aliasDivider || ':';
  var aliasMarker = aliasDivider;
  var startMarker = '[[';
  var endMarker = ']]';

  function tokenize(effects, ok, nok) {
    var data;
    var alias;
    var aliasCursor = 0;
    var startMarkerCursor = 0;
    var endMarkerCursor = 0;
    return start;

    function start(code) {
      if (code !== startMarker.charCodeAt(startMarkerCursor)) return nok(code);
      effects.enter('wikiLink');
      effects.enter('wikiLinkMarker');
      return consumeStart(code);
    }

    function consumeStart(code) {
      if (startMarkerCursor === startMarker.length) {
        effects.exit('wikiLinkMarker');
        return consumeData(code);
      }

      if (code !== startMarker.charCodeAt(startMarkerCursor)) {
        return nok(code);
      }

      effects.consume(code);
      startMarkerCursor++;
      return consumeStart;
    }

    function consumeData(code) {
      if (markdownLineEnding(code) || code === codes.eof) {
        return nok(code);
      }

      effects.enter('wikiLinkData');
      effects.enter('wikiLinkTarget');
      return consumeTarget(code);
    }

    function consumeTarget(code) {
      if (code === aliasMarker.charCodeAt(aliasCursor)) {
        if (!data) return nok(code);
        effects.exit('wikiLinkTarget');
        effects.enter('wikiLinkAliasMarker');
        return consumeAliasMarker(code);
      }

      if (code === endMarker.charCodeAt(endMarkerCursor)) {
        if (!data) return nok(code);
        effects.exit('wikiLinkTarget');
        effects.exit('wikiLinkData');
        effects.enter('wikiLinkMarker');
        return consumeEnd(code);
      }

      if (markdownLineEnding(code) || code === codes.eof) {
        return nok(code);
      }

      if (!markdownLineEndingOrSpace(code)) {
        data = true;
      }

      effects.consume(code);
      return consumeTarget;
    }

    function consumeAliasMarker(code) {
      if (aliasCursor === aliasMarker.length) {
        effects.exit('wikiLinkAliasMarker');
        effects.enter('wikiLinkAlias');
        return consumeAlias(code);
      }

      if (code !== aliasMarker.charCodeAt(aliasCursor)) {
        return nok(code);
      }

      effects.consume(code);
      aliasCursor++;
      return consumeAliasMarker;
    }

    function consumeAlias(code) {
      if (code === endMarker.charCodeAt(endMarkerCursor)) {
        if (!alias) return nok(code);
        effects.exit('wikiLinkAlias');
        effects.exit('wikiLinkData');
        effects.enter('wikiLinkMarker');
        return consumeEnd(code);
      }

      if (markdownLineEnding(code) || code === codes.eof) {
        return nok(code);
      }

      if (!markdownLineEndingOrSpace(code)) {
        alias = true;
      }

      effects.consume(code);
      return consumeAlias;
    }

    function consumeEnd(code) {
      if (endMarkerCursor === endMarker.length) {
        effects.exit('wikiLinkMarker');
        effects.exit('wikiLink');
        return ok(code);
      }

      if (code !== endMarker.charCodeAt(endMarkerCursor)) {
        return nok(code);
      }

      effects.consume(code);
      endMarkerCursor++;
      return consumeEnd;
    }
  }

  var call = {
    tokenize: tokenize
  };
  return {
    text: {
      91: call
    } // left square bracket

  };
}
var syntax = wikiLink;

function fromMarkdown() {
  var opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
  var permalinks = opts.permalinks || [];

  var defaultPageResolver = function defaultPageResolver(name) {
    return [name.replace(/ /g, '_').toLowerCase()];
  };

  var pageResolver = opts.pageResolver || defaultPageResolver;
  var newClassName = opts.newClassName || 'new';
  var wikiLinkClassName = opts.wikiLinkClassName || 'internal';

  var defaultHrefTemplate = function defaultHrefTemplate(permalink) {
    return "#/page/".concat(permalink);
  };

  var hrefTemplate = opts.hrefTemplate || defaultHrefTemplate;

  function enterWikiLink(token) {
    this.enter({
      type: 'wikiLink',
      value: null,
      data: {
        alias: null,
        permalink: null,
        exists: null
      }
    }, token);
  }

  function top(stack) {
    return stack[stack.length - 1];
  }

  function exitWikiLinkAlias(token) {
    var alias = this.sliceSerialize(token);
    var current = top(this.stack);
    current.data.alias = alias;
  }

  function exitWikiLinkTarget(token) {
    var target = this.sliceSerialize(token);
    var current = top(this.stack);
    current.value = target;
  }

  function exitWikiLink(token) {
    var wikiLink = this.exit(token);
    var pagePermalinks = pageResolver(wikiLink.value);
    var permalink = pagePermalinks.find(function (p) {
      return permalinks.indexOf(p) !== -1;
    });
    var exists = permalink !== undefined;

    if (!exists) {
      permalink = pagePermalinks[0];
    }

    var displayName = wikiLink.value;

    if (wikiLink.data.alias) {
      displayName = wikiLink.data.alias;
    }

    var classNames = wikiLinkClassName;

    if (!exists) {
      classNames += ' ' + newClassName;
    }

    wikiLink.data.alias = displayName;
    wikiLink.data.permalink = permalink;
    wikiLink.data.exists = exists;
    wikiLink.data.hName = 'a';
    wikiLink.data.hProperties = {
      className: classNames,
      href: hrefTemplate(permalink)
    };
    wikiLink.data.hChildren = [{
      type: 'text',
      value: displayName
    }];
  }

  return {
    enter: {
      wikiLink: enterWikiLink
    },
    exit: {
      wikiLinkTarget: exitWikiLinkTarget,
      wikiLinkAlias: exitWikiLinkAlias,
      wikiLink: exitWikiLink
    }
  };
}

var fromMarkdown_1 = fromMarkdown;

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Previous} Previous
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Code} Code
 */
const www = {
  tokenize: tokenizeWww,
  partial: true
};
const domain = {
  tokenize: tokenizeDomain,
  partial: true
};
const path = {
  tokenize: tokenizePath,
  partial: true
};
const punctuation = {
  tokenize: tokenizePunctuation,
  partial: true
};
const namedCharacterReference = {
  tokenize: tokenizeNamedCharacterReference,
  partial: true
};
const wwwAutolink = {
  tokenize: tokenizeWwwAutolink,
  previous: previousWww
};
const httpAutolink = {
  tokenize: tokenizeHttpAutolink,
  previous: previousHttp
};
const emailAutolink = {
  tokenize: tokenizeEmailAutolink,
  previous: previousEmail
};
/** @type {ConstructRecord} */

const text = {};
/** @type {Extension} */

const gfmAutolinkLiteral = {
  text
};
let code = 48; // Add alphanumerics.

while (code < 123) {
  text[code] = emailAutolink;
  code++;
  if (code === 58) code = 65;
  else if (code === 91) code = 97;
}

text[43] = emailAutolink;
text[45] = emailAutolink;
text[46] = emailAutolink;
text[95] = emailAutolink;
text[72] = [emailAutolink, httpAutolink];
text[104] = [emailAutolink, httpAutolink];
text[87] = [emailAutolink, wwwAutolink];
text[119] = [emailAutolink, wwwAutolink];
/** @type {Tokenizer} */

function tokenizeEmailAutolink(effects, ok, nok) {
  const self = this;
  /** @type {boolean} */

  let hasDot;
  /** @type {boolean|undefined} */

  let hasDigitInLastSegment;
  return start
  /** @type {State} */

  function start(code) {
    if (
      !gfmAtext(code) ||
      !previousEmail(self.previous) ||
      previousUnbalanced(self.events)
    ) {
      return nok(code)
    }

    effects.enter('literalAutolink');
    effects.enter('literalAutolinkEmail');
    return atext(code)
  }
  /** @type {State} */

  function atext(code) {
    if (gfmAtext(code)) {
      effects.consume(code);
      return atext
    }

    if (code === 64) {
      effects.consume(code);
      return label
    }

    return nok(code)
  }
  /** @type {State} */

  function label(code) {
    if (code === 46) {
      return effects.check(punctuation, done, dotContinuation)(code)
    }

    if (code === 45 || code === 95) {
      return effects.check(punctuation, nok, dashOrUnderscoreContinuation)(code)
    }

    if (asciiAlphanumeric(code)) {
      if (!hasDigitInLastSegment && asciiDigit(code)) {
        hasDigitInLastSegment = true;
      }

      effects.consume(code);
      return label
    }

    return done(code)
  }
  /** @type {State} */

  function dotContinuation(code) {
    effects.consume(code);
    hasDot = true;
    hasDigitInLastSegment = undefined;
    return label
  }
  /** @type {State} */

  function dashOrUnderscoreContinuation(code) {
    effects.consume(code);
    return afterDashOrUnderscore
  }
  /** @type {State} */

  function afterDashOrUnderscore(code) {
    if (code === 46) {
      return effects.check(punctuation, nok, dotContinuation)(code)
    }

    return label(code)
  }
  /** @type {State} */

  function done(code) {
    if (hasDot && !hasDigitInLastSegment) {
      effects.exit('literalAutolinkEmail');
      effects.exit('literalAutolink');
      return ok(code)
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeWwwAutolink(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    if (
      (code !== 87 && code !== 119) ||
      !previousWww(self.previous) ||
      previousUnbalanced(self.events)
    ) {
      return nok(code)
    }

    effects.enter('literalAutolink');
    effects.enter('literalAutolinkWww'); // For `www.` we check instead of attempt, because when it matches, GH
    // treats it as part of a domain (yes, it says a valid domain must come
    // after `www.`, but that‚Äôs not how it‚Äôs implemented by them).

    return effects.check(
      www,
      effects.attempt(domain, effects.attempt(path, done), nok),
      nok
    )(code)
  }
  /** @type {State} */

  function done(code) {
    effects.exit('literalAutolinkWww');
    effects.exit('literalAutolink');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeHttpAutolink(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    if (
      (code !== 72 && code !== 104) ||
      !previousHttp(self.previous) ||
      previousUnbalanced(self.events)
    ) {
      return nok(code)
    }

    effects.enter('literalAutolink');
    effects.enter('literalAutolinkHttp');
    effects.consume(code);
    return t1
  }
  /** @type {State} */

  function t1(code) {
    if (code === 84 || code === 116) {
      effects.consume(code);
      return t2
    }

    return nok(code)
  }
  /** @type {State} */

  function t2(code) {
    if (code === 84 || code === 116) {
      effects.consume(code);
      return p
    }

    return nok(code)
  }
  /** @type {State} */

  function p(code) {
    if (code === 80 || code === 112) {
      effects.consume(code);
      return s
    }

    return nok(code)
  }
  /** @type {State} */

  function s(code) {
    if (code === 83 || code === 115) {
      effects.consume(code);
      return colon
    }

    return colon(code)
  }
  /** @type {State} */

  function colon(code) {
    if (code === 58) {
      effects.consume(code);
      return slash1
    }

    return nok(code)
  }
  /** @type {State} */

  function slash1(code) {
    if (code === 47) {
      effects.consume(code);
      return slash2
    }

    return nok(code)
  }
  /** @type {State} */

  function slash2(code) {
    if (code === 47) {
      effects.consume(code);
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    return code === null ||
      asciiControl(code) ||
      unicodeWhitespace(code) ||
      unicodePunctuation(code)
      ? nok(code)
      : effects.attempt(domain, effects.attempt(path, done), nok)(code)
  }
  /** @type {State} */

  function done(code) {
    effects.exit('literalAutolinkHttp');
    effects.exit('literalAutolink');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeWww(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.consume(code);
    return w2
  }
  /** @type {State} */

  function w2(code) {
    if (code === 87 || code === 119) {
      effects.consume(code);
      return w3
    }

    return nok(code)
  }
  /** @type {State} */

  function w3(code) {
    if (code === 87 || code === 119) {
      effects.consume(code);
      return dot
    }

    return nok(code)
  }
  /** @type {State} */

  function dot(code) {
    if (code === 46) {
      effects.consume(code);
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    return code === null || markdownLineEnding$1(code) ? nok(code) : ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeDomain(effects, ok, nok) {
  /** @type {boolean|undefined} */
  let hasUnderscoreInLastSegment;
  /** @type {boolean|undefined} */

  let hasUnderscoreInLastLastSegment;
  return domain
  /** @type {State} */

  function domain(code) {
    if (code === 38) {
      return effects.check(
        namedCharacterReference,
        done,
        punctuationContinuation
      )(code)
    }

    if (code === 46 || code === 95) {
      return effects.check(punctuation, done, punctuationContinuation)(code)
    } // GH documents that only alphanumerics (other than `-`, `.`, and `_`) can
    // occur, which sounds like ASCII only, but they also support `www.ÈªûÁúã.com`,
    // so that‚Äôs Unicode.
    // Instead of some new production for Unicode alphanumerics, markdown
    // already has that for Unicode punctuation and whitespace, so use those.

    if (
      code === null ||
      asciiControl(code) ||
      unicodeWhitespace(code) ||
      (code !== 45 && unicodePunctuation(code))
    ) {
      return done(code)
    }

    effects.consume(code);
    return domain
  }
  /** @type {State} */

  function punctuationContinuation(code) {
    if (code === 46) {
      hasUnderscoreInLastLastSegment = hasUnderscoreInLastSegment;
      hasUnderscoreInLastSegment = undefined;
      effects.consume(code);
      return domain
    }

    if (code === 95) hasUnderscoreInLastSegment = true;
    effects.consume(code);
    return domain
  }
  /** @type {State} */

  function done(code) {
    if (!hasUnderscoreInLastLastSegment && !hasUnderscoreInLastSegment) {
      return ok(code)
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizePath(effects, ok) {
  let balance = 0;
  return inPath
  /** @type {State} */

  function inPath(code) {
    if (code === 38) {
      return effects.check(
        namedCharacterReference,
        ok,
        continuedPunctuation
      )(code)
    }

    if (code === 40) {
      balance++;
    }

    if (code === 41) {
      return effects.check(
        punctuation,
        parenAtPathEnd,
        continuedPunctuation
      )(code)
    }

    if (pathEnd(code)) {
      return ok(code)
    }

    if (trailingPunctuation(code)) {
      return effects.check(punctuation, ok, continuedPunctuation)(code)
    }

    effects.consume(code);
    return inPath
  }
  /** @type {State} */

  function continuedPunctuation(code) {
    effects.consume(code);
    return inPath
  }
  /** @type {State} */

  function parenAtPathEnd(code) {
    balance--;
    return balance < 0 ? ok(code) : continuedPunctuation(code)
  }
}
/** @type {Tokenizer} */

function tokenizeNamedCharacterReference(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.consume(code);
    return inside
  }
  /** @type {State} */

  function inside(code) {
    if (asciiAlpha(code)) {
      effects.consume(code);
      return inside
    }

    if (code === 59) {
      effects.consume(code);
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    // If the named character reference is followed by the end of the path, it‚Äôs
    // not continued punctuation.
    return pathEnd(code) ? ok(code) : nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizePunctuation(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.consume(code);
    return after
  }
  /** @type {State} */

  function after(code) {
    // Check the next.
    if (trailingPunctuation(code)) {
      effects.consume(code);
      return after
    } // If the punctuation marker is followed by the end of the path, it‚Äôs not
    // continued punctuation.

    return pathEnd(code) ? ok(code) : nok(code)
  }
}
/**
 * @param {Code} code
 * @returns {boolean}
 */

function trailingPunctuation(code) {
  return (
    code === 33 ||
    code === 34 ||
    code === 39 ||
    code === 41 ||
    code === 42 ||
    code === 44 ||
    code === 46 ||
    code === 58 ||
    code === 59 ||
    code === 60 ||
    code === 63 ||
    code === 95 ||
    code === 126
  )
}
/**
 * @param {Code} code
 * @returns {boolean}
 */

function pathEnd(code) {
  return code === null || code === 60 || markdownLineEndingOrSpace$1(code)
}
/**
 * @param {Code} code
 * @returns {boolean}
 */

function gfmAtext(code) {
  return (
    code === 43 ||
    code === 45 ||
    code === 46 ||
    code === 95 ||
    asciiAlphanumeric(code)
  )
}
/** @type {Previous} */

function previousWww(code) {
  return (
    code === null ||
    code === 40 ||
    code === 42 ||
    code === 95 ||
    code === 126 ||
    markdownLineEndingOrSpace$1(code)
  )
}
/** @type {Previous} */

function previousHttp(code) {
  return code === null || !asciiAlpha(code)
}
/** @type {Previous} */

function previousEmail(code) {
  return code !== 47 && previousHttp(code)
}
/**
 * @param {Array<Event>} events
 * @returns {boolean}
 */

function previousUnbalanced(events) {
  let index = events.length;
  let result = false;

  while (index--) {
    const token = events[index][1];

    if (
      (token.type === 'labelLink' || token.type === 'labelImage') &&
      !token._balanced
    ) {
      result = true;
      break
    } // @ts-expect-error If we‚Äôve seen this token, and it was marked as not
    // having any unbalanced bracket before it, we can exit.

    if (token._gfmAutolinkLiteralWalkedInto) {
      result = false;
      break
    }
  }

  if (events.length > 0 && !result) {
    // @ts-expect-error Mark the last token as ‚Äúwalked into‚Äù w/o finding
    // anything.
    events[events.length - 1][1]._gfmAutolinkLiteralWalkedInto = true;
  }

  return result
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Exiter} Exiter
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Event} Event
 */
const indent = {
  tokenize: tokenizeIndent,
  partial: true
};
/**
 * @returns {Extension}
 */

function gfmFootnote() {
  /** @type {Extension} */
  return {
    document: {
      [91]: {
        tokenize: tokenizeDefinitionStart,
        continuation: {
          tokenize: tokenizeDefinitionContinuation
        },
        exit: gfmFootnoteDefinitionEnd
      }
    },
    text: {
      [91]: {
        tokenize: tokenizeGfmFootnoteCall
      },
      [93]: {
        add: 'after',
        tokenize: tokenizePotentialGfmFootnoteCall,
        resolveTo: resolveToPotentialGfmFootnoteCall
      }
    }
  }
}
/** @type {Tokenizer} */

function tokenizePotentialGfmFootnoteCall(effects, ok, nok) {
  const self = this;
  let index = self.events.length;
  /** @type {Array<string>} */
  // @ts-expect-error It‚Äôs fine!

  const defined = self.parser.gfmFootnotes || (self.parser.gfmFootnotes = []);
  /** @type {Token} */

  let labelStart; // Find an opening.

  while (index--) {
    const token = self.events[index][1];

    if (token.type === 'labelImage') {
      labelStart = token;
      break
    } // Exit if we‚Äôve walked far enough.

    if (
      token.type === 'gfmFootnoteCall' ||
      token.type === 'labelLink' ||
      token.type === 'label' ||
      token.type === 'image' ||
      token.type === 'link'
    ) {
      break
    }
  }

  return start
  /** @type {State} */

  function start(code) {
    if (!labelStart || !labelStart._balanced) {
      return nok(code)
    }

    const id = normalizeIdentifier(
      self.sliceSerialize({
        start: labelStart.end,
        end: self.now()
      })
    );

    if (id.charCodeAt(0) !== 94 || !defined.includes(id.slice(1))) {
      return nok(code)
    }

    effects.enter('gfmFootnoteCallLabelMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteCallLabelMarker');
    return ok(code)
  }
}
/** @type {Resolver} */

function resolveToPotentialGfmFootnoteCall(events, context) {
  let index = events.length;

  while (index--) {
    if (
      events[index][1].type === 'labelImage' &&
      events[index][0] === 'enter'
    ) {
      events[index][1];
      break
    }
  }

  // Change the `labelImageMarker` to a `data`.
  events[index + 1][1].type = 'data';
  events[index + 3][1].type = 'gfmFootnoteCallLabelMarker'; // The whole (without `!`):

  const call = {
    type: 'gfmFootnoteCall',
    start: Object.assign({}, events[index + 3][1].start),
    end: Object.assign({}, events[events.length - 1][1].end)
  }; // The `^` marker

  const marker = {
    type: 'gfmFootnoteCallMarker',
    start: Object.assign({}, events[index + 3][1].end),
    end: Object.assign({}, events[index + 3][1].end)
  }; // Increment the end 1 character.

  marker.end.column++;
  marker.end.offset++;
  marker.end._bufferIndex++;
  const string = {
    type: 'gfmFootnoteCallString',
    start: Object.assign({}, marker.end),
    end: Object.assign({}, events[events.length - 1][1].start)
  };
  const chunk = {
    type: 'chunkString',
    contentType: 'string',
    start: Object.assign({}, string.start),
    end: Object.assign({}, string.end)
  };
  /** @type {Array<Event>} */

  const replacement = [
    // Take the `labelImageMarker` (now `data`, the `!`)
    events[index + 1],
    events[index + 2],
    ['enter', call, context], // The `[`
    events[index + 3],
    events[index + 4], // The `^`.
    ['enter', marker, context],
    ['exit', marker, context], // Everything in between.
    ['enter', string, context],
    ['enter', chunk, context],
    ['exit', chunk, context],
    ['exit', string, context], // The ending (`]`, properly parsed and labelled).
    events[events.length - 2],
    events[events.length - 1],
    ['exit', call, context]
  ];
  events.splice(index, events.length - index + 1, ...replacement);
  return events
}
/** @type {Tokenizer} */

function tokenizeGfmFootnoteCall(effects, ok, nok) {
  const self = this;
  /** @type {Array<string>} */
  // @ts-expect-error It‚Äôs fine!

  const defined = self.parser.gfmFootnotes || (self.parser.gfmFootnotes = []);
  let size = 0;
  /** @type {boolean} */

  let data;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('gfmFootnoteCall');
    effects.enter('gfmFootnoteCallLabelMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteCallLabelMarker');
    return callStart
  }
  /** @type {State} */

  function callStart(code) {
    if (code !== 94) return nok(code)
    effects.enter('gfmFootnoteCallMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteCallMarker');
    effects.enter('gfmFootnoteCallString');
    effects.enter('chunkString').contentType = 'string';
    return callData
  }
  /** @type {State} */

  function callData(code) {
    /** @type {Token} */
    let token;

    if (code === null || code === 91 || size++ > 999) {
      return nok(code)
    }

    if (code === 93) {
      if (!data) {
        return nok(code)
      }

      effects.exit('chunkString');
      token = effects.exit('gfmFootnoteCallString');
      return defined.includes(normalizeIdentifier(self.sliceSerialize(token)))
        ? end(code)
        : nok(code)
    }

    effects.consume(code);

    if (!markdownLineEndingOrSpace$1(code)) {
      data = true;
    }

    return code === 92 ? callEscape : callData
  }
  /** @type {State} */

  function callEscape(code) {
    if (code === 91 || code === 92 || code === 93) {
      effects.consume(code);
      size++;
      return callData
    }

    return callData(code)
  }
  /** @type {State} */

  function end(code) {
    effects.enter('gfmFootnoteCallLabelMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteCallLabelMarker');
    effects.exit('gfmFootnoteCall');
    return ok
  }
}
/** @type {Tokenizer} */

function tokenizeDefinitionStart(effects, ok, nok) {
  const self = this;
  /** @type {Array<string>} */
  // @ts-expect-error It‚Äôs fine!

  const defined = self.parser.gfmFootnotes || (self.parser.gfmFootnotes = []);
  /** @type {string} */

  let identifier;
  let size = 0;
  /** @type {boolean|undefined} */

  let data;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('gfmFootnoteDefinition')._container = true;
    effects.enter('gfmFootnoteDefinitionLabel');
    effects.enter('gfmFootnoteDefinitionLabelMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteDefinitionLabelMarker');
    return labelStart
  }
  /** @type {State} */

  function labelStart(code) {
    if (code === 94) {
      effects.enter('gfmFootnoteDefinitionMarker');
      effects.consume(code);
      effects.exit('gfmFootnoteDefinitionMarker');
      effects.enter('gfmFootnoteDefinitionLabelString');
      return atBreak
    }

    return nok(code)
  }
  /** @type {State} */

  function atBreak(code) {
    /** @type {Token} */
    let token;

    if (code === null || code === 91 || size > 999) {
      return nok(code)
    }

    if (code === 93) {
      if (!data) {
        return nok(code)
      }

      token = effects.exit('gfmFootnoteDefinitionLabelString');
      identifier = normalizeIdentifier(self.sliceSerialize(token));
      effects.enter('gfmFootnoteDefinitionLabelMarker');
      effects.consume(code);
      effects.exit('gfmFootnoteDefinitionLabelMarker');
      effects.exit('gfmFootnoteDefinitionLabel');
      return labelAfter
    }

    if (markdownLineEnding$1(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      size++;
      return atBreak
    }

    effects.enter('chunkString').contentType = 'string';
    return label(code)
  }
  /** @type {State} */

  function label(code) {
    if (
      code === null ||
      markdownLineEnding$1(code) ||
      code === 91 ||
      code === 93 ||
      size > 999
    ) {
      effects.exit('chunkString');
      return atBreak(code)
    }

    if (!markdownLineEndingOrSpace$1(code)) {
      data = true;
    }

    size++;
    effects.consume(code);
    return code === 92 ? labelEscape : label
  }
  /** @type {State} */

  function labelEscape(code) {
    if (code === 91 || code === 92 || code === 93) {
      effects.consume(code);
      size++;
      return label
    }

    return label(code)
  }
  /** @type {State} */

  function labelAfter(code) {
    if (code === 58) {
      effects.enter('definitionMarker');
      effects.consume(code);
      effects.exit('definitionMarker'); // Any whitespace after the marker is eaten, forming indented code
      // is not possible.
      // No space is also fine, just like a block quote marker.

      return factorySpace(effects, done, 'gfmFootnoteDefinitionWhitespace')
    }

    return nok(code)
  }
  /** @type {State} */

  function done(code) {
    if (!defined.includes(identifier)) {
      defined.push(identifier);
    }

    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeDefinitionContinuation(effects, ok, nok) {
  // Either a blank line, which is okay, or an indented thing.
  return effects.check(blankLine, ok, effects.attempt(indent, ok, nok))
}
/** @type {Exiter} */

function gfmFootnoteDefinitionEnd(effects) {
  effects.exit('gfmFootnoteDefinition');
}
/** @type {Tokenizer} */

function tokenizeIndent(effects, ok, nok) {
  const self = this;
  return factorySpace(
    effects,
    afterPrefix,
    'gfmFootnoteDefinitionIndent',
    4 + 1
  )
  /** @type {State} */

  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail &&
      tail[1].type === 'gfmFootnoteDefinitionIndent' &&
      tail[2].sliceSerialize(tail[1], true).length === 4
      ? ok(code)
      : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Event} Event
 */

/**
 * @param {Options} [options]
 * @returns {Extension}
 */
function gfmStrikethrough(options = {}) {
  let single = options.singleTilde;
  const tokenizer = {
    tokenize: tokenizeStrikethrough,
    resolveAll: resolveAllStrikethrough
  };

  if (single === null || single === undefined) {
    single = true;
  }

  return {
    text: {
      [126]: tokenizer
    },
    insideSpan: {
      null: [tokenizer]
    },
    attentionMarkers: {
      null: [126]
    }
  }
  /**
   * Take events and resolve strikethrough.
   *
   * @type {Resolver}
   */

  function resolveAllStrikethrough(events, context) {
    let index = -1; // Walk through all events.

    while (++index < events.length) {
      // Find a token that can close.
      if (
        events[index][0] === 'enter' &&
        events[index][1].type === 'strikethroughSequenceTemporary' &&
        events[index][1]._close
      ) {
        let open = index; // Now walk back to find an opener.

        while (open--) {
          // Find a token that can open the closer.
          if (
            events[open][0] === 'exit' &&
            events[open][1].type === 'strikethroughSequenceTemporary' &&
            events[open][1]._open && // If the sizes are the same:
            events[index][1].end.offset - events[index][1].start.offset ===
              events[open][1].end.offset - events[open][1].start.offset
          ) {
            events[index][1].type = 'strikethroughSequence';
            events[open][1].type = 'strikethroughSequence';
            const strikethrough = {
              type: 'strikethrough',
              start: Object.assign({}, events[open][1].start),
              end: Object.assign({}, events[index][1].end)
            };
            const text = {
              type: 'strikethroughText',
              start: Object.assign({}, events[open][1].end),
              end: Object.assign({}, events[index][1].start)
            }; // Opening.

            const nextEvents = [
              ['enter', strikethrough, context],
              ['enter', events[open][1], context],
              ['exit', events[open][1], context],
              ['enter', text, context]
            ]; // Between.

            splice(
              nextEvents,
              nextEvents.length,
              0,
              resolveAll(
                context.parser.constructs.insideSpan.null,
                events.slice(open + 1, index),
                context
              )
            ); // Closing.

            splice(nextEvents, nextEvents.length, 0, [
              ['exit', text, context],
              ['enter', events[index][1], context],
              ['exit', events[index][1], context],
              ['exit', strikethrough, context]
            ]);
            splice(events, open - 1, index - open + 3, nextEvents);
            index = open + nextEvents.length - 2;
            break
          }
        }
      }
    }

    index = -1;

    while (++index < events.length) {
      if (events[index][1].type === 'strikethroughSequenceTemporary') {
        events[index][1].type = 'data';
      }
    }

    return events
  }
  /** @type {Tokenizer} */

  function tokenizeStrikethrough(effects, ok, nok) {
    const previous = this.previous;
    const events = this.events;
    let size = 0;
    return start
    /** @type {State} */

    function start(code) {
      if (
        previous === 126 &&
        events[events.length - 1][1].type !== 'characterEscape'
      ) {
        return nok(code)
      }

      effects.enter('strikethroughSequenceTemporary');
      return more(code)
    }
    /** @type {State} */

    function more(code) {
      const before = classifyCharacter(previous);

      if (code === 126) {
        // If this is the third marker, exit.
        if (size > 1) return nok(code)
        effects.consume(code);
        size++;
        return more
      }

      if (size < 2 && !single) return nok(code)
      const token = effects.exit('strikethroughSequenceTemporary');
      const after = classifyCharacter(code);
      token._open = !after || (after === 2 && Boolean(before));
      token._close = !before || (before === 2 && Boolean(after));
      return ok(code)
    }
  }
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Token} Token
 */

/** @type {Extension} */
const gfmTable = {
  flow: {
    null: {
      tokenize: tokenizeTable,
      resolve: resolveTable
    }
  }
};
const nextPrefixedOrBlank = {
  tokenize: tokenizeNextPrefixedOrBlank,
  partial: true
};
/** @type {Resolver} */

function resolveTable(events, context) {
  let index = -1;
  /** @type {boolean|undefined} */

  let inHead;
  /** @type {boolean|undefined} */

  let inDelimiterRow;
  /** @type {boolean|undefined} */

  let inRow;
  /** @type {number|undefined} */

  let contentStart;
  /** @type {number|undefined} */

  let contentEnd;
  /** @type {number|undefined} */

  let cellStart;
  /** @type {boolean|undefined} */

  let seenCellInRow;

  while (++index < events.length) {
    const token = events[index][1];

    if (inRow) {
      if (token.type === 'temporaryTableCellContent') {
        contentStart = contentStart || index;
        contentEnd = index;
      }

      if (
        // Combine separate content parts into one.
        (token.type === 'tableCellDivider' || token.type === 'tableRow') &&
        contentEnd
      ) {
        const content = {
          type: 'tableContent',
          start: events[contentStart][1].start,
          end: events[contentEnd][1].end
        };
        /** @type {Token} */

        const text = {
          type: 'chunkText',
          start: content.start,
          end: content.end,
          // @ts-expect-error It‚Äôs fine.
          contentType: 'text'
        };
        events.splice(
          contentStart,
          contentEnd - contentStart + 1,
          ['enter', content, context],
          ['enter', text, context],
          ['exit', text, context],
          ['exit', content, context]
        );
        index -= contentEnd - contentStart - 3;
        contentStart = undefined;
        contentEnd = undefined;
      }
    }

    if (
      events[index][0] === 'exit' &&
      cellStart !== undefined &&
      cellStart + (seenCellInRow ? 0 : 1) < index &&
      (token.type === 'tableCellDivider' ||
        (token.type === 'tableRow' &&
          (cellStart + 3 < index ||
            events[cellStart][1].type !== 'whitespace')))
    ) {
      const cell = {
        type: inDelimiterRow
          ? 'tableDelimiter'
          : inHead
          ? 'tableHeader'
          : 'tableData',
        start: events[cellStart][1].start,
        end: events[index][1].end
      };
      events.splice(index + (token.type === 'tableCellDivider' ? 1 : 0), 0, [
        'exit',
        cell,
        context
      ]);
      events.splice(cellStart, 0, ['enter', cell, context]);
      index += 2;
      cellStart = index + 1;
      seenCellInRow = true;
    }

    if (token.type === 'tableRow') {
      inRow = events[index][0] === 'enter';

      if (inRow) {
        cellStart = index + 1;
        seenCellInRow = false;
      }
    }

    if (token.type === 'tableDelimiterRow') {
      inDelimiterRow = events[index][0] === 'enter';

      if (inDelimiterRow) {
        cellStart = index + 1;
        seenCellInRow = false;
      }
    }

    if (token.type === 'tableHead') {
      inHead = events[index][0] === 'enter';
    }
  }

  return events
}
/** @type {Tokenizer} */

function tokenizeTable(effects, ok, nok) {
  const self = this;
  /** @type {Array<Align>} */

  const align = [];
  let tableHeaderCount = 0;
  /** @type {boolean|undefined} */

  let seenDelimiter;
  /** @type {boolean|undefined} */

  let hasDash;
  return start
  /** @type {State} */

  function start(code) {
    // @ts-expect-error Custom.
    effects.enter('table')._align = align;
    effects.enter('tableHead');
    effects.enter('tableRow'); // If we start with a pipe, we open a cell marker.

    if (code === 124) {
      return cellDividerHead(code)
    }

    tableHeaderCount++;
    effects.enter('temporaryTableCellContent'); // Can‚Äôt be space or eols at the start of a construct, so we‚Äôre in a cell.

    return inCellContentHead(code)
  }
  /** @type {State} */

  function cellDividerHead(code) {
    effects.enter('tableCellDivider');
    effects.consume(code);
    effects.exit('tableCellDivider');
    seenDelimiter = true;
    return cellBreakHead
  }
  /** @type {State} */

  function cellBreakHead(code) {
    if (code === null || markdownLineEnding$1(code)) {
      return atRowEndHead(code)
    }

    if (markdownSpace(code)) {
      effects.enter('whitespace');
      effects.consume(code);
      return inWhitespaceHead
    }

    if (seenDelimiter) {
      seenDelimiter = undefined;
      tableHeaderCount++;
    }

    if (code === 124) {
      return cellDividerHead(code)
    } // Anything else is cell content.

    effects.enter('temporaryTableCellContent');
    return inCellContentHead(code)
  }
  /** @type {State} */

  function inWhitespaceHead(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return inWhitespaceHead
    }

    effects.exit('whitespace');
    return cellBreakHead(code)
  }
  /** @type {State} */

  function inCellContentHead(code) {
    // EOF, whitespace, pipe
    if (code === null || code === 124 || markdownLineEndingOrSpace$1(code)) {
      effects.exit('temporaryTableCellContent');
      return cellBreakHead(code)
    }

    effects.consume(code);
    return code === 92 ? inCellContentEscapeHead : inCellContentHead
  }
  /** @type {State} */

  function inCellContentEscapeHead(code) {
    if (code === 92 || code === 124) {
      effects.consume(code);
      return inCellContentHead
    } // Anything else.

    return inCellContentHead(code)
  }
  /** @type {State} */

  function atRowEndHead(code) {
    if (code === null) {
      return nok(code)
    }

    effects.exit('tableRow');
    effects.exit('tableHead');
    const originalInterrupt = self.interrupt;
    self.interrupt = true;
    return effects.attempt(
      {
        tokenize: tokenizeRowEnd,
        partial: true
      },
      function (code) {
        self.interrupt = originalInterrupt;
        effects.enter('tableDelimiterRow');
        return atDelimiterRowBreak(code)
      },
      function (code) {
        self.interrupt = originalInterrupt;
        return nok(code)
      }
    )(code)
  }
  /** @type {State} */

  function atDelimiterRowBreak(code) {
    if (code === null || markdownLineEnding$1(code)) {
      return rowEndDelimiter(code)
    }

    if (markdownSpace(code)) {
      effects.enter('whitespace');
      effects.consume(code);
      return inWhitespaceDelimiter
    }

    if (code === 45) {
      effects.enter('tableDelimiterFiller');
      effects.consume(code);
      hasDash = true;
      align.push('none');
      return inFillerDelimiter
    }

    if (code === 58) {
      effects.enter('tableDelimiterAlignment');
      effects.consume(code);
      effects.exit('tableDelimiterAlignment');
      align.push('left');
      return afterLeftAlignment
    } // If we start with a pipe, we open a cell marker.

    if (code === 124) {
      effects.enter('tableCellDivider');
      effects.consume(code);
      effects.exit('tableCellDivider');
      return atDelimiterRowBreak
    }

    return nok(code)
  }
  /** @type {State} */

  function inWhitespaceDelimiter(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return inWhitespaceDelimiter
    }

    effects.exit('whitespace');
    return atDelimiterRowBreak(code)
  }
  /** @type {State} */

  function inFillerDelimiter(code) {
    if (code === 45) {
      effects.consume(code);
      return inFillerDelimiter
    }

    effects.exit('tableDelimiterFiller');

    if (code === 58) {
      effects.enter('tableDelimiterAlignment');
      effects.consume(code);
      effects.exit('tableDelimiterAlignment');
      align[align.length - 1] =
        align[align.length - 1] === 'left' ? 'center' : 'right';
      return afterRightAlignment
    }

    return atDelimiterRowBreak(code)
  }
  /** @type {State} */

  function afterLeftAlignment(code) {
    if (code === 45) {
      effects.enter('tableDelimiterFiller');
      effects.consume(code);
      hasDash = true;
      return inFillerDelimiter
    } // Anything else is not ok.

    return nok(code)
  }
  /** @type {State} */

  function afterRightAlignment(code) {
    if (code === null || markdownLineEnding$1(code)) {
      return rowEndDelimiter(code)
    }

    if (markdownSpace(code)) {
      effects.enter('whitespace');
      effects.consume(code);
      return inWhitespaceDelimiter
    } // `|`

    if (code === 124) {
      effects.enter('tableCellDivider');
      effects.consume(code);
      effects.exit('tableCellDivider');
      return atDelimiterRowBreak
    }

    return nok(code)
  }
  /** @type {State} */

  function rowEndDelimiter(code) {
    effects.exit('tableDelimiterRow'); // Exit if there was no dash at all, or if the header cell count is not the
    // delimiter cell count.

    if (!hasDash || tableHeaderCount !== align.length) {
      return nok(code)
    }

    if (code === null) {
      return tableClose(code)
    }

    return effects.check(
      nextPrefixedOrBlank,
      tableClose,
      effects.attempt(
        {
          tokenize: tokenizeRowEnd,
          partial: true
        },
        factorySpace(effects, bodyStart, 'linePrefix', 4),
        tableClose
      )
    )(code)
  }
  /** @type {State} */

  function tableClose(code) {
    effects.exit('table');
    return ok(code)
  }
  /** @type {State} */

  function bodyStart(code) {
    effects.enter('tableBody');
    return rowStartBody(code)
  }
  /** @type {State} */

  function rowStartBody(code) {
    effects.enter('tableRow'); // If we start with a pipe, we open a cell marker.

    if (code === 124) {
      return cellDividerBody(code)
    }

    effects.enter('temporaryTableCellContent'); // Can‚Äôt be space or eols at the start of a construct, so we‚Äôre in a cell.

    return inCellContentBody(code)
  }
  /** @type {State} */

  function cellDividerBody(code) {
    effects.enter('tableCellDivider');
    effects.consume(code);
    effects.exit('tableCellDivider');
    return cellBreakBody
  }
  /** @type {State} */

  function cellBreakBody(code) {
    if (code === null || markdownLineEnding$1(code)) {
      return atRowEndBody(code)
    }

    if (markdownSpace(code)) {
      effects.enter('whitespace');
      effects.consume(code);
      return inWhitespaceBody
    } // `|`

    if (code === 124) {
      return cellDividerBody(code)
    } // Anything else is cell content.

    effects.enter('temporaryTableCellContent');
    return inCellContentBody(code)
  }
  /** @type {State} */

  function inWhitespaceBody(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return inWhitespaceBody
    }

    effects.exit('whitespace');
    return cellBreakBody(code)
  }
  /** @type {State} */

  function inCellContentBody(code) {
    // EOF, whitespace, pipe
    if (code === null || code === 124 || markdownLineEndingOrSpace$1(code)) {
      effects.exit('temporaryTableCellContent');
      return cellBreakBody(code)
    }

    effects.consume(code);
    return code === 92 ? inCellContentEscapeBody : inCellContentBody
  }
  /** @type {State} */

  function inCellContentEscapeBody(code) {
    if (code === 92 || code === 124) {
      effects.consume(code);
      return inCellContentBody
    } // Anything else.

    return inCellContentBody(code)
  }
  /** @type {State} */

  function atRowEndBody(code) {
    effects.exit('tableRow');

    if (code === null) {
      return tableBodyClose(code)
    }

    return effects.check(
      nextPrefixedOrBlank,
      tableBodyClose,
      effects.attempt(
        {
          tokenize: tokenizeRowEnd,
          partial: true
        },
        factorySpace(effects, rowStartBody, 'linePrefix', 4),
        tableBodyClose
      )
    )(code)
  }
  /** @type {State} */

  function tableBodyClose(code) {
    effects.exit('tableBody');
    return tableClose(code)
  }
  /** @type {Tokenizer} */

  function tokenizeRowEnd(effects, ok, nok) {
    return start
    /** @type {State} */

    function start(code) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return factorySpace(effects, prefixed, 'linePrefix')
    }
    /** @type {State} */

    function prefixed(code) {
      // Blank or interrupting line.
      if (
        self.parser.lazy[self.now().line] ||
        code === null ||
        markdownLineEnding$1(code)
      ) {
        return nok(code)
      }

      const tail = self.events[self.events.length - 1]; // Indented code can interrupt delimiter and body rows.

      if (
        !self.parser.constructs.disable.null.includes('codeIndented') &&
        tail &&
        tail[1].type === 'linePrefix' &&
        tail[2].sliceSerialize(tail[1], true).length >= 4
      ) {
        return nok(code)
      }

      self._gfmTableDynamicInterruptHack = true;
      return effects.check(
        self.parser.constructs.flow,
        function (code) {
          self._gfmTableDynamicInterruptHack = false;
          return nok(code)
        },
        function (code) {
          self._gfmTableDynamicInterruptHack = false;
          return ok(code)
        }
      )(code)
    }
  }
}
/** @type {Tokenizer} */

function tokenizeNextPrefixedOrBlank(effects, ok, nok) {
  let size = 0;
  return start
  /** @type {State} */

  function start(code) {
    // This is a check, so we don‚Äôt care about tokens, but we open a bogus one
    // so we‚Äôre valid.
    effects.enter('check'); // EOL.

    effects.consume(code);
    return whitespace
  }
  /** @type {State} */

  function whitespace(code) {
    if (code === -1 || code === 32) {
      effects.consume(code);
      size++;
      return size === 4 ? ok : whitespace
    } // EOF or whitespace

    if (code === null || markdownLineEndingOrSpace$1(code)) {
      return ok(code)
    } // Anything else.

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Previous} Previous
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Code} Code
 */
const tasklistCheck = {
  tokenize: tokenizeTasklistCheck
};
const gfmTaskListItem = {
  text: {
    [91]: tasklistCheck
  }
};
/** @type {Tokenizer} */

function tokenizeTasklistCheck(effects, ok, nok) {
  const self = this;
  return open
  /** @type {State} */

  function open(code) {
    if (
      // Exit if there‚Äôs stuff before.
      self.previous !== null || // Exit if not in the first content that is the first child of a list
      // item.
      !self._gfmTasklistFirstContentOfListItem
    ) {
      return nok(code)
    }

    effects.enter('taskListCheck');
    effects.enter('taskListCheckMarker');
    effects.consume(code);
    effects.exit('taskListCheckMarker');
    return inside
  }
  /** @type {State} */

  function inside(code) {
    // To match how GH works in comments, use `markdownSpace` (`[ \t]`) instead
    // of `markdownLineEndingOrSpace` (`[ \t\r\n]`).
    if (markdownLineEndingOrSpace$1(code)) {
      effects.enter('taskListCheckValueUnchecked');
      effects.consume(code);
      effects.exit('taskListCheckValueUnchecked');
      return close
    }

    if (code === 88 || code === 120) {
      effects.enter('taskListCheckValueChecked');
      effects.consume(code);
      effects.exit('taskListCheckValueChecked');
      return close
    }

    return nok(code)
  }
  /** @type {State} */

  function close(code) {
    if (code === 93) {
      effects.enter('taskListCheckMarker');
      effects.consume(code);
      effects.exit('taskListCheckMarker');
      effects.exit('taskListCheck');
      return effects.check(
        {
          tokenize: spaceThenNonSpace
        },
        ok,
        nok
      )
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function spaceThenNonSpace(effects, ok, nok) {
  const self = this;
  return factorySpace(effects, after, 'whitespace')
  /** @type {State} */

  function after(code) {
    const tail = self.events[self.events.length - 1];
    return (
      // We either found spaces‚Ä¶
      ((tail && tail[1].type === 'whitespace') || // ‚Ä¶or it was followed by a line ending, in which case, there has to be
        // non-whitespace after that line ending, because otherwise we‚Äôd get an
        // EOF as the content is closed with blank lines.
        markdownLineEnding$1(code)) &&
        code !== null
        ? ok(code)
        : nok(code)
    )
  }
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').HtmlExtension} HtmlExtension
 * @typedef {import('micromark-extension-gfm-strikethrough').Options} Options
 * @typedef {import('micromark-extension-gfm-footnote').HtmlOptions} HtmlOptions
 */

/**
 * Support GFM or markdown on github.com.
 *
 * @param {Options} [options]
 * @returns {Extension}
 */
function gfm(options) {
  return combineExtensions([
    gfmAutolinkLiteral,
    gfmFootnote(),
    gfmStrikethrough(options),
    gfmTable,
    gfmTaskListItem
  ])
}

/**
 * Count how often a character (or substring) is used in a string.
 *
 * @param {string} value
 *   Value to search in.
 * @param {string} character
 *   Character (or substring) to look for.
 * @return {number}
 *   Number of times `character` occurred in `value`.
 */
function ccount(value, character) {
  const source = String(value);

  if (typeof character !== 'string') {
    throw new TypeError('Expected character')
  }

  let count = 0;
  let index = source.indexOf(character);

  while (index !== -1) {
    count++;
    index = source.indexOf(character, index + character.length);
  }

  return count
}

function escapeStringRegexp(string) {
	if (typeof string !== 'string') {
		throw new TypeError('Expected a string');
	}

	// Escape characters with special meaning either inside or outside character sets.
	// Use a simple backslash escape when it‚Äôs always valid, and a `\xnn` escape when the simpler form would be disallowed by Unicode patterns‚Äô stricter grammar.
	return string
		.replace(/[|\\{}()[\]^$+*?.]/g, '\\$&')
		.replace(/-/g, '\\x2d');
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Parent} Parent
 *
 * @typedef {string} Type
 * @typedef {Object<string, unknown>} Props
 *
 * @typedef {null|undefined|Type|Props|TestFunctionAnything|Array.<Type|Props|TestFunctionAnything>} Test
 */

const convert =
  /**
   * @type {(
   *   (<T extends Node>(test: T['type']|Partial<T>|TestFunctionPredicate<T>) => AssertPredicate<T>) &
   *   ((test?: Test) => AssertAnything)
   * )}
   */
  (
    /**
     * Generate an assertion from a check.
     * @param {Test} [test]
     * When nullish, checks if `node` is a `Node`.
     * When `string`, works like passing `function (node) {return node.type === test}`.
     * When `function` checks if function passed the node is true.
     * When `object`, checks that all keys in test are in node, and that they have (strictly) equal values.
     * When `array`, checks any one of the subtests pass.
     * @returns {AssertAnything}
     */
    function (test) {
      if (test === undefined || test === null) {
        return ok
      }

      if (typeof test === 'string') {
        return typeFactory(test)
      }

      if (typeof test === 'object') {
        return Array.isArray(test) ? anyFactory(test) : propsFactory(test)
      }

      if (typeof test === 'function') {
        return castFactory(test)
      }

      throw new Error('Expected function, string, or object as test')
    }
  );
/**
 * @param {Array.<Type|Props|TestFunctionAnything>} tests
 * @returns {AssertAnything}
 */
function anyFactory(tests) {
  /** @type {Array.<AssertAnything>} */
  const checks = [];
  let index = -1;

  while (++index < tests.length) {
    checks[index] = convert(tests[index]);
  }

  return castFactory(any)

  /**
   * @this {unknown}
   * @param {unknown[]} parameters
   * @returns {boolean}
   */
  function any(...parameters) {
    let index = -1;

    while (++index < checks.length) {
      if (checks[index].call(this, ...parameters)) return true
    }

    return false
  }
}

/**
 * Utility to assert each property in `test` is represented in `node`, and each
 * values are strictly equal.
 *
 * @param {Props} check
 * @returns {AssertAnything}
 */
function propsFactory(check) {
  return castFactory(all)

  /**
   * @param {Node} node
   * @returns {boolean}
   */
  function all(node) {
    /** @type {string} */
    let key;

    for (key in check) {
      // @ts-expect-error: hush, it sure works as an index.
      if (node[key] !== check[key]) return false
    }

    return true
  }
}

/**
 * Utility to convert a string into a function which checks a given node‚Äôs type
 * for said string.
 *
 * @param {Type} check
 * @returns {AssertAnything}
 */
function typeFactory(check) {
  return castFactory(type)

  /**
   * @param {Node} node
   */
  function type(node) {
    return node && node.type === check
  }
}

/**
 * Utility to convert a string into a function which checks a given node‚Äôs type
 * for said string.
 * @param {TestFunctionAnything} check
 * @returns {AssertAnything}
 */
function castFactory(check) {
  return assertion

  /**
   * @this {unknown}
   * @param {Array.<unknown>} parameters
   * @returns {boolean}
   */
  function assertion(...parameters) {
    // @ts-expect-error: spreading is fine.
    return Boolean(check.call(this, ...parameters))
  }
}

// Utility to return true.
function ok() {
  return true
}

/**
 * @param {string} d
 * @returns {string}
 */
function color(d) {
  return d
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Parent} Parent
 * @typedef {import('unist-util-is').Test} Test
 */

/**
 * Continue traversing as normal
 */
const CONTINUE = true;
/**
 * Do not traverse this node‚Äôs children
 */
const SKIP = 'skip';
/**
 * Stop traversing immediately
 */
const EXIT = false;

const visitParents =
  /**
   * @type {(
   *   (<T extends Node>(tree: Node, test: T['type']|Partial<T>|import('unist-util-is').TestFunctionPredicate<T>|Array.<T['type']|Partial<T>|import('unist-util-is').TestFunctionPredicate<T>>, visitor: Visitor<T>, reverse?: boolean) => void) &
   *   ((tree: Node, test: Test, visitor: Visitor<Node>, reverse?: boolean) => void) &
   *   ((tree: Node, visitor: Visitor<Node>, reverse?: boolean) => void)
   * )}
   */
  (
    /**
     * Visit children of tree which pass a test
     *
     * @param {Node} tree Abstract syntax tree to walk
     * @param {Test} test test Test node
     * @param {Visitor<Node>} visitor Function to run for each node
     * @param {boolean} [reverse] Fisit the tree in reverse, defaults to false
     */
    function (tree, test, visitor, reverse) {
      if (typeof test === 'function' && typeof visitor !== 'function') {
        reverse = visitor;
        // @ts-ignore no visitor given, so `visitor` is test.
        visitor = test;
        test = null;
      }

      var is = convert(test);
      var step = reverse ? -1 : 1;

      factory(tree, null, [])();

      /**
       * @param {Node} node
       * @param {number?} index
       * @param {Array.<Parent>} parents
       */
      function factory(node, index, parents) {
        /** @type {Object.<string, unknown>} */
        var value = typeof node === 'object' && node !== null ? node : {};
        /** @type {string} */
        var name;

        if (typeof value.type === 'string') {
          name =
            typeof value.tagName === 'string'
              ? value.tagName
              : typeof value.name === 'string'
              ? value.name
              : undefined;

          Object.defineProperty(visit, 'name', {
            value:
              'node (' +
              color(value.type + (name ? '<' + name + '>' : '')) +
              ')'
          });
        }

        return visit

        function visit() {
          /** @type {ActionTuple} */
          var result = [];
          /** @type {ActionTuple} */
          var subresult;
          /** @type {number} */
          var offset;
          /** @type {Array.<Parent>} */
          var grandparents;

          if (!test || is(node, index, parents[parents.length - 1] || null)) {
            result = toResult(visitor(node, parents));

            if (result[0] === EXIT) {
              return result
            }
          }

          if (node.children && result[0] !== SKIP) {
            // @ts-ignore looks like a parent.
            offset = (reverse ? node.children.length : -1) + step;
            // @ts-ignore looks like a parent.
            grandparents = parents.concat(node);

            // @ts-ignore looks like a parent.
            while (offset > -1 && offset < node.children.length) {
              subresult = factory(node.children[offset], offset, grandparents)();

              if (subresult[0] === EXIT) {
                return subresult
              }

              offset =
                typeof subresult[1] === 'number' ? subresult[1] : offset + step;
            }
          }

          return result
        }
      }
    }
  );

/**
 * @param {VisitorResult} value
 * @returns {ActionTuple}
 */
function toResult(value) {
  if (Array.isArray(value)) {
    return value
  }

  if (typeof value === 'number') {
    return [CONTINUE, value]
  }

  return [value]
}

/**
 * @typedef Options Configuration.
 * @property {Test} [ignore] `unist-util-is` test used to assert parents
 *
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast').Content} Content
 * @typedef {import('mdast').PhrasingContent} PhrasingContent
 * @typedef {import('mdast').Text} Text
 * @typedef {Content|Root} Node
 * @typedef {Extract<Node, import('mdast').Parent>} Parent
 *
 * @typedef {import('unist-util-visit-parents').Test} Test
 * @typedef {import('unist-util-visit-parents').VisitorResult} VisitorResult
 *
 * @typedef RegExpMatchObject
 * @property {number} index
 * @property {string} input
 *
 * @typedef {string|RegExp} Find
 * @typedef {string|ReplaceFunction} Replace
 *
 * @typedef {[Find, Replace]} FindAndReplaceTuple
 * @typedef {Object.<string, Replace>} FindAndReplaceSchema
 * @typedef {Array.<FindAndReplaceTuple>} FindAndReplaceList
 *
 * @typedef {[RegExp, ReplaceFunction]} Pair
 * @typedef {Array.<Pair>} Pairs
 */

const own = {}.hasOwnProperty;

/**
 * @param tree mdast tree
 * @param find Value to find and remove. When `string`, escaped and made into a global `RegExp`
 * @param [replace] Value to insert.
 *   * When `string`, turned into a Text node.
 *   * When `Function`, called with the results of calling `RegExp.exec` as
 *     arguments, in which case it can return a single or a list of `Node`,
 *     a `string` (which is wrapped in a `Text` node), or `false` to not replace
 * @param [options] Configuration.
 */
const findAndReplace =
  /**
   * @type {(
   *   ((tree: Node, find: Find, replace?: Replace, options?: Options) => Node) &
   *   ((tree: Node, schema: FindAndReplaceSchema|FindAndReplaceList, options?: Options) => Node)
   * )}
   **/
  (
    /**
     * @param {Node} tree
     * @param {Find|FindAndReplaceSchema|FindAndReplaceList} find
     * @param {Replace|Options} [replace]
     * @param {Options} [options]
     */
    function (tree, find, replace, options) {
      /** @type {Options|undefined} */
      let settings;
      /** @type {FindAndReplaceSchema|FindAndReplaceList} */
      let schema;

      if (typeof find === 'string' || find instanceof RegExp) {
        // @ts-expect-error don‚Äôt expect options twice.
        schema = [[find, replace]];
        settings = options;
      } else {
        schema = find;
        // @ts-expect-error don‚Äôt expect replace twice.
        settings = replace;
      }

      if (!settings) {
        settings = {};
      }

      const ignored = convert(settings.ignore || []);
      const pairs = toPairs(schema);
      let pairIndex = -1;

      while (++pairIndex < pairs.length) {
        visitParents(tree, 'text', visitor);
      }

      return tree

      /** @type {import('unist-util-visit-parents').Visitor<Text>} */
      function visitor(node, parents) {
        let index = -1;
        /** @type {Parent|undefined} */
        let grandparent;

        while (++index < parents.length) {
          const parent = /** @type {Parent} */ (parents[index]);

          if (
            ignored(
              parent,
              // @ts-expect-error mdast vs. unist parent.
              grandparent ? grandparent.children.indexOf(parent) : undefined,
              grandparent
            )
          ) {
            return
          }

          grandparent = parent;
        }

        if (grandparent) {
          return handler(node, grandparent)
        }
      }

      /**
       * @param {Text} node
       * @param {Parent} parent
       * @returns {VisitorResult}
       */
      function handler(node, parent) {
        const find = pairs[pairIndex][0];
        const replace = pairs[pairIndex][1];
        let start = 0;
        // @ts-expect-error: TS is wrong, some of these children can be text.
        let index = parent.children.indexOf(node);
        /** @type {Array.<PhrasingContent>} */
        let nodes = [];
        /** @type {number|undefined} */
        let position;

        find.lastIndex = 0;

        let match = find.exec(node.value);

        while (match) {
          position = match.index;
          // @ts-expect-error this is perfectly fine, typescript.
          let value = replace(...match, {
            index: match.index,
            input: match.input
          });

          if (typeof value === 'string') {
            value = value.length > 0 ? {type: 'text', value} : undefined;
          }

          if (value !== false) {
            if (start !== position) {
              nodes.push({
                type: 'text',
                value: node.value.slice(start, position)
              });
            }

            if (Array.isArray(value)) {
              nodes.push(...value);
            } else if (value) {
              nodes.push(value);
            }

            start = position + match[0].length;
          }

          if (!find.global) {
            break
          }

          match = find.exec(node.value);
        }

        if (position === undefined) {
          nodes = [node];
          index--;
        } else {
          if (start < node.value.length) {
            nodes.push({type: 'text', value: node.value.slice(start)});
          }

          parent.children.splice(index, 1, ...nodes);
        }

        return index + nodes.length + 1
      }
    }
  );

/**
 * @param {FindAndReplaceSchema|FindAndReplaceList} schema
 * @returns {Pairs}
 */
function toPairs(schema) {
  /** @type {Pairs} */
  const result = [];

  if (typeof schema !== 'object') {
    throw new TypeError('Expected array or object as schema')
  }

  if (Array.isArray(schema)) {
    let index = -1;

    while (++index < schema.length) {
      result.push([
        toExpression(schema[index][0]),
        toFunction(schema[index][1])
      ]);
    }
  } else {
    /** @type {string} */
    let key;

    for (key in schema) {
      if (own.call(schema, key)) {
        result.push([toExpression(key), toFunction(schema[key])]);
      }
    }
  }

  return result
}

/**
 * @param {Find} find
 * @returns {RegExp}
 */
function toExpression(find) {
  return typeof find === 'string' ? new RegExp(escapeStringRegexp(find), 'g') : find
}

/**
 * @param {Replace} replace
 * @returns {ReplaceFunction}
 */
function toFunction(replace) {
  return typeof replace === 'function' ? replace : () => replace
}

/**
 * @typedef {import('mdast').Link} Link
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Transform} FromMarkdownTransform
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown/lib/types.js').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-find-and-replace').ReplaceFunction} ReplaceFunction
 * @typedef {import('mdast-util-find-and-replace').RegExpMatchObject} RegExpMatchObject
 * @typedef {import('mdast-util-find-and-replace').PhrasingContent} PhrasingContent
 */

/** @type {FromMarkdownExtension} */
const gfmAutolinkLiteralFromMarkdown = {
  transforms: [transformGfmAutolinkLiterals],
  enter: {
    literalAutolink: enterLiteralAutolink,
    literalAutolinkEmail: enterLiteralAutolinkValue,
    literalAutolinkHttp: enterLiteralAutolinkValue,
    literalAutolinkWww: enterLiteralAutolinkValue
  },
  exit: {
    literalAutolink: exitLiteralAutolink,
    literalAutolinkEmail: exitLiteralAutolinkEmail,
    literalAutolinkHttp: exitLiteralAutolinkHttp,
    literalAutolinkWww: exitLiteralAutolinkWww
  }
};

/** @type {FromMarkdownHandle} */
function enterLiteralAutolink(token) {
  this.enter({type: 'link', title: null, url: '', children: []}, token);
}

/** @type {FromMarkdownHandle} */
function enterLiteralAutolinkValue(token) {
  this.config.enter.autolinkProtocol.call(this, token);
}

/** @type {FromMarkdownHandle} */
function exitLiteralAutolinkHttp(token) {
  this.config.exit.autolinkProtocol.call(this, token);
}

/** @type {FromMarkdownHandle} */
function exitLiteralAutolinkWww(token) {
  this.config.exit.data.call(this, token);
  const node = /** @type {Link} */ (this.stack[this.stack.length - 1]);
  node.url = 'http://' + this.sliceSerialize(token);
}

/** @type {FromMarkdownHandle} */
function exitLiteralAutolinkEmail(token) {
  this.config.exit.autolinkEmail.call(this, token);
}

/** @type {FromMarkdownHandle} */
function exitLiteralAutolink(token) {
  this.exit(token);
}

/** @type {FromMarkdownTransform} */
function transformGfmAutolinkLiterals(tree) {
  findAndReplace(
    tree,
    [
      [/(https?:\/\/|www(?=\.))([-.\w]+)([^ \t\r\n]*)/gi, findUrl],
      [/([-.\w+]+)@([-\w]+(?:\.[-\w]+)+)/g, findEmail]
    ],
    {ignore: ['link', 'linkReference']}
  );
}

/**
 * @type {ReplaceFunction}
 * @param {string} _
 * @param {string} protocol
 * @param {string} domain
 * @param {string} path
 * @param {RegExpMatchObject} match
 */
// eslint-disable-next-line max-params
function findUrl(_, protocol, domain, path, match) {
  let prefix = '';

  // Not an expected previous character.
  if (!previous$1(match)) {
    return false
  }

  // Treat `www` as part of the domain.
  if (/^w/i.test(protocol)) {
    domain = protocol + domain;
    protocol = '';
    prefix = 'http://';
  }

  if (!isCorrectDomain(domain)) {
    return false
  }

  const parts = splitUrl(domain + path);

  if (!parts[0]) return false

  /** @type {PhrasingContent} */
  const result = {
    type: 'link',
    title: null,
    url: prefix + protocol + parts[0],
    children: [{type: 'text', value: protocol + parts[0]}]
  };

  if (parts[1]) {
    return [result, {type: 'text', value: parts[1]}]
  }

  return result
}

/**
 * @type {ReplaceFunction}
 * @param {string} _
 * @param {string} atext
 * @param {string} label
 * @param {RegExpMatchObject} match
 */
function findEmail(_, atext, label, match) {
  if (
    // Not an expected previous character.
    !previous$1(match, true) ||
    // Label ends in not allowed character.
    /[_-\d]$/.test(label)
  ) {
    return false
  }

  return {
    type: 'link',
    title: null,
    url: 'mailto:' + atext + '@' + label,
    children: [{type: 'text', value: atext + '@' + label}]
  }
}

/**
 * @param {string} domain
 * @returns {boolean}
 */
function isCorrectDomain(domain) {
  const parts = domain.split('.');

  if (
    parts.length < 2 ||
    (parts[parts.length - 1] &&
      (/_/.test(parts[parts.length - 1]) ||
        !/[a-zA-Z\d]/.test(parts[parts.length - 1]))) ||
    (parts[parts.length - 2] &&
      (/_/.test(parts[parts.length - 2]) ||
        !/[a-zA-Z\d]/.test(parts[parts.length - 2])))
  ) {
    return false
  }

  return true
}

/**
 * @param {string} url
 * @returns {[string, string|undefined]}
 */
function splitUrl(url) {
  const trailExec = /[!"&'),.:;<>?\]}]+$/.exec(url);
  /** @type {number} */
  let closingParenIndex;
  /** @type {number} */
  let openingParens;
  /** @type {number} */
  let closingParens;
  /** @type {string|undefined} */
  let trail;

  if (trailExec) {
    url = url.slice(0, trailExec.index);
    trail = trailExec[0];
    closingParenIndex = trail.indexOf(')');
    openingParens = ccount(url, '(');
    closingParens = ccount(url, ')');

    while (closingParenIndex !== -1 && openingParens > closingParens) {
      url += trail.slice(0, closingParenIndex + 1);
      trail = trail.slice(closingParenIndex + 1);
      closingParenIndex = trail.indexOf(')');
      closingParens++;
    }
  }

  return [url, trail]
}

/**
 * @param {RegExpMatchObject} match
 * @param {boolean} [email=false]
 * @returns {boolean}
 */
function previous$1(match, email) {
  const code = match.input.charCodeAt(match.index - 1);

  return (
    (match.index === 0 ||
      unicodeWhitespace(code) ||
      unicodePunctuation(code)) &&
    (!email || code !== 47)
  )
}

/**
 * @typedef {import('mdast').FootnoteReference} FootnoteReference
 * @typedef {import('mdast').FootnoteDefinition} FootnoteDefinition
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Map} Map
 */

/**
 * @returns {FromMarkdownExtension}
 */
function gfmFootnoteFromMarkdown() {
  return {
    enter: {
      gfmFootnoteDefinition: enterFootnoteDefinition,
      gfmFootnoteDefinitionLabelString: enterFootnoteDefinitionLabelString,
      gfmFootnoteCall: enterFootnoteCall,
      gfmFootnoteCallString: enterFootnoteCallString
    },
    exit: {
      gfmFootnoteDefinition: exitFootnoteDefinition,
      gfmFootnoteDefinitionLabelString: exitFootnoteDefinitionLabelString,
      gfmFootnoteCall: exitFootnoteCall,
      gfmFootnoteCallString: exitFootnoteCallString
    }
  }

  /** @type {FromMarkdownHandle} */
  function enterFootnoteDefinition(token) {
    this.enter(
      {type: 'footnoteDefinition', identifier: '', label: '', children: []},
      token
    );
  }

  /** @type {FromMarkdownHandle} */
  function enterFootnoteDefinitionLabelString() {
    this.buffer();
  }

  /** @type {FromMarkdownHandle} */
  function exitFootnoteDefinitionLabelString(token) {
    const label = this.resume();
    const node = /** @type {FootnoteDefinition} */ (
      this.stack[this.stack.length - 1]
    );
    node.label = label;
    node.identifier = normalizeIdentifier(
      this.sliceSerialize(token)
    ).toLowerCase();
  }

  /** @type {FromMarkdownHandle} */
  function exitFootnoteDefinition(token) {
    this.exit(token);
  }

  /** @type {FromMarkdownHandle} */
  function enterFootnoteCall(token) {
    this.enter({type: 'footnoteReference', identifier: '', label: ''}, token);
  }

  /** @type {FromMarkdownHandle} */
  function enterFootnoteCallString() {
    this.buffer();
  }

  /** @type {FromMarkdownHandle} */
  function exitFootnoteCallString(token) {
    const label = this.resume();
    const node = /** @type {FootnoteDefinition} */ (
      this.stack[this.stack.length - 1]
    );
    node.label = label;
    node.identifier = normalizeIdentifier(
      this.sliceSerialize(token)
    ).toLowerCase();
  }

  /** @type {FromMarkdownHandle} */
  function exitFootnoteCall(token) {
    this.exit(token);
  }
}

/**
 * @typedef {import('mdast').Delete} Delete
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 */

/** @type {FromMarkdownExtension} */
const gfmStrikethroughFromMarkdown = {
  canContainEols: ['delete'],
  enter: {strikethrough: enterStrikethrough},
  exit: {strikethrough: exitStrikethrough}
};

/** @type {FromMarkdownHandle} */
function enterStrikethrough(token) {
  this.enter({type: 'delete', children: []}, token);
}

/** @type {FromMarkdownHandle} */
function exitStrikethrough(token) {
  this.exit(token);
}

/**
 * @typedef {import('mdast').AlignType} AlignType
 * @typedef {import('mdast').Table} Table
 * @typedef {import('mdast').TableRow} TableRow
 * @typedef {import('mdast').TableCell} TableCell
 * @typedef {import('mdast').InlineCode} InlineCode
 * @typedef {import('markdown-table').MarkdownTableOptions} MarkdownTableOptions
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Context} ToMarkdownContext
 * @typedef {import('mdast-util-to-markdown').SafeOptions} SafeOptions
 *
 * @typedef Options
 * @property {boolean} [tableCellPadding=true]
 * @property {boolean} [tablePipeAlign=true]
 * @property {MarkdownTableOptions['stringLength']} [stringLength]
 */

/** @type {FromMarkdownExtension} */
const gfmTableFromMarkdown = {
  enter: {
    table: enterTable,
    tableData: enterCell,
    tableHeader: enterCell,
    tableRow: enterRow
  },
  exit: {
    codeText: exitCodeText,
    table: exitTable,
    tableData: exit,
    tableHeader: exit,
    tableRow: exit
  }
};

/** @type {FromMarkdownHandle} */
function enterTable(token) {
  /** @type {Array<'left'|'right'|'center'|'none'>} */
  // @ts-expect-error: `align` is custom.
  const align = token._align;
  this.enter(
    {
      type: 'table',
      align: align.map((d) => (d === 'none' ? null : d)),
      children: []
    },
    token
  );
  this.setData('inTable', true);
}

/** @type {FromMarkdownHandle} */
function exitTable(token) {
  this.exit(token);
  this.setData('inTable');
}

/** @type {FromMarkdownHandle} */
function enterRow(token) {
  this.enter({type: 'tableRow', children: []}, token);
}

/** @type {FromMarkdownHandle} */
function exit(token) {
  this.exit(token);
}

/** @type {FromMarkdownHandle} */
function enterCell(token) {
  this.enter({type: 'tableCell', children: []}, token);
}

// Overwrite the default code text data handler to unescape escaped pipes when
// they are in tables.
/** @type {FromMarkdownHandle} */
function exitCodeText(token) {
  let value = this.resume();

  if (this.getData('inTable')) {
    value = value.replace(/\\([\\|])/g, replace);
  }

  const node = /** @type {InlineCode} */ (this.stack[this.stack.length - 1]);
  node.value = value;
  this.exit(token);
}

/**
 * @param {string} $0
 * @param {string} $1
 * @returns {string}
 */
function replace($0, $1) {
  // Pipes work, backslashes don‚Äôt (but can‚Äôt escape pipes).
  return $1 === '|' ? $1 : $0
}

/**
 * @typedef {Extract<import('mdast').Root|import('mdast').Content, import('unist').Parent>} Parent
 * @typedef {import('mdast').ListItem} ListItem
 * @typedef {import('mdast').Paragraph} Paragraph
 * @typedef {import('mdast').BlockContent} BlockContent
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 */

/** @type {FromMarkdownExtension} */
const gfmTaskListItemFromMarkdown = {
  exit: {
    taskListCheckValueChecked: exitCheck,
    taskListCheckValueUnchecked: exitCheck,
    paragraph: exitParagraphWithTaskListItem
  }
};

/** @type {FromMarkdownHandle} */
function exitCheck(token) {
  const node = /** @type {ListItem} */ (this.stack[this.stack.length - 2]);
  // We‚Äôre always in a paragraph, in a list item.
  node.checked = token.type === 'taskListCheckValueChecked';
}

/** @type {FromMarkdownHandle} */
function exitParagraphWithTaskListItem(token) {
  const parent = /** @type {Parent} */ (this.stack[this.stack.length - 2]);
  const node = /** @type {Paragraph} */ (this.stack[this.stack.length - 1]);
  const siblings = parent.children;
  const head = node.children[0];
  let index = -1;
  /** @type {Paragraph|undefined} */
  let firstParaghraph;

  if (
    parent &&
    parent.type === 'listItem' &&
    typeof parent.checked === 'boolean' &&
    head &&
    head.type === 'text'
  ) {
    while (++index < siblings.length) {
      const sibling = siblings[index];
      if (sibling.type === 'paragraph') {
        firstParaghraph = sibling;
        break
      }
    }

    if (firstParaghraph === node) {
      // Must start with a space or a tab.
      head.value = head.value.slice(1);

      if (head.value.length === 0) {
        node.children.shift();
      } else if (
        node.position &&
        head.position &&
        typeof head.position.start.offset === 'number'
      ) {
        head.position.start.column++;
        head.position.start.offset++;
        node.position.start = Object.assign({}, head.position.start);
      }
    }
  }

  this.exit(token);
}

/**
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 *
 * @typedef {import('mdast-util-gfm-table').Options} Options
 */

/**
 * @returns {Array.<FromMarkdownExtension>}
 */
function gfmFromMarkdown() {
  return [
    gfmAutolinkLiteralFromMarkdown,
    gfmFootnoteFromMarkdown(),
    gfmStrikethroughFromMarkdown,
    gfmTableFromMarkdown,
    gfmTaskListItemFromMarkdown
  ]
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const mathFlow = {
  tokenize: tokenizeMathFenced,
  concrete: true
};
/** @type {Construct} */

const nonLazyLine = {
  tokenize: tokenizeNonLazyLine,
  partial: true
};
/** @type {Tokenizer} */

function tokenizeMathFenced(effects, ok, nok) {
  const self = this;
  const tail = self.events[self.events.length - 1];
  const initialSize =
    tail && tail[1].type === 'linePrefix'
      ? tail[2].sliceSerialize(tail[1], true).length
      : 0;
  let sizeOpen = 0;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('mathFlow');
    effects.enter('mathFlowFence');
    effects.enter('mathFlowFenceSequence');
    return sequenceOpen(code)
  }
  /** @type {State} */

  function sequenceOpen(code) {
    if (code === 36) {
      effects.consume(code);
      sizeOpen++;
      return sequenceOpen
    }

    effects.exit('mathFlowFenceSequence');
    return sizeOpen < 2
      ? nok(code)
      : factorySpace(effects, metaOpen, 'whitespace')(code)
  }
  /** @type {State} */

  function metaOpen(code) {
    if (code === null || markdownLineEnding$1(code)) {
      return openAfter(code)
    }

    effects.enter('mathFlowFenceMeta');
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return meta(code)
  }
  /** @type {State} */

  function meta(code) {
    if (code === null || markdownLineEnding$1(code)) {
      effects.exit('chunkString');
      effects.exit('mathFlowFenceMeta');
      return openAfter(code)
    }

    if (code === 36) return nok(code)
    effects.consume(code);
    return meta
  }
  /** @type {State} */

  function openAfter(code) {
    effects.exit('mathFlowFence');
    return self.interrupt ? ok(code) : contentStart(code)
  }
  /** @type {State} */

  function contentStart(code) {
    if (code === null) {
      return after(code)
    }

    if (markdownLineEnding$1(code)) {
      return effects.attempt(
        nonLazyLine,
        effects.attempt(
          {
            tokenize: tokenizeClosingFence,
            partial: true
          },
          after,
          initialSize
            ? factorySpace(effects, contentStart, 'linePrefix', initialSize + 1)
            : contentStart
        ),
        after
      )(code)
    }

    effects.enter('mathFlowValue');
    return contentContinue(code)
  }
  /** @type {State} */

  function contentContinue(code) {
    if (code === null || markdownLineEnding$1(code)) {
      effects.exit('mathFlowValue');
      return contentStart(code)
    }

    effects.consume(code);
    return contentContinue
  }
  /** @type {State} */

  function after(code) {
    effects.exit('mathFlow');
    return ok(code)
  }
  /** @type {Tokenizer} */

  function tokenizeClosingFence(effects, ok, nok) {
    let size = 0;
    return factorySpace(effects, closingPrefixAfter, 'linePrefix', 4)
    /** @type {State} */

    function closingPrefixAfter(code) {
      effects.enter('mathFlowFence');
      effects.enter('mathFlowFenceSequence');
      return closingSequence(code)
    }
    /** @type {State} */

    function closingSequence(code) {
      if (code === 36) {
        effects.consume(code);
        size++;
        return closingSequence
      }

      if (size < sizeOpen) return nok(code)
      effects.exit('mathFlowFenceSequence');
      return factorySpace(effects, closingSequenceEnd, 'whitespace')(code)
    }
    /** @type {State} */

    function closingSequenceEnd(code) {
      if (code === null || markdownLineEnding$1(code)) {
        effects.exit('mathFlowFence');
        return ok(code)
      }

      return nok(code)
    }
  }
}
/** @type {Tokenizer} */

function tokenizeNonLazyLine(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return lineStart
  }
  /** @type {State} */

  function lineStart(code) {
    return self.parser.lazy[self.now().line] ? nok(code) : ok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Previous} Previous
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Token} Token
 *
 * @typedef Options
 * @property {boolean} [singleDollarTextMath=true]
 *   Whether to support math (text) with a single dollar (`boolean`, default:
 *   `true`).
 *   Single dollars work in Pandoc and many other places, but often interfere
 *   with ‚Äúnormal‚Äù dollars in text.
 */

/**
 * @param {Options} [options]
 * @returns {Construct}
 */
function mathText(options = {}) {
  let single = options.singleDollarTextMath;

  if (single === null || single === undefined) {
    single = true;
  }

  return {
    tokenize: tokenizeMathText,
    resolve: resolveMathText,
    previous
  }
  /** @type {Tokenizer} */

  function tokenizeMathText(effects, ok, nok) {
    let sizeOpen = 0;
    /** @type {number} */

    let size;
    /** @type {Token} */

    let token;
    return start
    /** @type {State} */

    function start(code) {
      effects.enter('mathText');
      effects.enter('mathTextSequence');
      return openingSequence(code)
    }
    /** @type {State} */

    function openingSequence(code) {
      if (code === 36) {
        effects.consume(code);
        sizeOpen++;
        return openingSequence
      }

      if (sizeOpen < 2 && !single) return nok(code)
      effects.exit('mathTextSequence');
      return gap(code)
    }
    /** @type {State} */

    function gap(code) {
      if (code === null) {
        return nok(code)
      } // Closing fence?
      // Could also be data.

      if (code === 36) {
        token = effects.enter('mathTextSequence');
        size = 0;
        return closingSequence(code)
      } // Tabs don‚Äôt work, and virtual spaces don‚Äôt make sense.

      if (code === 32) {
        effects.enter('space');
        effects.consume(code);
        effects.exit('space');
        return gap
      }

      if (markdownLineEnding$1(code)) {
        effects.enter('lineEnding');
        effects.consume(code);
        effects.exit('lineEnding');
        return gap
      } // Data.

      effects.enter('mathTextData');
      return data(code)
    } // In math.

    /** @type {State} */

    function data(code) {
      if (
        code === null ||
        code === 32 ||
        code === 36 ||
        markdownLineEnding$1(code)
      ) {
        effects.exit('mathTextData');
        return gap(code)
      }

      effects.consume(code);
      return data
    } // Closing fence.

    /** @type {State} */

    function closingSequence(code) {
      // More.
      if (code === 36) {
        effects.consume(code);
        size++;
        return closingSequence
      } // Done!

      if (size === sizeOpen) {
        effects.exit('mathTextSequence');
        effects.exit('mathText');
        return ok(code)
      } // More or less accents: mark as data.

      token.type = 'mathTextData';
      return data(code)
    }
  }
}
/** @type {Resolver} */

function resolveMathText(events) {
  let tailExitIndex = events.length - 4;
  let headEnterIndex = 3;
  /** @type {number} */

  let index;
  /** @type {number|undefined} */

  let enter; // If we start and end with an EOL or a space.

  if (
    (events[headEnterIndex][1].type === 'lineEnding' ||
      events[headEnterIndex][1].type === 'space') &&
    (events[tailExitIndex][1].type === 'lineEnding' ||
      events[tailExitIndex][1].type === 'space')
  ) {
    index = headEnterIndex; // And we have data.

    while (++index < tailExitIndex) {
      if (events[index][1].type === 'mathTextData') {
        // Then we have padding.
        events[tailExitIndex][1].type = 'mathTextPadding';
        events[headEnterIndex][1].type = 'mathTextPadding';
        headEnterIndex += 2;
        tailExitIndex -= 2;
        break
      }
    }
  } // Merge adjacent spaces and data.

  index = headEnterIndex - 1;
  tailExitIndex++;

  while (++index <= tailExitIndex) {
    if (enter === undefined) {
      if (index !== tailExitIndex && events[index][1].type !== 'lineEnding') {
        enter = index;
      }
    } else if (
      index === tailExitIndex ||
      events[index][1].type === 'lineEnding'
    ) {
      events[enter][1].type = 'mathTextData';

      if (index !== enter + 2) {
        events[enter][1].end = events[index - 1][1].end;
        events.splice(enter + 2, index - enter - 2);
        tailExitIndex -= index - enter - 2;
        index = enter + 2;
      }

      enter = undefined;
    }
  }

  return events
}
/** @type {Previous} */

function previous(code) {
  // If there is a previous code, there will always be a tail.
  return (
    code !== 36 ||
    this.events[this.events.length - 1][1].type === 'characterEscape'
  )
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('./math-text').Options} Options
 */
/**
 * @param {Options} [options]
 * @returns {Extension}
 */

function math(options) {
  return {
    flow: {
      [36]: mathFlow
    },
    text: {
      [36]: mathText(options)
    }
  }
}

/**
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 * @typedef {import('./complex-types').Math} Math
 * @typedef {import('./complex-types').InlineMath} InlineMath
 *
 * @typedef ToOptions
 * @property {boolean} [singleDollarTextMath=true]
 *   Whether to support math (text) with a single dollar (`boolean`, default:
 *   `true`).
 *   Single dollars work in Pandoc and many other places, but often interfere
 *   with ‚Äúnormal‚Äù dollars in text.
 */

/**
 * @returns {FromMarkdownExtension}
 */
function mathFromMarkdown() {
  return {
    enter: {
      mathFlow: enterMathFlow,
      mathFlowFenceMeta: enterMathFlowMeta,
      mathText: enterMathText
    },
    exit: {
      mathFlow: exitMathFlow,
      mathFlowFence: exitMathFlowFence,
      mathFlowFenceMeta: exitMathFlowMeta,
      mathFlowValue: exitMathData,
      mathText: exitMathText,
      mathTextData: exitMathData
    }
  }

  /** @type {FromMarkdownHandle} */
  function enterMathFlow(token) {
    this.enter(
      {
        type: 'math',
        meta: null,
        value: '',
        data: {
          hName: 'div',
          hProperties: {className: ['math', 'math-display']},
          hChildren: [{type: 'text', value: ''}]
        }
      },
      token
    );
  }

  /** @type {FromMarkdownHandle} */
  function enterMathFlowMeta() {
    this.buffer();
  }

  /** @type {FromMarkdownHandle} */
  function exitMathFlowMeta() {
    const data = this.resume();
    const node = /** @type {Math} */ (this.stack[this.stack.length - 1]);
    node.meta = data;
  }

  /** @type {FromMarkdownHandle} */
  function exitMathFlowFence() {
    // Exit if this is the closing fence.
    if (this.getData('mathFlowInside')) return
    this.buffer();
    this.setData('mathFlowInside', true);
  }

  /** @type {FromMarkdownHandle} */
  function exitMathFlow(token) {
    const data = this.resume().replace(/^(\r?\n|\r)|(\r?\n|\r)$/g, '');
    const node = /** @type {Math} */ (this.exit(token));
    node.value = data;
    // @ts-expect-error: we defined it.
    node.data.hChildren[0].value = data;
    this.setData('mathFlowInside');
  }

  /** @type {FromMarkdownHandle} */
  function enterMathText(token) {
    this.enter(
      {
        type: 'inlineMath',
        value: '',
        data: {
          hName: 'span',
          hProperties: {className: ['math', 'math-inline']},
          hChildren: [{type: 'text', value: ''}]
        }
      },
      token
    );
    this.buffer();
  }

  /** @type {FromMarkdownHandle} */
  function exitMathText(token) {
    const data = this.resume();
    const node = /** @type {Math} */ (this.exit(token));
    node.value = data;
    // @ts-expect-error: we defined it.
    node.data.hChildren[0].value = data;
  }

  /** @type {FromMarkdownHandle} */
  function exitMathData(token) {
    this.config.enter.data.call(this, token);
    this.config.exit.data.call(this, token);
  }
}

const labelMatch = /\^([a-zA-Z0-9-_:]*)\s*$/;
/* Match:
 * - some stuff
 * '(' followed by any amount of stuff that is not '(', to get everything inside the last paren
 */
const preCiteMatch = /^(.*)\(([^(]*)$/s;
const postCiteMatch = /^([^)]*)\)(.*)$/s;
/*
 * Overall function to carry out the conversion
 */
function ASTtoString(input, settings, indent = 0) {
    input.type;
    const transforms = {
        'root': wrapper("\n", ""),
        'paragraph': wrapper("", "\n"),
        'emphasis': (a) => { return "\\emph{" + wrapper("", "")(a, settings) + "}"; },
        'strong': (a) => { return "\\textbf{" + wrapper("", "")(a, settings) + "}"; },
        'delete': (a) => { return "\\st{" + wrapper("", "")(a, settings) + "}"; },
        'footnote': (a) => { return "\\footnote{" + wrapper("", "")(a, settings) + "}"; },
        'list': list,
        'listItem': (a) => { return "\t".repeat(indent) + "\\item " + wrapper("", "")(a, settings, indent); },
        'heading': heading,
        'wikiLink': internalLink,
        'link': externalLink,
        'code': codeBlock,
        'inlineCode': inlineCode,
        'inlineMath': inlineMath,
        'math': displayMath,
    };
    const f = transforms[input.type] || defaultC;
    const trans = f(input, settings, indent);
    return trans;
}
/*
 * Individual functions to convert elements
 */
const defaultC = (a, settings, indent = 0) => {
    const v = a.value;
    const lm = labelMatch.exec(v);
    if (lm && lm.length > 0)
        return `\\label{${lm[1]}}`;
    if (!v)
        return "";
    return escapeLatex(v);
};
function escapeLatex(input) {
    var v = input;
    if (input === null || input === undefined)
        return "";
    // Characters that need escaping in free text:
    // & % $ # _ { } ~ ^ \
    // \& \% \$ \# \_ \{ \}
    v = v.replace(/\\/g, "\\textbackslash");
    v = v.replace(/([{}])/g, "\\$1");
    v = v.replace(/\\textbackslash/g, "\\textbackslash{}");
    v = v.replace(/([&%$#_])/g, "\\$1");
    v = v.replace(/~/g, "\\textasciitilde{}");
    v = v.replace(/\^/g, "\\textasciicircum{}");
    return v;
}
const wrapper = (jn, aft) => (a, settings, indent = 0) => {
    return (a.children.map((c) => ASTtoString(c, settings, indent)).join(jn)) + aft;
};
const heading = (a, settings, indent = 0) => {
    const h = a;
    var sec = "section";
    if (h.depth == 2)
        sec = "subsection";
    if (h.depth == 3)
        sec = "subsubsection";
    return "\\" + sec + "{" + ASTtoString(a.children[0], settings) + "}\n";
};
const list = (a, settings, indent = 0) => {
    const h = a;
    var sec = h.ordered ? "enumerate" : "itemize";
    return "\t".repeat(indent) + "\\begin{" + sec + "}\n" +
        wrapper("", "")(a, settings, indent + 1) +
        "\t".repeat(indent) + "\\end{" + sec + "}\n";
};
const internalLink = (a, settings, indent = 0) => {
    const h = a;
    const url = h.value;
    if (url.startsWith("@")) {
        if (settings.citeCommand === "extended") {
            return extendedCitation(h, settings);
        }
        else {
            if (settings.citeCommand == "basic")
                return "\\cite{" + url.substring(1) + "}";
            else if (settings.citeCommand == "autocite")
                return "\\autocite{" + url.substring(1) + "}";
            else if (settings.citeCommand == "parencite")
                return "\\parencite{" + url.substring(1) + "}";
        }
    }
    if (url.startsWith("^")) {
        return "\\ref{" + url.substring(1) + "}";
    }
    return url;
};
//For internal links that start with '@'
const extendedCitation = (h, settings) => {
    const pre = "pre" in h ? h.pre : null;
    const post = "post" in h ? h.post : null;
    const id = h.value.substring(1);
    var citeText = '\\cite{{{id}}}';
    // Bare citation, e.g. `go see [[@ref]] for some stuff`
    if ((pre === null) && (post === null)) {
        citeText = settings.citationTemplates["bare"];
    }
    // Surrounded citation, e.g. `a bit thing (e.g. [[@ref]] p.37)`
    else if (pre && post) {
        citeText = settings.citationTemplates["surrounded"];
    }
    // Pre citation `something large (e.g. [[@ref]])`
    else if (pre) {
        citeText = settings.citationTemplates["pre"];
    }
    // Post citation `some things from the book ([[@ref]], p.37)
    else if (post) {
        citeText = settings.citationTemplates["post"];
    }
    // Paren citation => citet `some things from Author ([[@ref]])
    else {
        citeText = settings.citationTemplates["paren"];
    }
    //let citation = settings.citeTemplate
    citeText = citeText.replace(/#id/, id || "");
    citeText = citeText.replace(/#pre/, pre || "");
    citeText = citeText.replace(/#post/, post || "");
    //console.log("From",h)
    //console.log("Got: ",citeText)
    return citeText || "";
};
const externalLink = (a, settings, indent = 0) => {
    const l = a;
    return "\\url{" + l.url + "}";
};
const codeBlock = (a, settings, indent = 0) => {
    const cd = a;
    if (settings.mintedListings) {
        return `\\begin{minted}{${cd.lang}}
${cd.value}
\\end{minted}
`;
    }
    return `\\begin{lstlisting}[language=${cd.lang}]
${cd.value}
\\end{lstlisting}
`;
};
const inlineCode = (a, settings, indent = 0) => {
    const cd = a;
    if (settings.inlineDelimiter && settings.inlineDelimiter.length > 0) {
        const d = settings.inlineDelimiter;
        return `\\lstinline${d}${cd.value}${d}`;
    }
    return `\\lstinline{${cd.value}}`;
};
// Make sure not to escape anything in the math block
// (and add back in the dollar signs)
const inlineMath = (a, settings, indent = 0) => {
    const v = a.value;
    // This is a wierd hack - the mdast parser doesn't differentiate between block
    // and inline, so we have to guess by the difference between the length of the
    // value string and the amount of characters it covers in the source
    const difference = a.position.end.offset - a.position.start.offset - v.length;
    if (difference > 2)
        return `$$${v}$$`;
    else
        return `$${v}$`;
};
const displayMath = (a, settings, indent = 0) => {
    const v = a.value;
    return `$$\n${v}\n$$`;
};
function findAll(input, cond) {
    const r = cond(input) ? [input] : [];
    if (input.children)
        input.children.forEach(n => r.push(...findAll(n, cond)));
    return r;
}
function findCitations(ast) {
    const citationElements = findAll(ast, (n) => {
        if (n.type != 'wikiLink')
            return false;
        return n.value.startsWith("@");
    });
    const keyList = citationElements.map((n) => n.value.replace("@", ""));
    return new Set(keyList);
}
function preprocessAST(input) {
    // instanceof was being funny - should be input instanceof Parent
    if (input.children) {
        const children = input.children;
        children.forEach((e, i) => {
            const v = [null, e, null];
            if (i > 0)
                v[0] = children[i - 1];
            if (i < children.length - 1)
                v[2] = children[i + 1];
            modifyAST(v);
        });
        children.forEach(c => preprocessAST(c));
    }
}
function modifyAST(input) {
    // For some reason, the type system is being hinky here - doesn't think wikiLink is part of type
    if (input[1] && (input[1].type === "wikiLink")) {
        //console.log(`Working with: '${input[0] ? (input[0] as any).value : "<none>"}' : "${(input[1] as any).value}" : "${input[2] ? (input[2] as any).value : "<none>"}"`)
        if (input[0] && input[0].type === "text") {
            const i = input[0];
            const m = i.value.match(preCiteMatch);
            if (m) {
                //console.log(`Pre match: '${m[1]}':'${m[2]}'`)
                i.value = m[1];
                input[1].pre = m[2].trim();
            }
        }
        if (input[2] && input[2].type === "text") {
            const i = input[2];
            const m = i.value.match(postCiteMatch);
            if (m) {
                //console.log(`Post match: '${m[1]}':'${m[2]}'`)
                i.value = m[2];
                input[1].post = m[1].trim();
            }
        }
    }
}

// Pull items out of a bibliography
const bibItemPattern = /(^|\n)\s*(@\w+{[^@]*)(?=(\n\s*@|$))/sg;
// Get the key from a bibliography item
const bibKeyPattern = /^[\s\S]*@\w+{([^,]*)/s;
class BibtexConverter {
    /*
     * Returns a dictionary of all the bibtex entries in the file
     * by key
     */
    parseBibtex(text) {
        const items = [...text.matchAll(bibItemPattern)].map(i => i[2]);
        const kvps = items.map(i => [i.match(bibKeyPattern)[1], i]);
        const result = Object.fromEntries(kvps);
        return result;
    }
}

/* No settings provided yet... */
const DEFAULT_SETTINGS = {
    logOutput: false,
    copyWhole: true,
    inlineDelimiter: "",
    mintedListings: false,
    citeCommand: 'autocite',
    bibtexFile: "",
    citationTemplates: {
        "bare": "\\citep{#id}",
        "surrounded": "\\cite[#pre][#post]{#id}}",
        "pre": "\\cite[#pre]{#id}}",
        "post": "\\cite[#post]{#id}}",
        "paren": "\\citet{#id}"
    }
};
const citationExplanations = {
    "bare": "Bare citation: `... is clearly shown [[@foo]].`",
    "paren": "Parenthetical: `Author ([[@ref]]) says...`",
    "pre": "Pre-text: `some people (e.g. [[@ref]]) say ...`",
    "post": "Post-text: `... from the book ([[@ref]] p.29)`",
    "surrounded": "Pre and post: `can find examples (e.g. [[@ref]] p.29)`",
};
const citationSets = {
    "Default": {
        "bare": "\\cite{#id}",
        "surrounded": "\\cite[#pre][#post]{#id}",
        "pre": "\\cite[#pre][]{#id}",
        "post": "\\cite[#post]{#id}",
        "paren": "\\cite{#id}"
    },
    "Autocite": {
        "bare": "\\autocite{#id}",
        "surrounded": "\\autocite[#pre][#post]{#id}",
        "pre": "\\autocite[#pre][]{#id}",
        "post": "\\autocite[#post]{#id}",
        "paren": "\\citeyear{#id}"
    },
    "Natbib": {
        "bare": "\\citep{#id}",
        "surrounded": "\\cite[#pre][#post]{#id}",
        "pre": "\\cite[#pre][]{#id}",
        "post": "\\cite[#post]{#id}",
        "paren": "\\citet{#id}"
    },
    "Brute-Force": {
        "bare": "\\cite{#id}",
        "surrounded": "(#pre \\cite{#id} #post)",
        "pre": "(#pre \\cite{#id}})",
        "post": "(\\cite{#id}} #post)",
        "paren": "(\\cite{#id})"
    },
    "Testing": {
        "bare": "\\cite{#id} BARE",
        "surrounded": "(#pre \\cite{#id} #post) SURR",
        "pre": "(#pre \\cite{#id}}) PRE",
        "post": "(\\cite{#id}} #post) POST",
        "paren": "\\cite{#id} PAREN"
    }
};
class CopyAsLatexSettingTab extends obsidian.PluginSettingTab {
    constructor(app, plugin) {
        super(app, plugin);
        this.plugin = plugin;
    }
    display() {
        let { containerEl } = this;
        containerEl.empty();
        containerEl.createEl('h2', { text: 'Settings for Copy as Latex' });
        new obsidian.Setting(containerEl)
            .setName('Log Output')
            .setDesc('Should the plugin log output to the Console - mostly just for debugging')
            .addToggle(toggle => toggle
            .setValue(this.plugin.settings.logOutput)
            .onChange((value) => __awaiter(this, void 0, void 0, function* () {
            this.plugin.settings.logOutput = value;
            yield this.plugin.saveSettings();
        })));
        new obsidian.Setting(containerEl)
            .setName('Minted Output')
            .setDesc('Use the minted package for code listings? (Note: - not used for inline code at the moment)')
            .addToggle(toggle => toggle
            .setValue(this.plugin.settings.mintedListings)
            .onChange((value) => __awaiter(this, void 0, void 0, function* () {
            this.plugin.settings.mintedListings = value;
            yield this.plugin.saveSettings();
        })));
        new obsidian.Setting(containerEl)
            .setName('Inline delimiters')
            .setDesc('What delimiters to use for inline lstlistings? Default is curly braces ')
            .addText(text => text
            .setValue(this.plugin.settings.inlineDelimiter)
            .onChange((value) => __awaiter(this, void 0, void 0, function* () {
            this.plugin.settings.inlineDelimiter = value;
            yield this.plugin.saveSettings();
        })));
        new obsidian.Setting(containerEl)
            .setName('Copy whole note')
            .setDesc('If nothing is selected, should the plugin copy the whole note as latex?')
            .addToggle(toggle => toggle
            .setValue(this.plugin.settings.copyWhole)
            .onChange((value) => __awaiter(this, void 0, void 0, function* () {
            this.plugin.settings.copyWhole = value;
            yield this.plugin.saveSettings();
        })));
        const options = {
            "basic": "Basic - \\cite{@foo}",
            "autocite": "Autocite - \\autocite{@foo}",
            "parencite": "Paren Cite - \\parencite{@foo}",
            "extended": "Extended Citations - commands below"
        };
        new obsidian.Setting(containerEl)
            .setName('Citation Command')
            .setDesc('What command to use for citations?')
            .addDropdown(dropdown => dropdown
            .addOptions(options)
            .setValue(this.plugin.settings.citeCommand)
            .onChange((value) => __awaiter(this, void 0, void 0, function* () {
            this.plugin.settings.citeCommand = value;
            yield this.plugin.saveSettings();
        })));
        /*
              new Setting(containerEl)
              .setName('Extended Citation parsing')
              .setDesc('Tries to do some clever parsing of text for complex citations. Overrides citation type above')
              .addToggle(toggle => toggle
                  .setValue(this.plugin.settings.extendedCitations)
                  .onChange(async (value) => {
                      this.plugin.settings.extendedCitations = value;
                      await this.plugin.saveSettings();
                  }));
                  */
        const textFields = {};
        new obsidian.Setting(containerEl)
            .setName('Extended Citation Templates')
            .setDesc('Templates for new citation technique; they make available {{id}}, {{pre}}, {{post}} tags')
            .addDropdown(dropdown => {
            for (const k in citationSets) {
                dropdown.addOption(k, k);
            }
            dropdown
                .setValue("Default")
                .onChange((value) => __awaiter(this, void 0, void 0, function* () {
                const templs = citationSets[value];
                this.plugin.settings.citationTemplates = templs;
                for (const k in templs) {
                    textFields[k].setValue(templs[k]);
                }
                yield this.plugin.saveSettings();
            }));
        });
        for (const k in citationExplanations) {
            const typ = k;
            new obsidian.Setting(containerEl)
                .setName(k + ' Citation')
                .setDesc(citationExplanations[typ])
                .addText(text => {
                text
                    .setValue(this.plugin.settings.citationTemplates[typ])
                    .onChange((value) => __awaiter(this, void 0, void 0, function* () {
                    this.plugin.settings.citationTemplates[typ] = value;
                    yield this.plugin.saveSettings();
                }));
                textFields[typ] = text;
            });
        }
        new obsidian.Setting(containerEl)
            .setName('BibTex file Copy Citations')
            .setDesc('! Set a bibtex file here relative to Vault root, and then you can copy citations from it if they are missing in a target bibliography on the clipboard')
            .addText(text => text
            .setValue(this.plugin.settings.bibtexFile)
            .onChange((value) => __awaiter(this, void 0, void 0, function* () {
            this.plugin.settings.bibtexFile = value;
            yield this.plugin.saveSettings();
        })));
    }
}

class CopyAsLatexPlugin extends obsidian.Plugin {
    constructor() {
        super(...arguments);
        this.bibtex = new BibtexConverter();
        this.remarkSetup = {
            extensions: [syntax(), gfm(), math()],
            mdastExtensions: [fromMarkdown_1(), gfmFromMarkdown(), mathFromMarkdown()]
        };
    }
    onload() {
        return __awaiter(this, void 0, void 0, function* () {
            console.log('loading Copy as Latex');
            yield this.loadSettings();
            this.addCommand({
                id: 'copy-as-latex',
                name: 'Copy as Latex',
                editorCallback: (editor, _) => this.markdownToLatex(editor)
            });
            this.addCommand({
                id: 'latex-citations',
                name: 'Copy Missing Citations',
                editorCallback: (editor, _) => this.copyMissingCitations(editor)
            });
            this.addSettingTab(new CopyAsLatexSettingTab(this.app, this));
        });
    }
    markdownToLatex(editor) {
        let text = editor.getSelection();
        if (text.length == 0 && this.settings.copyWhole)
            text = editor.getRange({ line: 0, ch: 0 }, { line: (editor.lastLine() + 1), ch: 0 });
        if (this.settings.logOutput) {
            console.log(text);
        }
        const ast = fromMarkdown$1(text, this.remarkSetup);
        if (this.settings.logOutput) {
            console.log(ast);
        }
        if (this.settings.citeCommand === "extended")
            preprocessAST(ast);
        if (this.settings.logOutput) {
            console.log("New AST:", ast);
        }
        const result = ASTtoString(ast, this.settings);
        if (this.settings.logOutput) {
            console.log(result);
        }
        navigator.clipboard.writeText(result);
        return true;
    }
    copyMissingCitations(editor) {
        return __awaiter(this, void 0, void 0, function* () {
            let text = editor.getSelection();
            if (text.length == 0 && this.settings.copyWhole)
                text = editor.getRange({ line: 0, ch: 0 }, { line: (editor.lastLine() + 1), ch: 0 });
            const ast = fromMarkdown$1(text, this.remarkSetup);
            const keysInDoc = findCitations(ast);
            console.log("Citations in document", keysInDoc);
            const myBibFile = this.resolveLibraryPath(this.settings.bibtexFile);
            console.log("Bib file:", myBibFile);
            const myBib = yield obsidian.FileSystemAdapter.readLocalFile(myBibFile);
            //console.log("Got bibliography",myBib)
            // Decode file as UTF-8.
            const dataView = new DataView(myBib);
            const decoder = new TextDecoder('utf8');
            const value = decoder.decode(dataView);
            //console.log("Got bibliography",value)
            const sourceBibliography = this.bibtex.parseBibtex(value);
            //console.log("Source bibliography keys",Object.keys(sourceBibliography))
            const destBibliography = this.bibtex.parseBibtex(yield navigator.clipboard.readText());
            console.log("Destination bibliography keys", Object.keys(destBibliography));
            for (const k in destBibliography) {
                console.log("Citation found in target:", k);
                keysInDoc.delete(k);
            }
            console.log("Keys in document missing from target: ", keysInDoc);
            const toAdd = [];
            const found = [];
            const missing = [];
            [...keysInDoc].forEach((k) => {
                if (sourceBibliography[k]) {
                    found.push(k);
                    toAdd.push(sourceBibliography[k]);
                }
                else {
                    missing.push(k);
                }
            });
            console.log("Found keys: ", found);
            console.log("Missing keys: ", missing);
            const final = toAdd.join("\n");
            console.log("Final:", final);
            navigator.clipboard.writeText(final);
            //forEach((k:string,v:string)=> keysInDoc.delete(k))
            //const missingKeys = keysInDoc.
        });
    }
    /**
  * Resolve a provided library path, allowing for relative paths rooted at
  * the vault directory.
  * From https://github.com/hans/obsidian-citation-plugin/blob/master/src/main.ts
  */
    resolveLibraryPath(rawPath) {
        const vaultRoot = this.app.vault.adapter instanceof obsidian.FileSystemAdapter
            ? this.app.vault.adapter.getBasePath()
            : '/';
        return path__namespace.resolve(vaultRoot, rawPath);
    }
    onunload() {
        console.log('unloading plugin');
    }
    loadSettings() {
        return __awaiter(this, void 0, void 0, function* () {
            this.settings = Object.assign({}, DEFAULT_SETTINGS, yield this.loadData());
        });
    }
    saveSettings() {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.saveData(this.settings);
        });
    }
}

module.exports = CopyAsLatexPlugin;


/* nosourcemap */