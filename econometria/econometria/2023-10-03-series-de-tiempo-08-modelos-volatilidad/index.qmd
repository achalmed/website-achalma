---
title: Modelos Univariados y Multivariados de Volatilidad
subtitle: Modelos para analizar la volatilidad en series de tiempo.
description: |
  Introducción a modelos univariados y multivariados de volatilidad y su aplicación en series de tiempo
categories:
  - Estadística
  - Análisis de datos
  - Series de tiempo
  - Modelos Univariados
  - Multivariados de Volatilidad
tags:
  - SeriesDeTiempo
  - AnálisisDeDatos
  - Estadística
  - ModelosUnivariados
  - MultivariadosDeVolatilidad
date: "10/03/2023"
draft: false  # Modo de borrador (false = final, true = borrador)
---

# Modelos Univariados y Multivariados de Volatilidad

## Motivación

Estos modelos de Heterocedásticidad Condicional Autoregresiva (ARCH, por sus siglas en inglés) y modelos Heterocedásticidad Condicional Autoregresiva Generalizados (GARCH, por sus siglas en inglés) tienen la característica de modelar situaciones como las que ilustra la Figutra \@ref(fig:fig102). Es decir: 

1) Existen zonas donde la variación de los datos es mayor y zonas donde la variación es más estable--a estas situaciones se les conoce como de variabilidad por clúster--, y 

2) los datos corresponden a innformación de alta frecuencia.

Iniciemos por las bibliotecas necesarias:

```{r SetUp_ARCH, warning=FALSE, message=FALSE}

library(expm)
library(Matrix)
library(ggplot2)
library(quantmod)
library(moments)
library(dynlm)
library(broom)
library(FinTS)
library(lubridate)
library(forecast)
library(readxl)
library(MASS)
library(rugarch)
library(tsbox)
library(MTS)
library(rmgarch)
library(Rcpp)

```

Para el análisis de temas financieros existe una librería de mucha utilidad llamada __quantmod__. En primer lugar esta librería permite acceder a datos financieros de un modo muy simple, es posible decargar series financieras desde _yahoo_, la _FRED (Federal Reserve Economic Data)_, _google_, etc. Por otro lado también es una librería que permite realizar gráficos altamente estéticos con unas cuantas líneas de código. Ahora, usaremos datos de Yahoo Finance respecto de la cotización del bitcoin (ticker: "BTC-USD"). 
```{r Data_ARCH, warning=FALSE, message=FALSE}

options("getSymbols.warning4.0"=FALSE)

BTC <-getSymbols("BTC-USD", src = "yahoo", auto.assign = FALSE)

BTC <- na.omit(BTC)

chartSeries(BTC,TA='addBBands();
                    addBBands(draw="p");
                    addVo();
                    addMACD()',# subset='2021',
                theme="white")

head(BTC)

tail(BTC)

```

Para fines del ejercicio de esta clase, usaremos el valor de la acción ajustado. Esto nos servirá para calcular el rendimiento diario, o puesto en lenguaje de series temporales podemos decir que usaremos la serie en diferencias logarítmicas. 

```{r fig101, fig.cap = "Evolución del precio del Bitcoin", fig.align='center'}

plot(BTC$`BTC-USD.Adjusted`)

```
Una de las preguntas relevantes al observar la serie en diferencias, es si podríamos afirmar que esta serie cumple con el supuesto de homoscedasticidad. 

```{r fig102, fig.cap = "Evolución del rendimiento (diferenccias logarítmicas) del Bitcoin", fig.align='center'}

logret <- ts(diff(log(BTC$`BTC-USD.Adjusted`))[-1])

plot(logret)

```
### Value at risk

Utilicemos como ejemplo el Valor en Riesgo. Este es básicamente es un cálculo que nos permite estimar el monto que una acción o portafolio podría perder dada una probabilidad $(1-\alpha)$. 

```{r VaR, message=FALSE, warning=FALSE}

alpha <- 0.05

VaR <- quantile( logret, alpha )

round( VaR, 4 )*100

```

```{r fig103, fig.cap = "Histograma de rendimientos del Bitcoin", fig.align='center', message=FALSE, warning=FALSE}

qplot(logret , geom = 'histogram') + 
  geom_histogram(fill = 'lightblue' , bins = 30) +
  geom_histogram( aes(logret[logret < quantile(logret , 0.05)]) , 
                  fill = 'red' , bins = 30) +
  labs(x = 'Daily Returns')

```

```{r fig104, fig.cap = "Densidad de rendimientos del Bitcoin Vs. una distribución normal", fig.align='center', message=FALSE, warning=FALSE}

normal_dist <- rnorm(100000, mean(logret), sd(logret))
VaR_n <- quantile(normal_dist, 0.05)
ES_n <- mean(normal_dist[normal_dist<VaR])
  
ggplot()+
  geom_density(aes(logret, geom ='density', col = 'returns'))+
  geom_density(aes(normal_dist, col = 'normal'))

```


```{r DescStatARCH, warning=FALSE}

vector_ret <- as.vector(logret)

##Kurtosis
round(kurtosis(vector_ret),2)
##Sesgo
round(skewness(vector_ret),2)

```

## Prueba de normalidad 

$H_o: K=S=0$

```{r JB_ARCH}

jarque.test(vector_ret)

```

## Modelos ARCH y GARCH Univariados

Para plantear el modelo supongamos --por simplicidad-- que hemos construido y estimado un modelo AR(1). Es decir, asumamos que el proceso subyacente para la media condicional está dada por:
\begin{equation}
    X_t = a_0 + a_1 X_{t-1} + U_t
\end{equation}

Donde $| a_1 |< 1$ para garantizar la convergencia del proceso en el largo plazo, en el cual:
\begin{eqnarray*}
    \mathbb{E}[X_t] & = & \frac{a_0 }{1 - a_1} = \mu \\
    Var[X_t] & = & \frac{\sigma^2}{1 - a_1^2}
\end{eqnarray*}

Ahora, supongamos que este tipo de modelos pueden ser extendidos y generalizados a un modelo ARMA(p, q), que incluya otras variables exogénas. Denotemos a como $\mathbf{Z}_t$ al conjunto que incluye los componentes AR, MA y variables exogénas que pueden explicar a $X_t$ de forma que el proceso estará dado por:
\begin{equation}
    X_t = \mathbf{Z}_t \boldsymbol{\beta} + U_t
\end{equation}

Donde $U_t$ es un proceso estacionario que representa el error asociado a un proceso ARMA(p, q) y donde siguen diendo válidos los supuestos:
\begin{eqnarray*}
    \mathbb{E}[U_t] & = & 0 \\
    Var[U_t^2] & = & \sigma^2
\end{eqnarray*}

No obstante, en este caso podemos suponer que existe autocorrelación en el término de error al cuadrado que puede ser capturada por un porceso similar a uno de medias móviles (MA) dado por:
\begin{equation}
    U_t^2 = \gamma_0 + \gamma_1 U_{t-1}^2 + \gamma_2 U_{t-2}^2 + \ldots + \gamma_q U_{t-q}^2 + \nu_t
\end{equation}

Donde $\nu_t$ es un ruido blanco y $U_{t-i} = X_{t-i} - \mathbf{Z}_{t-i} \boldsymbol{\beta}$, $i = 1, 2 ,\ldots $. Si bien los procesos son estacionarios por los supuestos antes enunciados, la varianza condicional estará dada por:
\begin{eqnarray*}
    \sigma^2_{t | t-1} & = & Var[ U_t | \Omega_{t-1} ] \\
    & = & \mathbb{E}[ U^2_t | \Omega_{t-1} ]
\end{eqnarray*}

Donde $\Omega_{t-1} = \{U_{t-1}, U_{t-2}, \ldots \}$ es el conjunto de toda la información pasada de $U_t$ y observada hasta el momento $t-1$, por lo que:
\begin{equation*}
    U_t | \Omega_{t-1} \sim \mathbb{D}(0, \sigma^2_{t | t-1})
\end{equation*}

Así, de forma similar a un proceso MA(q) podemos decir que la varianza condicional tendrá efectos ARCH de orden $q$ (ARCH(q)) cuando:
\begin{equation}
    \sigma^2_{t | t-1} = \gamma_0 + \gamma_1 U_{t-1}^2 + \gamma_2 U_{t-2}^2 + \ldots + \gamma_q U_{t-q}^2
    (\#eq:ARCHEffect)
\end{equation}

Donde $\mathbb{E}[\nu_t] = 0$ y $\gamma_0$ y $\gamma_i \geq 0$, para $i = 1, 2, \ldots, q-1$ y  $\gamma_q > 0$. Estas condiciones son necesarias para garantizar que la varianza sea positiva. En general, la varianza condicional se expresa de la forma $\sigma^2_{t | t-1}$, no obstante, para facilitar la notación, nos referiremos en cada caso a esta simplemente como $\sigma^2_{t}$.

Podemos generalizar está situación si asumimos a la varianza condicional como dependiente de lo valores de la varianza rezagados, es decir, como si fuera un proceso AR de orden $p$ para la varianza y juntandolo con la ecuación \@ref(eq:ARCHEffect). Bollerslev (1986) y Taylor (1986) generalizaron el problema de heterocedásticidad condicional. El modelo se conoce como GARCH(p, q), el cual se especifica como:
\begin{eqnarray}
    \sigma^2_t & = & \gamma_0 + \gamma_1 U_{t-1}^2 + \gamma_2 U_{t-2}^2 + \ldots + \gamma_q U_{t-q}^2 \\ \nonumber 
    & & + \beta_1 \sigma^2_{t-1} + \beta_2 \sigma^2_{t-2} + \ldots + \beta_p \sigma^2_{t-p}
    (\#eq:GARCHEffect)
\end{eqnarray}

Donde las condiciones de no negatividad son que $\gamma_0 > 0$, $\gamma_i \geq 0$, $i = 1, 2, \ldots, q-1$, $\beta_j \geq 0$, $j = 1, 2, \ldots, p-1$, $\gamma_q > 0$ y $\beta_p > 0$. Además, otra condición de convergencia es que:
\begin{equation*}
    \gamma_1 + \ldots + \gamma_q + \beta_1 + \ldots + \beta_p < 1
\end{equation*}

Usando el operador rezago $L$ en la ecuación \@ref(eq:GARCHEffect) podemos obtener:
\begin{equation}
    \sigma^2_t = \gamma_0 + \alpha(L) U_t^2 + \beta(L) \sigma^2_t
    (\#eq:GARCHEffectL)
\end{equation}

De donde podemos establecer:
\begin{equation}
    \sigma^2_t = \frac{\gamma_0}{1 - \beta(L)} + \frac{\alpha(L)}{1 - \beta(L)} U_t^2 
\end{equation}

Por lo que la ecuación \@ref(eq:GARCHEffect) del GARCH(p, q) representa un ARCH($\infty$):
\begin{equation}
    \sigma^2_t = \frac{a_0}{1 - b_1 - b_2 - \ldots - b_p} + \sum_{i = 1}^\infty U_{t-i}^2 
\end{equation}

### Ejemplo ARCH(1) 

Hasta ahora las distribuciones utilizadas para medir el Valor en Riesgo de este activo, asumen que no existe correlación serial en los retornos diarios de este activo. Observemos un par de gráficas de la función de autocorrelación para corroborar este hecho. 

```{r fig105, fig.cap = "Función de autocorrelación parcial de lo rendimientos del Bitcoin", fig.align='center', message=FALSE, warning=TRUE}

acf(logret)

```

La idea de clusterización de volatilidad, asume que periodos de alta volatilidad serán seguidos por una alta volatilidad y viceversa. Por esta razón la función de autocorrelación útil para saber si existen clústers de volatilidad es utilizando el valor absoluto, ya que lo que importa es saber si la serie está autocorrelacionada en la magnitud de los movimientos. 

```{r fig106, fig.cap = "Evolución de los rendimientos del Bitcoin en valor absoluto", fig.align='center', message=FALSE, warning=TRUE}

plot(abs(logret))

```

```{r fig107, fig.cap = "Función de autocorrelación parcial de los rendimientos del Bitcoin en valor absoluto", fig.align='center', message=FALSE, warning=TRUE}

acf(abs(logret))

```

Otra manera de corroborar esta idea es volviendo IID nuestra serie de datos y observar que de este modo se pierde la autocorrelación serial, lo que refuerza la idea de que en esta serie existen clusters de volatilidad. 

```{r fig108, fig.cap = "Función de autocorrelación parcial de los rendimientos del Bitcoin en valor absoluto", fig.align='center', message=FALSE, warning=FALSE}

logret_random <- sample(as.vector(logret), size =  length(logret), replace = FALSE)

acf(abs(logret_random))

```

```{r fig109, fig.cap = "Función de autocorrelación parcial de los rendimientos del Bitcoin en valor absoluto", fig.align='center', message=FALSE, warning=FALSE}

par(mfrow = c(1,2))
plot(logret)
plot(logret_random, type = 'l')

```

Primer enfoque para comprobar aceptar o rechazar la hopótesis de que necesitamos estimar un ARCH(q)

```{r ArchTest}
logret_mean = dynlm(logret~1)

summary(logret_mean)

ehatsq = ts(resid(logret_mean)^2)

ARCH_m = dynlm(ehatsq~L(ehatsq))

summary(ARCH_m)


acf(ARCH_m$residuals)
acf(abs(ARCH_m$residuals))

ArchTest(logret, lags = 1, demean = TRUE)
```

Estimemos un ARCH(1), considerando la siguente especificación:

$Y_t = \mu+\sqrt{h_t}\varepsilon_t$

$h_t = \omega+\alpha_ih_{t-i}+u_t$

$\varepsilon \sim N(0,1)$

```{r ARCH_1}

library(rugarch)

auto.arima(logret)

#?ugarchspec

model.spec = ugarchspec( variance.model = list(model = 'sGARCH' , 
                                               garchOrder = c(1, 0)), 
                        mean.model = list(armaOrder = c(2,0)), 
                        distribution.model = "std")

#?ugarchfit

arch.fit = ugarchfit(spec = model.spec , data = logret, 
                     solver = 'solnp')

arch.fit@fit$matcoef

boot.garch <- ugarchboot(arch.fit,
                         method = "Partial",
                         sampling = "raw",  #bootstrap from fitted varepsilon
                         n.ahead = 1,          #simulation horizon
                         n.bootpred = 100000, #number of simulations 
                         solver = "solnp")

boot.garch

```

## Ejemplo GARCH(0,1)

Estimemos un GARCH(0,1) unsando la siguiente especificación:

$Y_t = \mu+\sqrt{h_t}\varepsilon_t$

$h_t = \omega+\beta_i \sigma^2_{t-i}+u_t$

$\varepsilon \sim N(0,1)$

```{r GARCH_0_1}
model.spec = ugarchspec(variance.model = list(model = 'sGARCH' , 
                                              garchOrder = c(0,1)), 
                        mean.model = list(armaOrder = c(2,0)), 
                        distribution.model = "std")

fit.garch.n = ugarchfit(spec = model.spec, data = logret, 
                        solver = "solnp")

fit.garch.n@fit$matcoef

boot.garch <- ugarchboot(fit.garch.n,
                         method = "Partial",
                         sampling = "raw",  #bootstrap from fitted varepsilon
                         n.ahead = 1,          #simulation horizon
                         n.bootpred = 100000, #number of simulations 
                         solver = "solnp")
boot.garch

```

### Selección GARCH(p,q) óptimo

¿Cómo seleccionamos el órden adecuado para un GARCH(p,q)? Acá una respuesta.

$Y_t = \mu+\sqrt{h_t}\varepsilon_t$

$h_t = \omega+\beta_ih_{t-i}+\alpha_i\varepsilon^2_{t-i}+u_t$

$\varepsilon \sim N(0,1)$

#### Criterios de información 

```{r AIC_GARCH}

infocriteria(fit.garch.n)

```

#### Selección del modelo óptimo

```{r LagOptGARCH}

source("code lag opt garch.r")

Lag_Opt_GARCH(ehatsq,4,4)

```

#### Estimación de modelo óptimo 

```{r}

model.spec = ugarchspec(variance.model = list(model = 'sGARCH', 
                                              garchOrder = c(4,2)), 
                        mean.model = list(armaOrder = c(2,0)), 
                        distribution.model = "std")


model.fit = ugarchfit(spec = model.spec , data = logret, 
                      solver = 'solnp')

model.fit@fit$matcoef


boot.garch <- ugarchboot(model.fit,
                         method = "Partial",
                         sampling = "raw",  #bootstrap from fitted varepsilon
                         n.ahead = 1,          #simulation horizon
                         n.bootpred = 100000, #number of simulations 
                         solver = "solnp")

boot.garch

```

#### Forecasting with GARCH(1,1)

Para realizar pronósticos con la estimación de un GARCH, utilizando la librería _rugarch_, es necesario utilizar la función __ugarchforecast()__. 

```{r}
model.spec = ugarchspec(variance.model = list(model = 'sGARCH', 
                                              garchOrder = c(1,1)), 
                        mean.model = list(armaOrder = c(4,2)), 
                        distribution.model = "std")

model.fit = ugarchfit(spec = model.spec , data = logret, 
                      solver = 'solnp')

spec = getspec(model.fit)

setfixed(spec) <- as.list(coef(model.fit))
```

Esta función precisa como argumentos nuestra estimación del modelo GARCH, con una modificación en la manera en que se presentan los coeficientes, realizada en la última línea del código anterior y que llamamos _spec_. _n.ahead_ es el número de periodos que vamos a pronosticar, _n.roll_ señala el número de pronósticos móviles que utilizaremos, en caso de que haya más información para realizar el pronóstico. Finalmente damos como input nuestro set de datos y como producto obtendremos el pronostico de Sigma tanto como de la serie.

```{r}
forecast = ugarchforecast(spec, n.ahead = 12, n.roll = 0, logret)

sigma(forecast)

fitted(forecast)

forecast
```

## Modelos ARCH y GARCH Multivariados

De forma similar a los modelo univariados, los modelos multivariados de heterocedásticidad condicional asumen una estructura de la media condicional. En este caso, descrita por un VAR(p) cuyo proceso estocástico $\mathbf{X}$ es estacionario de dimensión $k$. De esta forma la expresión reducida del modelo o el proceso VAR(p) estará dado por:
\begin{equation}
    \mathbf{X}_t = \mathbf{\delta} + A_1 \mathbf{X}_{t-1} + A_2 \mathbf{X}_{t-2} + \ldots + A_p \mathbf{X}_{t-p} + \mathbf{U}_{t}
\end{equation}

Donde cada uno de las $A_i$, $i = 1, 2, \ldots, p$, son matrices cuadradas de dimensión $k$ y $\mathbf{U}_t$ representa un vector de dimensión $k \times 1$ con los residuales en el momento del tiempo $t$ que son un proceso pueramente aleatorio. También se incorpora un vector de términos constantes denominado como $\mathbf{\delta}$, el cual es de dimensión $k \times 1$ --es este caso también es posible incorporar procesos determinas adicionales--.

Así, suponemos que el término de error tendrá estructura de vector:
\begin{equation*}
    \mathbf{U}_t = 
    \begin{bmatrix}
    U_{1t} \\ U_{2t} \\ \vdots \\ U_{Kt}
    \end{bmatrix}
\end{equation*}

De forma que diremos que:
\begin{equation*}
    \mathbf{U}_t | \Omega_{t-1} \sim (0, \Sigma_{t | t-1})
\end{equation*}

Dicho lo anterior, entonces, el mode ARCH(q) multivariado será descrito por:
\begin{equation}
    Vech(\Sigma_{t | t-1}) = \boldsymbol{\gamma}_0 + \Gamma_1 Vech(\mathbf{U}_{t-1} \mathbf{U}_{t-1}') + \ldots + \Gamma_q Vech(\mathbf{U}_{t-q} \mathbf{U}_{t-q}')
    (\#eq:M_ARCH)
\end{equation}

Donde $Vech$ es un operador que apila en un vector la parte superior de la matriz a la cual se le aplique, $\boldsymbol{\gamma}_0$ es un vector de cosntantes, $\Gamma_i$, $i = 1, 2, \ldots$ son matrices de coeficientes asociados a la estimación.

Para ilustrar la ecuación \@ref(eq:M_ARCH), tomemos un ejemplo de $K = 2$, de esta forma tenemos que un M-ARCH(1) será:
\begin{equation*}
    \Sigma_{t | t-1} = 
    \begin{bmatrix}
    \sigma^2_{1, t | t-1} & \sigma_{12, t | t-1} \\ \sigma_{21, t | t-1} & \sigma^2_{2, t | t-1}
    \end{bmatrix} = 
    \begin{bmatrix}
    \sigma_{11, t} & \sigma_{12, t} \\ \sigma_{21, t} & \sigma_{22, t}
    \end{bmatrix} =
    \Sigma_{t}
\end{equation*}

Donde hemos simplificado la notación de la varianzas y la condición de que están en función de $t-1$. Así,
\begin{equation*}
    Vech(\Sigma_{t}) = 
    Vech \begin{bmatrix}
    \sigma_{11, t} & \sigma_{12, t} \\ \sigma_{21, t} & \sigma_{22, t}
    \end{bmatrix} =
    \begin{bmatrix}
    \sigma_{11, t} \\ \sigma_{12, t} \\ \sigma_{22, t}
    \end{bmatrix}
\end{equation*}

De esta forma, podemos establecer el modelo M-ARCH(1) con $K = 2$ será de la forma:
\begin{equation*}
    \begin{bmatrix}
    \sigma_{11, t} \\ \sigma_{12, t} \\ \sigma_{22, t}
    \end{bmatrix} =
    \begin{bmatrix}
    \gamma_{10} \\ \gamma_{20} \\ \gamma_{30}
    \end{bmatrix} +
    \begin{bmatrix}
    \gamma_{11} & \gamma_{12} & \gamma_{13} \\ \gamma_{21} & \gamma_{22} & \gamma_{23} \\ \gamma_{31} & \gamma_{32} & \gamma_{33}
    \end{bmatrix} 
    \begin{bmatrix}
    U^2_{1, t-1} \\ U_{1, t-1} U_{2, t-1} \\ U^2_{2, t-1}
    \end{bmatrix}
\end{equation*}

Como notarán este tipo de procedimientos implica la estimación de muchos paramétros. En este circunstacia, se suelen estimar modelos restringidos para reducir el número de coeficientes estimados. por ejemplo, podríamos querer estimar un caso como:
\begin{equation*}
    \begin{bmatrix}
    \sigma_{11, t} \\ \sigma_{12, t} \\ \sigma_{22, t}
    \end{bmatrix} =
    \begin{bmatrix}
    \gamma_{10} \\ \gamma_{20} \\ \gamma_{30}
    \end{bmatrix} +
    \begin{bmatrix}
    \gamma_{11} & 0 & 0 \\ 0 & \gamma_{22} & 0 \\ 0 & 0 & \gamma_{33}
    \end{bmatrix} 
    \begin{bmatrix}
    U^2_{1, t-1} \\ U_{1, t-1} U_{2, t-1} \\ U^2_{2, t-1}
    \end{bmatrix}
\end{equation*}

Finalmente y de forma analóga al caso univariado, podemos plantear un modelo M-GARCH(p, q) como:
\begin{equation}
    Vech(\Sigma_{t | t-1}) = \boldsymbol{\gamma}_0 + \sum_{j = 1}^q \Gamma_j Vech(\mathbf{U}_{t-j} \mathbf{U}_{t-j}') + \sum_{m = 1}^p \mathbf{G}_m Vech(\Sigma_{t-m | t-m-1})
    \label{M_GARCH}
\end{equation}

Donde cada una de las $\mathbf{G}_m$ es una matriz de coeficientes. Para ilustrar este caso retomemos el ejemplo anterior pera ahora para un modelo M-GARCH(1, 1) con $K = 2$ de formaque tendríamos:
\begin{eqnarray*}
    \begin{bmatrix}
    \sigma_{11, t} \\ \sigma_{12, t} \\ \sigma_{22, t}
    \end{bmatrix} & = &
    \begin{bmatrix}
    \gamma_{10} \\ \gamma_{20} \\ \gamma_{30}
    \end{bmatrix} +
    \begin{bmatrix}
    \gamma_{11} & \gamma_{12} & \gamma_{13} \\ \gamma_{21} & \gamma_{22} & \gamma_{23} \\ \gamma_{31} & \gamma_{32} & \gamma_{33}
    \end{bmatrix} 
    \begin{bmatrix}
    U^2_{1, t-1} \\ U_{1, t-1} U_{2, t-1} \\ U^2_{2, t-1}
    \end{bmatrix} \\
    & & + 
    \begin{bmatrix}
    g_{11} & g_{12} & g_{13} \\ g_{21} & g_{22} & g_{23} \\ g_{31} & g_{32} & g_{33}
    \end{bmatrix} 
    \begin{bmatrix}
    \sigma_{11, t-1} \\ \sigma_{12, t-1} \\ \sigma_{22, t-1}
    \end{bmatrix}
\end{eqnarray*}

## Pruebas para detectar efectos ARCH

La prueba que mostraremos es conocida como una ARCH-LM, la cual está basada en una regresión de los residuales estimados de un modelo VAR(p) o cualquier otra estimación que deseemos probar, con el objeto de determinar si existen efectos ARCH --esta prueba se puede simplificar para el caso univariado--.

Partamos de platear:
\begin{eqnarray}
    Vech(\hat{\mathbf{U}}_t \hat{\mathbf{U}}_t') & = & \mathbf{B}_0 + \mathbf{B}_1 Vech(\hat{\mathbf{U}}_{t-1} \hat{\mathbf{U}}_{t-1}') + \ldots \\ \nonumber
    & & + \mathbf{B}_q Vech(\hat{\mathbf{U}}_{t-q} \hat{\mathbf{U}}_{t-q}') + \varepsilon_t
    (\#eq:ARCH-LM)
\end{eqnarray}

Dada la estimación en la ecuación \@ref(eq:ARCH-LM), plantemos la estructura de hipótesis dada por:
\begin{eqnarray*}
    H_0 & : & \mathbf{B}_1 = \mathbf{B}_2 = \ldots = \mathbf{B}_q = 0 \\
    H_a & : & No H_0    
\end{eqnarray*}

La estadística de prueba será determinada por:
\begin{equation}
    LM_{M-ARCH} = \frac{1}{2} T K (K + 1) - Traza \left( \hat{\Sigma}_{ARCH} \hat{\Sigma}^{-1}_{0} \right) \sim \chi^2_{[q K^2 (K + 1)^2 / 4]}
\end{equation}

Donde la matriz $\hat{\Sigma}_{ARCH}$ es calcula de acuerdo con la ecuación \@ref(eq:ARCH-LM) y la matriz $\hat{\Sigma}_{0}$ sin considerar una estructura dada para los errores.
